\chapter{Closing Remarks}
In this report, we model decisions in the box task using a softmax model with parameters $\alpha$, $\beta$ and $\eta$. The parameter $\alpha$ is a small penalty or loss we get each time we open a box, and $\beta$ is the loss we get when the test terminates before choosing what the majority colour is. The last parameter, $\eta$, says something about how far away the choices that are made are from the decision with the least expected loss.
We have data from 76 participants who have done several box task trials, and we find maximum likelihood estimates for each participant and confidence intervals tied to each parameter using parametric bootstrapping. MLEs are plotted for all participants, in addition to bootstrap samples and CIs for some participants. 
We find that the model is a good fit for participants who make good choices but worse for those who make decisions with high expected losses. Moreover, parametric bootstrapping makes the confidence intervals for participants that make good choices be zero. Thus, that is not an ideal way of finding CIs for these participants.
We also discuss the sensitivity to the hyperparameters in the prior distribution for $\Theta$. The results for the unlimited case of the box task are not very sensitive to changes in the hyperparameters, unlike the results in the limited version, where all parameters seem to have estimates of lower value. 

In addition to this, we develop an Ideal Observer (IO) solution of the box task. This is done by finding the expected losses for the three choices we have each time a box is opened and then always making the decision with the least expected loss. These expected losses are the expected loss of choosing that blue is the majority colour, choosing that red is the majority colour and the expected loss of opening the next box. These IO solutions are visualised as decision trees that are dependent on parameters $\alpha$ and $\beta$.

In Chapter \ref{chapter:introduction} we discussed that the box task is an alternative to the beads task to assess a 'jumping to conclusions' (JTC) bias. The parameters $\alpha$ and $\beta$ say something about how reluctant one is to open boxes. As $\beta$ is the loss the participant gets when the test terminates in the limited trial, we might believe that $\alpha$ is the parameter that best describes the tendency to jump to conclusions. We see, for example, that participant 44 opens one box in all the limited trials. She gets a high value of $\ha$ as seen in \eqref{mles_unlim_person44}. Additionally, participant 75 is one of the few to get $\ha \neq 0$ in the limited version, and she opens one box before deciding in all the limited trials. However, as mentioned before, it is hard to differentiate between $\alpha$ and $\beta$ and the loss one gets. Thus, $\beta$ might also say something about the JTC bias. 
%evt 11 og 13?

%In Chapter \ref{chapter:introduction} we discussed that the box task is an alternative to the beads task to assess a 'jumping to conclusions' (JTC) bias. In the unlimited version of the box task we see that most participants have confidence intervals for $\alpha$ that include zero. Having $\alpha=0$ in the unlimited case means that one does not have any loss of opening boxes. We can therefore not conclude that these participants have a JTC bias. However, having confidence intervals for $\alpha$ above zero might indicate that the participant has a JTC bias. These participants chooses majority colour early. We see, for example, in \eqref{mles_unlim_person44} that participant 44 has a high value of $\ha$ and chooses after she has opened one box in the three unlimited trials. She might be an example of someone with a JTC bias, thus $\ha=0.1585$ could be in the range of $\ha$ defining this bias. However, because she has a high value of $\he$, and we use parametric bootstrapping, the length of her confidence interval fro $\alpha$ is zero. This might be the reason that the CI does not include zero, meaning that we should find a more reliant CI before concluding. 
%In the limited version, there are only two participants that have confidence intervals that do not include zero for both $\alpha$ and $\beta$. However, both have CIs of length zero, meaning that we cannot conclude that they have both parameters different from zero. However, we see that participant 75 chooses after one box in all the limited trials. Her MLEs are given in \ref{mles_lim_person75}, where we see that both $\ha$ and $\hb$ are higher than zero. She might have a JTC bias, or she might be afraid of the test terminating. It is hard to differentiate between these, but the MLEs indicate that she is mostly afraid of the test terminating. 
%Individuals 11 and 13 both have $\hb=0$ and high values of $\ha$, and are thus interpreted to be 


%Something about participants with high alpha or beta choosing early. then they might tend to jump to conclusions. i hvilken grad har folk tendensen til JTC? 
%unlim: most participats have CIs that include zero. some that do not. this indicates that they have a loss of choosing early, or that they make hasty desicions. This suggests that these participants might have a JTC bias as discussed in Chapter (introduction). 
%limited: only part 70 and 75 that have intervals for both $\alpha$ ad $\beta$ that do not include zero, but this is mostly because of the length of the intervals being zero. None of the others have both intervals above zero. Many have MLE of $\alpha$ equal zero, but many have $\hb$ different from zero, indicating some loss of opening boxes, but one might simply be afraid of the test termianting instead of having a jtc bias.
%Talk about participants 11 and 13 that have high values of $\ha$ but $\hb=0$. they choose wrong. maybe jtc bias? 


%As discussed in Chapter \ref{chapter:results_cis}, the model is not a good fit for the participants that tend to make choices with high expected losses. When we find the expected loss of opening the next box, this depends on the choices that an Ideal Observer would make in the following steps. As these participants tend to make decisions with high expected losses, these IO decisions are not that relevant for them. Thus, to make the model fit these participants better, we could find another way to determine the expected loss of opening the next box. 

Another adjustment we could do with the model is to remove $\alpha$ in the limited version. As we saw in Chapter \ref{chapter:mles},
for the majority of the individuals, the $\ha$ is zero in the limited case. However, we saw that including $\alpha$ might be helpful in the situations where the participants make decisions with high expected losses. On the other hand, if we find an expected loss of opening the next box that fit those participants better, we might omit $\alpha$ in the model for the limited version.

We have assumed that participants have one value of both $\alpha$ and $\eta$ in the unlimited case and then another in the limited case. Another possibility is that each participant has one single value of $\alpha$ and one single value of $\eta$ that applies to both versions of the box task. We could then combine the two likelihood functions and minimise this one to find these values once instead of twice for each participant. 

The parameter $\alpha$ is assumed to be constant and does not depend on the number of boxes that are opened, $i$. It could be a possibility that $\alpha$ varies with $i$. The same holds for $\beta$. Moreover, in this thesis, it is assumed that $T$, the number of opened boxes when the test terminates, is uniformly distributed. We could also make a model where $T$ varies with $i$. 

In Chapter \ref{chapter:results_cis} we discussed that some participants get confidence intervals with length zero. That means that parametric bootstrapping is not adequate in these situations. Thus, it might be useful to find confidence intervals another way, for example, using nonparametric bootstrapping. 

In this report, we discussed the sensitivity to hyperparameters using a beta prior for $\Theta$ with $\gamma=\kappa=0.5$. We could try with other hyperparameters and see if the results will be even more different. For example, $\gamma=\kappa=0.1$ might be an interesting case as this prior will be even more concentrated to the ends of the parameter space for $\Theta$. 


%To summarise, we have found a model for the decisions participants make in the box task. This model is a good fit for participants who make good choices but not adequate for participants that make decisions with high expected losses.  We also find that the unlimited version is not very sensitive to the changes in the hyperparameters we have done here. In contrast, the parameter estimates in the limited version tend to be smaller with the smaller values of hyperparameters we have used. Additionally, we have defined an Ideal Observer solution that varies with the parameters.  