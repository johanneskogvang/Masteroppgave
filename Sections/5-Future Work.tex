\chapter{Closing Remarks}
In this report we model decisions in the box task using a softmax model with parameters $\alpha$, $\beta$ and $\eta$. The parameter $\alpha$ is a small penalty or loss we get each time we open a box and $\beta$ is the loss we get when the test terminates before we can choose what the majority colour is. The last parameter, $\eta$, says something about how far away the choices that are made are from the decision with the least expected loss.
We have data from 76 participants that have done several trials of the box task, and we find maximum likelihood estimates for each participant and confidence intervals tied to each parameter using parametric bootstrapping. The MLEs are plotted for all participants, and the bootstrap samples and CIs are plotted together for each participants, but only a handful of them are shown here. 
We find that the model is a good fit for participants that make good choices, but worse for the ones that make decisions with high expected losses. Moreover, we find that parametric bootstrapping makes the confidence intervals for participants that make good choices be zero. Thus, that is not an ideal way of finding CIs for these participants.
We also discuss the sensitivity to the hyperparameters in the prior distribution for $\Theta$. The results for the unlimited case of the box task are not very sensitive to changes in the hyperparameters, unlike the results in the limited version, where all parameters seem to have estimates of lower value. 


In addition to this, we develop an Ideal Observer (IO) solution of the box task. This is done by finding the expected losses for the three choices we have each time a box is opened and then always making the decision with the least expected loss. These expected losses are the expected loss of choosing that blue is the majority colour, choosing that red is the majority colour and the expected loss of opening the next box. These IO solutions are visualised as decision trees which are dependent on parameters $\alpha$ and $\beta$.

Something about participants with high alpha or beta choosing early. then they might tend to jump to conclusions. i hvilken grad har folk tendensen til JTC? 
unlim: most participats have CIs that include zero. some that do not. this indicates that they have a loss of choosing early, or that they make hasty desicions. This suggests that these participants might have a JTC bias as discussed in Chapter (introduction). 
limited: only part 70 and 75 that have intervals for both $\alpha$ ad $\beta$ that do not include zero, but this is mostly because of the length of the intervals being zero. None of the others have both intervals above zero. But, looking at the plot of all of the MLEs for $\alpha$ and $\beta$ together, we see that


As discussed in Chapter \ref{chapter:results_cis}, the model is not a good fit for the participants that tend to make choices with high expected losses. When we find the expected loss of opening the next box, this depends on the choices that an Ideal Observer would do in the next steps. As these participants tend to make decisions with high expected losses, these IO decisions are not that relevant for them. Thus, to make the model fit these participants better we could find another way to determine the expected loss of opening the next box. 

Another adjustment we could do with the model is to remove $\alpha$ in the limited version. As we saw in Chapter \ref{chapter:mles},
for the majority of the individuals, the $\ha$ is zero in the limited case. However, we saw that including $\alpha$ might be useful in the situations where the participants make decisions with high expected losses. On the other hand, if we find an expected loss of opening the next box that fit those participants better, we might be able to omit $\alpha$ in the model for the limited version.

We have assumed that the participants have one value of both $\alpha$ and $\eta$ in the unlimited case and then another in the limited case. Another possibility is that each participant have one single value of $\alpha$ and one single value of $\eta$ that applies to both versions of the box task. We could then combine the two likelihood functions and minimise this one to find these values once instead of twice for each participant. 

The parameter $\alpha$ is assumed to be constant and does not depend on the number of boxes that are opened, $i$. It could be a possibility that $\alpha$ varies with $i$. The same holds for $\beta$. Moreover, in this thesis, it is assumed that $T$, the number of boxes that are opened when the test terminates, is uniformly distributed. We could also make a model where $T$ varies with $i$. 

In Chapter \ref{chapter:results_cis} we also discussed that some participants get confidence intervals with length zero. That means that parametric bootstrapping is not adequate in these situations. Thus, it might be useful to find confidence intervals another way, for example using nonparametric bootstrapping. 

In this report we discussed the sensitivity to hyperparameters using a beta prior for $\Theta$ with $\gamma=\kappa=0.5$. We could try with other hyperparameters and see if the results will be even more different. For example $\gamma=\kappa=0.1$ might be an interesting case as this prior will be even more concentrated to the ends of the parameter space for $\Theta$. 


