\chapter{Results}

As we have found the maximum likelihood estimates and their respective confidence intervals, the next step is to show some of these results. However, we will firstly introduce the Ideal Observer solutions for different values of the parameters, which depends on the expected losses. We firstly look at the situations where $\gamma=\kappa=1$, thus that the prior is uniform. 

\section{Uniform Prior}
When we present the results, we start with the results where we have a uniform prior. Recall that this means that it is equally likely that $\theta$ is anywhere between 0 and 1. We start with having a look at the probabilities that either blue or red are the majority colours. 

\subsection{Conditional Probabilities}
We will here have a look at the probability that blue is the dominant colour, and the probability that red is the dominant colour, as shown in \eqref{blue_major_final} and \eqref{redmajor_final}, respectively. These probabilities can be represented for each possible combination of blue and red boxes. Thus, we can find those probabilities for all the trials the participants have done. 

We present the probabilities in Figure \ref{fig:probability_gamma_kappa_1}. In the tree, the top node represents the situation where no boxes are opened. The probability that blue is the majority colour is then equal to the probability of red being the majority colour. This is represented as the proportion of blue and red inside the nodes, which in this case are equal quantities. The circle around the node represent which of the colours that have the highest probability of being in majority. In the top node, the probabilities are equal, thus, this circle is split in two. The node down to the left of the top node represents the situation where one box is opened, and that box is blue. One node down to the left of that one again represents the situation where two boxes are opened and both are blue, and so on. Similarly, the node down to the right of the top node represents the situation where one box is opened, and that box is red and so fourth down the tree. We see that in the last row of the tree, the middle node is missing. This is because the last row represents the situations where twelve boxes are opened, and as there cannot be six of each colour, that node is not included in the tree. In the row above, we see that all the nodes are completely red or completely blue. That means that we can be sure what the majority colour is after eleven boxes are opened. This is because there cannot be six boxes of each of the colours. Then, if there are six of one colour and five of the other, we know that the colour with six boxes is the majority colour. 
\begin{figure}
    \centering
    \scalebox{0.4}{\input{tikz-trees/probability_gamma_kappa_1}}
    \caption[The probabilities of majority colour plotted. $\gamma=\kappa=1$]{This tree represents the probabilities that either red or blue are in majority in the box task with a uniform prior. The top node is the situation where no boxes are opened, where we do not have any information. Hence, the probabilities are equal, and the fraction that is blue inside the node is the same as the blue part. The circle around the nodes represents which colour that is most likely to be in majority, hence the circle is split between red and blue in the top node. The node down to the left is the situation when a blue box is opened, the node down to the right is when one red box is opened, and so forth.}
    \label{fig:probability_gamma_kappa_1}
\end{figure}



When we have these probabilities, the next step is to look at the Ideal Observer solution we have found.




\subsection{An Ideal Observer Solution in the Unlimited case}

As we have all the expected losses for each possible combination of opened boxes, we can present these similarly to the probabilities in Figure \ref{fig:probability_gamma_kappa_1}. 
The expected losses in the unlimited case is as given in \eqref{exp_loss_blue}, \eqref{exp_loss_red} and \eqref{exp_loss_next_box_unlim}. In the unlimited case, we get different solutions for different values of $\alpha$. We have looked at numerous solutions, but only a handful of them will be presented here. 

Recall that an Ideal Observer solution is a solution where the decisions tied to the least expected loss is chosen each time a box is opened. In Figure \ref{fig:unlim_a0.0001_gk1}, we see the expected losses for an individual with $\alpha=0.0001$ visualised. As in Figure \ref{fig:probability_gamma_kappa_1}, the top node represents the situation where no boxes are opened, and the node down to the left represents the situation where one box is opened, and that box is blue and so forth. The circles around the nodes represents the decision with the least expected loss, thus the decision that an Ideal Observer would make. A blue circle indicates that choosing blue as the majority colour has the least expected loss, and a red circle indicates that choosing red has the least expected loss. A green circle means that the the decision to open the next box has the least expected loss. The colours inside the nodes represent what we could call the inverse of the expected losses. That means that if the decision of choosing red as the majority colour has a low expected loss, the amount of red inside that node is big. That means that the colour that represents the Ideal Observer solution is the most prominent in the different nodes. The inverse expected losses are found by adding together all the expected losses and then subtracting the expected loss in question. Late we are normalising these inverse expected losses as they do not sum to one. Let $\tau_i(\delta_i)$ be the inverse expected losses. Then, the inverse expected loss for choosing blue as the majority colour is 
\begin{equation*}
    \tau_i(0) = \sum_{j=0}^2 \EE_{\delta_j}^i(\alpha) - \EE_0^i(\alpha).
\end{equation*}
Similarly, for red it would be
\begin{equation*}
    \tau_i(1) = \sum_{j=0}^2 \EE_{\delta_j}^i(\alpha) - \EE_1^i(\alpha),
\end{equation*}
and for opening the next box it will be
\begin{equation*}
    \tau_i(2) = \sum_{j=0}^2 \EE_{\delta_j}^i(\alpha) - \EE_2^i(\alpha).
\end{equation*}
We need to normalise these. The proportion of blue in each node would then be
\begin{equation*}
    \frac{\tau_i(0)}{\tau_i(0)+\tau_i(1)+\tau_i(2)}.
\end{equation*}
\begin{figure}
    \centering
    \scalebox{0.7}{\input{tikz-trees/unlim_a_0.0001_g_k_1}}
    \caption[IO solution, unlimited. $\alpha=0.0001$, $\gamma=\kappa=1$]{This is a decision tree for the unlimited version of the box task with $\alpha = 0.0001$ and $\gamma=\kappa=1$. Green circles around each node show that opening another box has the least expected loss, and blue and red circles show that the least expected loss is for choosing the majority colour to be blue and red respectively. The colours inside the nodes represent the inverse expected losses. As in Figure \ref{fig:probability_gamma_kappa_1}, the top node is the situation before any boxes are opened, and the node down to the left of the top node is when one blue box is opened and so on.}
    \label{fig:unlim_a0.0001_gk1}
\end{figure}


As we can see in Figures \ref{fig:unlim_a0.0001_gk1}, \ref{fig:unlim_a0.01_gk1} and \ref{fig:unlim_a0.05_gk1}, where the $\alpha$ values are 0.0001, 0.01 and 0.05, respectively, the trees are slimmer for bigger values of $\alpha$. Recall that $\alpha$ is the penalty of opening a box and that the expected loss for choosing to open another box increases with it. Hence the threshold for when that expected loss surpasses the expected loss for choosing either blue or red as majority colour decreases with increasing $\alpha$. Therefore, we make a decision at an earlier point when $\alpha$ is high, which makes the trees slimmer.
\begin{figure}
    \centering
    \begin{minipage}{0.45\textwidth} 
        \centering
        \scalebox{0.5}{\input{tikz-trees/unif_unlim_a0.01v2}}
        \caption[IO solution, unlimited. $\alpha=0.01$,$\gamma=\kappa=1$]{A decision tree for an unlimited trial with $\alpha = 0.01$ and $\gamma=\kappa=1$.
        We can interpret this tree in the same way as Figure \ref{fig:unlim_a0.0001_gk1} where the circles around each node shows which decision the Ideal Observer would do.}
        \label{fig:unlim_a0.01_gk1}
    \end{minipage}\hfill
    \begin{minipage}{0.45\textwidth}
        \centering
        \scalebox{0.5}{\input{tikz-trees/unlim_a0.05_gk1}}
        \caption[IO solution, unlimited. $\alpha=0.05$,$\gamma=\kappa=1$]{A decision tree in the unlimited case with $\alpha = 0.05$ and $\gamma=\kappa=1$ that can be understood in the same way as Figure \ref{fig:unlim_a0.0001_gk1} where the circles around each node shows which decision the Ideal Observer would do.}
        \label{fig:unlim_a0.05_gk1}
    \end{minipage}
\end{figure}



At some point, $\alpha$ could get so big that the ideal observer would decide what the majority colour is after only one box is opened. The expected loss for opening another box is dependent on both $\alpha$ and the expected losses for continuing to open boxes. In contrast, the expected losses for choosing the majority colour are only dependent on the probabilities that one of the colours is in majority. For example, if the first box is red, the probability that red is in majority increases. Therefore, if $\alpha$ is big enough, the expected loss for opening another box could be higher than the probabilities that one of the colours is in majority; thus the ideal observer would decide after one box is opened. This is the situation when $\alpha$ is 0.1 as in Figure \ref{fig:unlim_a0.1_gk1}. Here, the expected loss before any boxes are opened is 0.5 both for choosing blue and red as the majority colour. For the choice of opening a box, the expected loss is 0.308. This is then the choice an ideal observer would make before any boxes are opened. If the box that opens is blue, the expected loss for choosing that blue is the majority colour is 0.208, 0.792 for choosing red, and 0.260 for opening another box. Hence, the ideal observer would decide that blue is the majority colour. This problem is symmetric. That means that if the opened box is red, the expected loss for choosing that red is the majority colour is 0.208, 0.792 for choosing blue and 0.260 for opening another box. In that case, the expected loss is smallest when we choose red as the majority colour.
\begin{figure}
    \centering
    \scalebox{1}{\input{tikz-trees/unlim_a0.1_gk1}}
    \caption[IO solution, unlimited. $\alpha=0.1$,$\gamma=\kappa=1$]{A decision tree for an unlimited trial with $\alpha = 0.1$, that can be interpreted in the same way as Figure \ref{fig:unlim_a0.0001_gk1}}
    \label{fig:unlim_a0.1_gk1}
\end{figure}


As $\alpha$ is the loss we get when we open a box, we can imagine that it also could be zero. In Figure \ref{fig:unlim_a0_gk1} we see the decision tree for $\alpha=0$. When we have six boxes of one of the colours, for example red, the expected loss of choosing red as the majority colour is zero, but so is the expected loss of opening the next box. Thus, and Ideal Observer would choose arbitrarily between those. However, we have decided here that the IO would rather choose majority colour than to open the next box if both of these expected losses are zero, such that one does not open any more boxes than necessary. We see that this tree resembles the tree where $\alpha=0.0001$ as shown in Figure \ref{fig:unlim_a0.0001_gk1}. This indicated that such a small value of $\alpha$ is very close to having $\alpha$ equal to zero. 
\begin{figure}
    \centering
    \scalebox{0.5}{\input{tikz-trees/unif_unlim_a0}}
    \caption[IO solution, unlimited. $\alpha=0$, $\gamma=\kappa=1$]{An Ideal Observer solution of the unlimited version of the box task with $\alpha = 0$ and $\gamma=\kappa=1$. This tree can be interpreted the same way as the tree in Figure \ref{fig:unlim_a0.0001_gk1}.  Here we choose that the IO chooses majority colour if the expected loss of opening the next box is the same as for choosing majority colour. These are both zero if there are six boxes of one of the colour that are displayed, which is the situation in all the nodes that have circles that are split between two colours.}
    \label{fig:unlim_a0_gk1}
\end{figure}

In Figure \ref{fig:IO_trial2_a0.01} we see the Ideal Observer solution in Trial 2 for an individual with $\alpha=0.01$. Trial 2 is as shown in Figure \ref{fig:trial2_order}. We see that the Ideal Observer would choose after six boxes are opened, hence before we can be completely sure that red is the majority colour, but the probability is .... (find this one), so it is very likely that we choose the right colour here. The expected loss of choosing red is then (1-that prob), hence very low. 
We see that if a participant has an $\alpha=0.05$, then an Ideal Observer would choose after two boxes are opened, as shown in Figure \ref{fig:IO_trial2_a0.05}. Then, the penalty for opening the next box is much higher than in Figure \ref{fig:IO_trial2_a0.01}, thus, the IO would choose after only two boxes are opened. 

%\begin{figure}
%    \centering
%    \scalebox{0.5}{\input{tikz-trees/test_of_trial2_unlim_a0.01_gamma_kappa_1}}
%    \caption{Trial 2, IO solution for a participant with $\alpha = 0.01$.}
%    \label{fig:IO_trial2_a0.01}
%\end{figure}
%\begin{figure}
%    \centering
%    \scalebox{0.5}{\input{tikz-trees/trial2_unlim_a0.05_gk1}}
%    \caption{Trial 2, IO solution for a participant with $\alpha = 0.05$.}
%    \label{fig:IO_trial2_a0.05}
%\end{figure}

\begin{figure}
    \centering
    \begin{minipage}{0.45\textwidth}
        \centering
        \scalebox{0.5}{\input{tikz-trees/trial2_unlim_a0.01_gk1}}
        \caption[IO Solution for Trial 2. $\alpha=0.01$,$\gamma=\kappa=1$]{This is an Ideal Observer solution for Trial 2 with $\alpha=0.01$ and $\gamma=\kappa=1$. The tree can be interpreted in the same way as Figure \ref{fig:unlim_a0.0001_gk1}.}
        \label{fig:IO_trial2_a0.01}
    \end{minipage}\hfill
    \begin{minipage}{0.45\textwidth}
        \centering
        \scalebox{0.5}{\input{tikz-trees/trial2_unlim_a0.05_gk1}}
        \caption[IO Solution for Trial 2. $\alpha=0.05$,$\gamma=\kappa=1$]{This is an Ideal Observer solution for Trial 2 with $\alpha=0.05$ and $\gamma=\kappa=1$. The tree can be interpreted in the same way as Figure \ref{fig:unlim_a0.0001_gk1}.}
        \label{fig:IO_trial2_a0.05}
    \end{minipage}
\end{figure}

As we have presented Ideal Observer solutions in the unlimited case for different values of $\alpha$, the next step is to show some of the solutions in the limited case. 

\subsection{An Ideal Observer Solution in the Limited case}
Having the expected losses in the limited case as given in \eqref{exp_loss_blue}, \eqref{exp_loss_red} and \eqref{exp_loss_limited_final}, we can visualise them in the same way as Figure \ref{fig:unlim_a0.0001_gk1}. In the limited trials, we have two parameters, $\alpha$ and $\beta$. Thus, we have solutions with both of these parameters varying. 

In Figures \ref{fig:lim_a0.01_b0.6_gk1} and \ref{fig:lim_a0.01_b0.4_gk1}, we see two solutions, both with $\alpha=0.01$. They have different values of $\beta$, 0.6 and 0.4 respectively. Both trees have the same width, but we see that the tree with the higher $\beta$ value is shorter. Thus, an Ideal Observer with $\beta=0.6$ would open fewer boxes than one with $\beta=0.4$, which is what we would imagine as $\beta$ is the loss of the test terminating. 
\begin{figure}
    \centering
    \begin{minipage}[t]{0.45\textwidth}
        \centering
        \scalebox{0.6}{\input{tikz-trees/lim_a0.01_b0.6_gk1}}
        \caption[IO solution, limited. $\alpha=0.01$, $\beta=0.6$ and $\gamma=\kappa=1$]{A decision tree for an unlimited trial with $\alpha = 0.01$, $\beta=0.6$ and $\gamma=\kappa=1$.
        We can interpret this tree in the same way as Figure \ref{fig:unlim_a0.0001_gk1} where the circles around each node shows which decision the Ideal Observer would do.}
        \label{fig:lim_a0.01_b0.6_gk1}
    \end{minipage}\hfill
    \begin{minipage}[t]{0.45\textwidth}
        \centering
        \scalebox{0.6}{\input{tikz-trees/lim_a0.01_b0.4_gk1}}
        \caption[IO solution, limited. $\alpha=0.01$, $\beta=0.4$ and $\gamma=\kappa=1$]{A decision tree in the limited case with $\alpha = 0.05$, $\beta=0.4$ and $\gamma=\kappa=1$ that can be understood in the same way as Figure \ref{fig:unlim_a0.0001_gk1} where the circles around each node shows which decision the Ideal Observer would do.}
        \label{fig:lim_a0.01_b0.4_gk1}
    \end{minipage}
\end{figure}


The trees in the limited case are in general slimmer than in the unlimited case. This is because of the penalty we get when the test terminates before we have made a decision. The expected losses for opening another box are bigger than in the unlimited case. Hence, in the limited case, these surpass the expected losses of choosing blue or red as majority colour earlier than in the unlimited case. Small values of $\alpha$ and $\beta$ in combination makes the trees wider, as in Figure \ref{fig:lim_a0.0001_b0.2_gk1}.
\begin{figure}
    \centering
    \scalebox{0.8}{\input{tikz-trees/lim_a0.0001_b0.2_gk1}}
    \caption[IO solution, limited. $\alpha=0.0001, \beta=0.2$. $\gamma=\kappa=1$.]{A decision tree for an unlimited trial with $\alpha = 0.01$, $\beta=0.2$ and $\gamma=\kappa=1$.
    We can interpret this tree in the same way as Figure \ref{fig:unlim_a0.0001_gk1} where the circles around each node shows which decision the Ideal Observer would do.}
    \label{fig:lim_a0.0001_b0.2_gk1}
\end{figure}

As in the unlimited case, there are trials where the Ideal Observer solution is to choose the majority colour after one box is opened. This is the case in Figures \ref{fig:lim_a0.05_b0.4_gk1} and \ref{fig:lim_a0.05_b0.6_gk1}. The only thing that has changed from Figure \ref{fig:lim_a0.01_b0.4_gk1} to Figure \ref{fig:lim_a0.05_b0.4_gk1} and from Figure \ref{fig:lim_a0.01_b0.6_gk1} to Figure \ref{fig:lim_a0.05_b0.6_gk1} is the $\alpha$ value, which has increased from 0.01 to 0.05. In the cases with the bigger $\alpha$ values, the expected loss for opening box two is bigger than for choosing the majority colour. This is a result of these expected losses being dependent on the next expected losses, which again depend on the expected losses for opening another box after that and so on. Additionally, these could potentially be big if the amount of red and blue boxes are close to each other, meaning that we for example first open a red box, then a blue, then a red and so forth. 

\begin{figure}
    \centering
    \begin{minipage}[t]{0.45\textwidth} 
        \centering
        \scalebox{0.8}{\input{tikz-trees/lim_a0.05_b0.4_gk1}}
        \caption[IO solution limited. $\alpha=0.05$, $\beta=0.4$ and $\gamma=\kappa=1$.]{A decision tree for a limited trial with $\alpha = 0.05$, $\beta=0.4$ and $\gamma=\kappa=1$. It can bee interpreted as the tree in Figure \ref{fig:unlim_a0.0001_gk1}.}
        \label{fig:lim_a0.05_b0.4_gk1}
    \end{minipage}\hfill
    \begin{minipage}[t]{0.45\textwidth} 
        \centering
        \scalebox{0.8}{\input{tikz-trees/lim_a0.05_b0.4_gk1}}
        \caption[IO solution limited. $\alpha=0.05$, $\beta=0.6$ and $\gamma=\kappa=1$.]{A decision tree for a limited trial with $\alpha = 0.05$, $\beta=0.6$ and $\gamma=\kappa=1$ that can be interpreted in the same way as the tree in Figure \ref{fig:unlim_a0.0001_gk1}).}
        \label{fig:lim_a0.05_b0.6_gk1}
    \end{minipage}
\end{figure}

In Figure \ref{fig:trial8_IO_a0.01_b0.6_gk1}, we see the IO solution for Trial 8 where $\alpha=0.01$ and $\beta=0.6$. We see that an Ideal Observer would choose majority colour after seven boxes are opened, where four are blue and three are red. In Figure \ref{fig:trial8_IO_a0.0001_b0.2_gk1}, we see another IO solution for Trial 8, where $\alpha=0.0001$ and $\beta=0.2$. Here, an Ideal Observer would not choose before the test terminates, and that would be a failed trial. Thus, the Ideal Observer is not perfect, as it is based on expected losses based on the previously opened boxes, and not based on what actually is going to happen.
\begin{figure}
    \centering
     \begin{minipage}[t]{0.45\textwidth}
        \centering
        \scalebox{0.7}{\input{tikz-trees/trial8_lim_a0.01_b0.6_gk1}}
        \caption[IO solution, Trial 8. $\alpha=0.01$, $\beta=0.6$ and $\gamma=\kappa=1$.]{This is an Ideal Observer solution for Trial 8 with $\alpha=0.01$, $\beta=0.6$ and $\gamma=\kappa=1$. The tree can be interpreted in the same way as Figure \ref{fig:unlim_a0.0001_gk1}}
        \label{fig:trial8_IO_a0.01_b0.6_gk1}
     \end{minipage}\hfill
     \begin{minipage}[t]{0.45\textwidth}
        \centering
        \scalebox{0.7}{\input{tikz-trees/trial8_lim_a0.0001_b0.2_gk1}}
        \caption[IO solution, Trial 8. $\alpha=0.0001$, $\beta=0.2$ and $\gamma=\kappa=1$.]{This is an Ideal Observer solution for Trial 8 with $\alpha=0.01$, $\beta=0.2$ and $\gamma=\kappa=1$. The tree can be interpreted in the same way as Figure \ref{fig:unlim_a0.0001_gk1}}
        \label{fig:trial8_IO_a0.0001_b0.2_gk1}
     \end{minipage}
\end{figure}

%\begin{figure}
%    \centering
%    \scalebox{0.8}{\input{tikz-trees/trial8_lim_a0.01_b0.6_gk1}}
%    \caption[IO solution, trial 8. $\alpha=0.01$, $\beta=0.6$ and $\gamma=\kappa=1$.]{IO solution, trial 8. $\alpha=0.01$, $\beta=0.6$ and $\gamma=\kappa=1$.}
    %\label{fig:trial8_IO_a0.01_b0.6_gk1}
%\end{figure}


%\begin{figure}
%    \centering
%    \scalebox{0.8}{\input{tikz-trees/trial8_lim_a0.0001_b0.2_gk1}}
%    \caption[IO solution, trial 8. $\alpha=0.0001$, $\beta=0.2$ and $\gamma=\kappa=1$.]{IO solution, trial 8. $\alpha=0.0001$, $\beta=0.2$ and $\gamma=\kappa=1$.}
    %\label{fig:trial8_IO_a0.0001_b0.2_gk1}
%\end{figure}


We have now presented some of the Ideal Observer solutions we have found, and will continue to present some of the results tied to the decision model we have defined. 





\subsection{Maximum Likelihood Estimates}
\label{chapter:mles}
As we have presented some Ideal Observer solutions, we will now have a look at the parameter estimates we have found for each of the participants. 


\subsubsection{Unlimited}
We start with the unlimited case, where we have the parameters $\alpha$ and $\eta$. For each participant we have found the maximum likelihood estimates of both of these parameters, denoted $\ha$ and $\he$. These are plotted in Figure \ref{fig:plot_all_mles_unlim_zoom0}. We see that there are some outliers of both $\ha$ and $\he$. To get a better picture of the other values, we zoom in closer to zero for both parameters. This is done in Figure \ref{fig:plot_all_mles_unlim_zoom1}, and we have zoomed even more in Figure \ref{fig:plot_all_mles_unlim_zoom2}. Many of the participants have $\hat{\alpha}$ equal to or close to zero, meaning that they have none or little loss of opening boxes. 
(litt usikker på hva jeg skal si om disse plottene?)
\begin{comment}
\begin{figure}
    \centering
    \begin{minipage}{0.45\textwidth}
        \centering
        \includegraphics[scale=0.4]{pictures/plotted_mles_unlim_gk1.png}
        \caption[All MLEs plotted, unlimited]{Caption}
        \label{fig:plot_all_mles_unlim_zoom0}
    \end{minipage}\hfill
    \begin{minipage}{0.45\textwidth}
        \centering
        \includegraphics[scale=0.4]{pictures/plotted_mles_unlim_gk1_zoom1.png}
        \caption[Some MLEs plotted, unlimited]{Caption}
        \label{fig:plot_all_mles_unlim_zoom1}
    \end{minipage}
\end{figure}
\end{comment}


\begin{figure}
    \centering
    \includegraphics[scale=0.7]{pictures/plotted_mles_unlim_gk1.png}
    \caption[MLEs of $\alpha$ and $\eta$, unlimited with $\gamma=\kappa=1$.]{The MLEs for all the participants plotted for the unlimited case of the box task with $\gamma=\kappa=1$.}
    \label{fig:plot_all_mles_unlim_zoom0}
\end{figure}

\begin{figure}
    \centering
    \includegraphics[scale=0.7]{pictures/plotted_mles_unlim_gk1_zoom1.png}
    \caption[MLEs of $\alpha$ and $\eta$, unlimited with $\gamma=\kappa=1$, zoomed.]{The MLEs for all the participants plotted for the unlimited case of the box task with $\gamma=\kappa=1$. Here we have zoomed in closer to zero.}
    \label{fig:plot_all_mles_unlim_zoom1}
\end{figure}

\begin{figure}
    \centering
    \includegraphics[scale=0.7]{pictures/plotted_mles_unlim_gk1_zoom2.png}
    \caption[MLEs of $\alpha$ and $\eta$, unlimited with $\gamma=\kappa=1$, zoomed more]{The MLEs for all the participants plotted for the unlimited case of the box task with $\gamma=\kappa=1$. Here we have zoomed in closer to zero even more than in Figure \ref{fig:plot_all_mles_unlim_zoom2}.}
    \label{fig:plot_all_mles_unlim_zoom2}
\end{figure}

The log likelihood function is almost flat for high values of $\eta$. That means that the stopping criterion for the optimisation algorithm will be met several places for high values of $\eta$. High values indicates that the participant makes the decisions with the least expected losses,  and when the log likelihood function is as flat as it is, we can find some threshold for $\eta$. Then, we can say that if a participant has $\he$ above that threshold, she always makes the decisions with the least expected loss. If we for example have a majority of red boxes, then the expected loss of choosing red as the majority colour is quite low, but so could the expected loss of opening the next box be. Consider, for example, that we have $\EE_0^i(\vp)=0.98$, $\EE_1^i(\vp)=0.02$ and $\EE_2^i(\vp)=0.01$. Then, an Ideal Observer would make the choice of opening the next box, thus, we want the probability that the participant makes the same decision to be quite high. If $\eta=500$, the probability that the participant chooses to open the next box given these expected losses, is above $0.99$. Thus, we set $\eta=500$ as a threshold for when the participant makes the best choices, that is, the Ideal Observer choices. 
 
If we look at the outliers in Figure \ref{fig:plot_all_mles_unlim_zoom0}, we find one participant with a very high value of $\he$ and small value of $\ha$. This is individual 58, who has MLEs
\begin{equation}
\label{mles_unlim_person58}
    \begin{aligned}
        \ha &= 0.0016\\
        \he &= 443422.7.
    \end{aligned}
\end{equation}
In each of the three unlimited trials, this individual chooses the majority colour exactly when there are six of one of the colours, which is when we can be completely sure what the true majority colour is. That means that individual 58 chooses after seven boxes are opened in Trial 2, and she then chooses red. In Trials 3 and 4 she chooses after 10 and 9 boxes are opened, respectively. Thus, she always chooses the decision with the least expected loss, which are the decisions an Ideal Observer would make, and $\he$ is therefore above the threshold value of 500. Individual 58 has $\ha=0.0016$, which is quite small. This might be because she does not open any more boxes than necessary. She might then have a small loss of opening boxes, or some kind of reward of finishing early. This $\ha$ value is so small that it would give an IO solution similar to the one in Figure \ref{fig:unlim_a0.0001_gk1}, such that one always chooses after six boxes of one of the colours have been opened. 

Looking at the other outlier in Figure \ref{fig:plot_all_mles_unlim_zoom0}, which is individual number 13, we see that she has a high value of $\ha$ and a small value of $\he$. In fact, the value of $\eta$ is negative. The values are
\begin{equation}
\label{mles_unlim_person13}
    \begin{aligned}
        \ha &= 4.2224\\
        \he &= -0.4290.
    \end{aligned}
\end{equation}
In Trial 2, she chooses after two boxes are opened, where both boxes are red. In both Trial 3 and Trial 4, she chooses when three boxes are opened, where two of them are blue and one is red. She then chooses red as the majority colour despite the fact that choosing blue as the majority colour has a lower expected loss. Thus, she tends to choose the decisions with higher expected losses, and therefore she has a negative estimate of $\eta$. She also chooses quite early, thus she gets a high estimate of $\alpha$. However, an Ideal Observer with this high value of $\alpha$ would always choose after one box is opened. (hvorfor har jeg da fått en så høy alpha når denne personen velger etter to og tre bokser?)
kanskje fordi det på en mpte er bedre å velge veldig tidlig, før noen boxer er åpnet, derfro så høy alpha? Finn IO for denne perosne!

If we look at one of the individuals that is not an outlier, we find, for example, individual 61. She has
\begin{equation}
\label{mles_unilim_person61}
    \begin{aligned}
        \ha &= 0.0135\\
        \he &= 19.9432.
    \end{aligned}
\end{equation}
In the unlimited trials, she chooses what she thinks is the majority colour after five, six and four boxes are opened. She chooses majority colour before she can be completely sure, and therefore has $\ha>0$. When she chooses however, she chooses the colour with the least expected loss, and thus have a positive $\he$. An IO with the parameters equal to individual 61s estimates would choose after 3, 10 and 9 boxes were opened, thus her decisions do not coincide with the IO decisions, but they are not far away.  
\begin{figure}
    \centering
    \scalebox{0.7}{\input{tikz-trees/unlim_a0.0135_g1_k1}}
    \caption[IO solution of individual number 61 with $\ha=0.0135$ and $\gamma=\kappa=1$]{Here we see and Ideal Observer solution of the box task in the unlimited case for individual number 61 with a uniform prior, such that $\gamma=\kappa=1$. She has $\ha=0.0135$. This tree can be interpreted in the same way as the tree in Figure \ref{fig:unlim_a0.0001_gk1}.}
    \label{fig:IO_sol_individual61}
\end{figure}

Having looked at the MLEs in the unlimited case, we now continue with the limited trials. 


\subsubsection{Limited}
In the limited version, we have three parameters, $\alpha$, $\beta$ and $\eta$, and we have found maximum likelihood estimates for these for all of the 76 participants. The MLEs of $\alpha$ and $\eta$ for all participants are plotted in Figure \ref{fig:mles_limited_alpha_eta}. We see that many of the participants have $\hat{\alpha}=0$. In fact, all participants except two have $\ha=0$. 
We also see that none of the participants are even close to the threshold value of $\eta$, thus none of them are making the choices with the least expected loss each time a box is opened. However, we see that all participants except two have $\he$ higher than zero, meaning that they make choices with low expected losses, but not necessarily the ones with the lowest expected losses.  
\begin{figure}
    \centering
    \includegraphics[scale=0.7]{pictures/plotted_mles_limited_alpha_eta_gk1.png}
    \caption{Mles limited, alpha and eta for all participants. Bytt ut disse plottene så du får på en hatt!!}
    \label{fig:mles_limited_alpha_eta}
\end{figure}
There are two prominent outliers in Figure \ref{fig:mles_limited_alpha_eta}, one with $\hat{\eta}=30.7573$ and another with $\hat{\alpha}=2.2997$. These are participants number 75 and 11, respectively. 

%Talk about the two other plots here, and the zoomed ones. 
In Figure \ref{fig:mles_limited_alpha_beta} we have plotted the MLEs of $\alpha$ and $\beta$ for all participants. Again we see that many participants have $\ha=0$. This might indicate that $\alpha$ is unnecessary to include in the limited version. Both $\alpha$ and $\beta$ are values tied to choosing early or not, thus, it might be enough to only include $\beta$. It is also not obvious how the MLEs are interpreting(?) $\alpha$ and $\beta$. We, for example, see an individual with a high value if $\hat{\beta}$ in Figure \ref{fig:mles_limited_alpha_beta}. This is the same individual that has the high $\hat{\eta}$ value in Figure \ref{fig:mles_limited_alpha_eta}, individual 75. She is also seen in the top right corner of Figure \ref{fig:mles_limited_beta_eta} that displays $\hat{\beta}$ and $\hat{\eta}$ for all participants. Indvividual 75 chooses majoity colour after one box is opened in all of the six limited trials. She has a high value of $\hb$, but $\ha=0$. Thus, her actions are interpreted as her being very afraid of the test terminating, but that she has no loss of opening a new box.


\begin{figure}
    \centering
    \begin{minipage}{0.48\textwidth}
        \centering
        \includegraphics[scale=0.38]{pictures/plotted_mles_limited_alpha_beta_gk1.png}
        \caption{Mles limited, alpha and beta for all participants. Not zoomed}
        \label{fig:mles_limited_alpha_beta}
    \end{minipage}\hfill%\hspace{0.2cm}%\hfill
    \begin{minipage}{0.48\textwidth}
        \centering
        \includegraphics[scale=0.38]{pictures/plotted_mles_limited_alpha_beta_zoomed_gk1.png}
        \caption{Mles limited, alpha and beta for participants, zoomed}
        \label{fig:mles_limited_alpha_beta_zoomed}
    \end{minipage}
\end{figure}
%\begin{figure}
%    \centering
%    \includegraphics[scale=0.7]{pictures/plotted_mles_limited_alpha_beta_gk1.png}
%    \caption{Mles limited, alpha and beta for all participants}
%    \label{fig:mles_limited_alpha_beta}
%\end{figure}
%\begin{figure}
%    \centering
%    \includegraphics[scale=0.7]{pictures/plotted_mles_limited_alpha_beta_zoomed_gk1.png}
%    \caption{Mles limited, alpha and beta for all participants, zoomed}
%    \label{fig:mles_limited_alpha_beta_zoomed}
%\end{figure}

Zooming in more on the plot in Figure \ref{fig:mles_limited_alpha_beta}, like in Figure \ref{fig:mles_limited_alpha_beta_zoomed}, we see that many participants have $\ha=0$, and that $\hb$ typically is between 0.1 and 0.6. In Figure \ref{fig:mles_limited_beta_eta_zoomed} we have zoomed in on the plot in Figure \ref{fig:mles_limited_beta_eta}. Here we see that many of the $\hb$ values are zero, and the ones different from zero is spread around between 0.1 and 0.6 as seen in the $\ha$-$\hb$ plot. 
\begin{figure}
    \centering
    \begin{minipage}{0.48\textwidth}
        \centering
        \includegraphics[scale=0.38]{pictures/plotted_mles_limited_beta_eta_gk1.png}
        \caption{Mles limited, beta and eta for all participants}
        \label{fig:mles_limited_beta_eta}
    \end{minipage}
    \hfill
    \begin{minipage}{0.48\textwidth}
        \centering
        \includegraphics[scale=0.38]{pictures/plotted_mles_limited_beta_eta_zoomed_gk1.png}
        \caption{Mles limited, beta and eta for all participants, zoomed}
        \label{fig:mles_limited_beta_eta_zoomed}
    \end{minipage}
\end{figure}

Having a closer look at individual 75, we see that she has parameter estimates
\begin{equation}
\label{mles_lim_person75}
    \begin{aligned}
        \ha &= 0\\
        \hb &= 40.7103\\
        \he &= 30.7573.
    \end{aligned}
\end{equation}
As said earlier, this participant chooses after one box is opened in all of the six limited trials, hence, the high value of $\hb$. At the same time, individual 75 always chooses the colour of that first box as the majority colour, which is the colour with the least expected loss. The expected loss of opening the next box might be lower than the expected loss of choosing that as the majority colour. However, these expected losses are often close to each other, whereas the expected loss of choosing the other colour as the majority is often further away. Thus, she tends to choose decisions with low expected losses. That is the reason for the high value of $\he$ compared to the other participants. (but why is alpha 0? skla jeg heller snakke her om at det er vanseklig å tolke alpha og beta verdiene? eller er det bedre lenger opp som jeg har gjort nå?). In Figure \ref{fig:IO_sol_person_75_lim} we see the IO solution for a participant with the parameters as individual number 75 has. We see that an IO with these estimates also would choose after one box is opened in all trials. 
\begin{figure}
    \centering
    \scalebox{0.8}{\input{tikz-trees/lim_a0_b40.71_g1_k1}}
    \caption[IO solution for individual number 75, limited]{IO sol for individual 75}
    \label{fig:IO_sol_person_75_lim}
\end{figure}

The other outlier in Figure \ref{fig:mles_limited_alpha_eta} is individual number 11 with 
\begin{equation}
\label{mles_lim_person11}
    \begin{aligned}
        \ha &= 2.2997 \\
        \hb &= 0 \\
        \he &= -0.8474.
    \end{aligned}
\end{equation}
We also see her as an outlier in Figure \ref{fig:mles_limited_alpha_beta} that shows the MLEs of $\alpha$ and $\beta$ in the limited trial. This participant tends to choose the alternatives with the highest expected loss, and thus has a negative value of $\he$. Making those decisions also indicated that one are not afraid to make wrong choices, thus $\hb=0$. (why is $\ha=2.2997$?? velger gaaanske tidlig, typ etter 2-3 bokser.) An individual with these parameter estimates has IO solution as shown in Figure \ref{fig:IO_sol_person_11_lim}. Having such a high value of $\ha$ makes the expected loss of opening the next box higher than the expected loss of choosing the majority colour before any boxes are opened. Recall that the expected loss of for example choosing red as the majority colour is the probability that blue is the majority colour given the colours of the boxes that are opened, as seen in \eqref{exp_loss_red}. When no boxes are opened, this probability is 0.5. The expected loss of opening the first box is $\alpha$ plus the expected loss when the first box is opened as seen in \eqref{exp_loss_limited_final}. Thus, the expected loss of opening the next box is much higher than the expected loss of choosing between blue and red randomly before any boxes are opened. (somethin about alpha being necessary when teh participants chooses badly, bc than beta is zero, but if they still open few boxes they tend to be reluctant to open to many. thus, tehy get a higher alpha value. Also say that these arguments hold for the other person with alpha different from zero.)
og noe om at den andre personen med $\ha \neq 0$ kan tolkes på samme måte. 
\begin{figure}
    \centering
    \scalebox{0.8}{\input{tikz-trees/lim_a2.2997_b0_g1_k1}}
    \caption[IO solution for individual number 11, limited]{IO sol for individual number 11}
    \label{fig:IO_sol_person_11_lim}
\end{figure}




If we look at an individual that has estimates more in the middle of the range, we find, for example, individual 32. She has parameter estimates
\begin{equation}
\label{mles_limited_person32}
    \begin{aligned}
        \ha &= 0.0\\
        \hb &= 0.2377\\
        \he &= 7.4835.
    \end{aligned}
\end{equation}
The IO solution for someone with these parameters is shown in Figure \ref{fig:IO_sol_lim_person32and33}. We see that we wait much longer before choosing here than for individuals 75 and 11. This is because the parameter estimates are much lower, thus the expected loss of opening the next box is lower than in Figures \ref{fig:IO_sol_person_75_lim} and \ref{fig:IO_sol_person_11_lim}.
Individual 32 chooses majority colour in Trial 5 after two boxes are opened, after three are opened in Trial 6, and after four in the last limited trials. An IO with the same parameters would actually end up with Trials 6, 8 and 9 terminating. Thus, one might argue that individual 32 makes better choices than the IO in these trials. 
\begin{figure}
    \centering
    \scalebox{0.7}{\input{tikz-trees/lim_a0.0_b0.2377_g1_k1}}
    \caption{IO sol individuals 32 and 33 (similiar)}
    \label{fig:IO_sol_lim_person32and33}
\end{figure}


We also find that individuals 32 ad 33  have the same values of $\ha$ and $\hb$, but different values of $\he$. Thus, individual 33 has $\ha$ and $\hb$ as in \eqref{mles_limited_person32}, but $\he=10.5099$. Individual 33 opens 3, 3, 4, 5, 4 and 4 boxes in Trials 5, 6, 7, 8, 9 and 10, respectively. Thus, individual 33 opens more boxes that 32, but the choices are closer to the Ideal Observer choices. (men hvorfor har de samme estimater for alpha og beta??)
vanseklig å si noe om fordi vi ikke vet hvordan mleene tolkes?

%for example person 28, $\ha=0$, $\hb=0.3628$ and $\he=10.5168$ ish. 

%\begin{figure}
%    \centering
%   \scalebox{0.7}{\input{tikz-trees/lim_a0.0_b0.3628_g1_k1}}
%    \caption{IO sol individual number 28}
%    \label{fig:IO_sol_lim_person28}
%\end{figure}









\subsection{Confidence Intervals}
We have presented and Ideal Observer solution of the box task and the maximum likelihood estimates for different participants. Now, we will show some of the confidence intervals that we have found. 

\subsubsection{Unlimited}
We start with the CIs for the unlimited case. In Figure \ref{fig:all_cis_alpha_unlim_v2} we see the confidence intervals for $\alpha$. The whole interval for individual number 13 is not included as it is very long. Recall that the MLE of $\alpha$ for person 13 is very large, and we also have a very large value of $\ha_{1000}^{(95)}$. We see that many of the CIs include zero, meaning that many participants might not have that small loss of opening the next box. 
\begin{figure}
    \centering
    \includegraphics[scale=0.37]{pictures/all_cis_unlim_alpha.png}
    \caption[CIs for $\alpha$, unlimited. $\gamma=\kappa=1$]{Here are the confidence intervals for all the participants for $\alpha$ in the unlimited version of the box task. We see that individual number 13 has an interval outside the range of this plot. $\gamma=\kappa=1$.}
    \label{fig:all_cis_alpha_unlim_v2}
\end{figure}



In Figure \ref{fig:all_cis_eta_unlim_v2} we see all the CIs in the unlimited case for $\eta$. We see that some of the participants have the whole CI above 500, the threshold value of $\he$. We can for these participants conclude that they always make decision with small expected losses. We also see that many of the CIs include the threshold value. In Figure \ref{fig:all_cis_eta_unlim_zoomed} we have zoomed in on the CIs, and added a line at zero. Only one CI include zero, the CI for individual number 13. Recall that she has a negative value of $\he$ and a very high $\ha$.
\begin{figure}
    \centering
    \includegraphics[scale=0.38]{pictures/test_cis_eta_unlim.png}
    \caption[CIs for $\eta$, unlimited. $\gamma=\kappa=1$]{Confidence intervals for each participant for $\eta$ in the unlimited version of the box task. $\gamma=\kappa=1$.}
    \label{fig:all_cis_eta_unlim_v2}
\end{figure}

\begin{figure}
    \centering
    \includegraphics[scale=0.38]{pictures/all_cis_unlim_eta_zoomed.png}
    \caption[CIs for $\eta$ zoomed, unlimited. $\gamma=\kappa=1$]{Confidence intervals of $\eta$ for each participant in the unlimited trials of the box task with $\gamma=\kappa=1$, zoomed.}
    \label{fig:all_cis_eta_unlim_zoomed}
\end{figure}


In Chapter \ref{chapter:mles} we talked about individual 61 that has MLEs in the middle of the range of the MLEs. The MLEs are as given in \eqref{mles_unilim_person61}.
We have 1000 bootstrap samples and thus 1000 values of both $\hat{\alpha}$ and $\he$ for this participant. These are plotted in Figure \ref{fig:ci_unlim_person_61}. There, we have also plotted the confidence interval as black lines. We see that most of the bootstrap samples are accumulated in the bottom left corner. Thus, we zoom in there in Figure \ref{fig:ci_unlim_person_61_zoomed}, where we also have plotted the CI. We have that
\begin{equation*}
    [\hat{\alpha}^{*(5)}_{1000},\hat{\alpha}^{*(95)}_{1000}] = [0,0.0362]
\end{equation*}
and
\begin{equation*}
    [\hat{\eta}^{*(5)}_{1000},\hat{\eta}^{*(95)}_{1000}] = [10.0449,110.3661].
\end{equation*}
(jeg vet ikke helt hva jeg skal si om disse CIene??)

\begin{figure}
    \centering
    \begin{minipage}{0.48\textwidth}
        \centering
        \includegraphics[scale=0.37]{pictures/ci_unlim_person61.png}
        \caption[MLEs of bootstrap samples individual number 61, unlimited]{All of the MLEs of the 1000 bootstrap samples plotted for individual number 61 in the unlimited case with $\gamma=\kappa=1$. The confidence intervals for the two parameters are also included.}
        \label{fig:ci_unlim_person_61}
    \end{minipage}\hfill
    \begin{minipage}{0.48\textwidth}
        \centering
        \includegraphics[scale=0.37]{pictures/ci_unlim_person61_zoomed.png}
        \caption[MLEs of bootstrap samples individual number 61, unlimited, zoomed]{Here we have zoomed in on the bootstrap samples and confidence intervals that are plotted in Figure \ref{fig:ci_unlim_person_61}. This is for individual number 61 in the unlimited case with $\gamma=\kappa=1$.}
        \label{fig:ci_unlim_person_61_zoomed}
    \end{minipage}
\end{figure}

In Chapter \ref{chapter:mles} we also talked about individual number 13 that has a high $\ha$, as seen in \eqref{mles_unlim_person13}, compared to the other participants. The 1000 bootstrap samples for participant number 13 are plotted in Figure \ref{fig:ci_unlim_person_13}, and zoomed on the $\he$ axis in Figure \ref{fig:ci_unlim_person_13_zoomed}. The CIs are
\begin{equation*}
    [\hat{\alpha}^{*(5)}_{1000},\hat{\alpha}^{*(95)}_{1000}] = [0,1246.3510]
\end{equation*}
and
\begin{equation*}
    [\hat{\eta}^{*(5)}_{1000},\hat{\eta}^{*(95)}_{1000}] = [-9.9272,18.3986].
\end{equation*}
We see that many of the values of $\ha$ are very high, much higher than the MLE, thus $\hat{\alpha}^{*(95)}_{1000}$ is very high.  It might look like we have found multiple local maximum points in the log likelihood function. Having values of $\ha$ this high indicates that one does not open any boxes before choosing, whereas this participant actually opens two or three boxes before choosing majority colour. Thus, the more relevant data points might be the ones closer to $\ha=0$. 

\begin{figure}
    \centering
    \begin{minipage}{0.48\textwidth}
        \centering
        \includegraphics[scale=0.37]{pictures/ci_unlim_person13.png}
        \caption[MLEs of bootstrap samples individual number 13, unlimited]{All of the MLEs of the 1000 bootstrap samples plotted for individual number 13 in the unlimited case with $\gamma=\kappa=1$. The confidence intervals for the two parameters are also included.}
        \label{fig:ci_unlim_person_13}
    \end{minipage}\hfill
    \begin{minipage}{0.48\textwidth}
        \centering
        \includegraphics[scale=0.37]{pictures/ci_unlim_person13_zoomed.png}
        \caption[MLEs of bootstrap samples individual number 13, unlimited, zoomed]{Here we have zoomed in on the bootstrap samples and confidence intervals that are plotted in Figure \ref{fig:ci_unlim_person_61}. This is for individual number 13 in the unlimited case with $\gamma=\kappa=1$.}
        \label{fig:ci_unlim_person_13_zoomed}
    \end{minipage}
\end{figure}
%commenting out figure where zooming even more for person 13. 
\begin{comment}
\begin{figure}
    \centering
    \includegraphics[scale=0.7]{pictures/ci_unlim_person13_zoomed2.png}
    \caption{ci unlim person 13 zoomed even more. Kanskje ikke zoome såå mye siden mle er på4.2???}
    \label{fig:ci_unlim_person_13_zoomed2}
\end{figure}
\end{comment}

Another outlier we looked at in Chapter \ref{chapter:mles} is individual number 58. The MLEs are 
\begin{equation*}
    \begin{aligned}
        \ha &= 0.0016\\
        \he &= 443422.7.
    \end{aligned}
\end{equation*}
This value of $\he$ is above the threshold value, which makes the probabilities in \eqref{probabilities_bootstrap} be approximate either zero or one. Thus, when we draw decisions based on those probabilities, we will always end up with the same decisions, and those are the decisions that the participant have made. All the simulated decisions are therefore identical to the decisions the participant has made, and the MLEs will be identical. Thus, the length of the two CIs will be zero, and the values will be equal to the MLEs. Hence, the CIs are
\begin{equation*}
    [\hat{\alpha}^{*(5)}_{1000},\hat{\alpha}^{*(95)}_{1000}] = [0.0016,0.0016]
\end{equation*}
and
\begin{equation*}
    [\hat{\eta}^{*(5)}_{1000},\hat{\eta}^{*(95)}_{1000}] = [443422.7,443422.7].
\end{equation*}
We also see in Figure \ref{fig:ci_unlim_person_58} that all the data points are collected at one spot. 
\begin{figure}
    \centering
    \includegraphics[scale=0.7]{pictures/ci_unlim_person58.png}
    \caption[MLEs of bootstrap samples individual number 58, unlimited]{All MLEs of the 1000 bootstrap samples plotted in the unlimited case for individual number 58. We have a uniform prior here, meaning that $\gamma=\kappa=1$. We see that all the MLEs are in one spot, and thus the CI has length zero, with both ends for each parameter being the values of the MLEs.}
    \label{fig:ci_unlim_person_58}
\end{figure}
The situation described here where the probabilities are either zero or one and we therefore get identical bootstrap samples is also the case for the other participants that have CIs of length zero. 

Having shown some of the confidence intervals for the unlimited trials we continue with the limited trials.












\subsubsection{Limited}
We will now have a look at the confidence intervals in the limited case. In Figure \ref{fig:all_cis_alpha_lim} we see the CIs for $\alpha$ for all of the participants except participant 13. In \eqref{mles_lim_person11} we see that she has a very high $\ha$, and thus the values of the CI are high, and the values are outside the range of the plot here. We also see that individual number 11 has a high value of the upper limit of the CI, and that participant number 75 has a CI that is zero in both the lower and upper limit. All of the CIs include zero except for individual number 13. 

\begin{figure}
    \centering
    \includegraphics[scale=0.37]{pictures/all_cis_lim_alpha.png} %wrong name, right plot
    \caption{All cis of $\alpha$ except individual 13 (bc much higher vlaues of ci), unif prior, limited}
    \label{fig:all_cis_alpha_lim}
\end{figure}

In Figure \ref{fig:all_cis_beta} we see all the CIs for $\beta$ plotted. This time it is participant number 75 that is not included because of too high values of the CI.  Participant number 11 has a high upper limit of the CI, just like in the CI for $\alpha$.

\begin{figure}
    \centering
    \includegraphics[scale=0.38]{pictures/all_cis_lim_beta.png}
    \caption{Al cis beta except person 75, (bc too hgh values) and person 11 has the upper limit outside plot. unif prior, limited.}
    \label{fig:all_cis_beta}
\end{figure}

In Figure \ref{fig:all_cis_eta_lim} we see all the CIs of $\eta$. We see here that participant number 75 has a CI of length zero, just as the CI for $\alpha$. In Figure \ref{fig:all_cis_eta_lim_zoomed} we have zoomed in , and see that only two participants have CIs that include zero. This means that most of the participants make reasonable choices, except for these two. 

\begin{figure}
    \centering
    \includegraphics[scale=0.37]{pictures/all_cis_lim_eta.png}
    \caption{All cis eta, uniform prior, limited.}
    \label{fig:all_cis_eta_lim}
\end{figure}

\begin{figure}
    \centering
    \includegraphics[scale=0.37]{pictures/all_cis_lim_eta_zoomed.png}
    \caption{All cis eta, uniform prior, limited, zoomed.}
    \label{fig:all_cis_eta_lim_zoomed}
\end{figure}

If we again have a look at person 32, we find that the CIs are
\begin{equation*}
    [\hat{\alpha}^{*(5)}_{1000},\hat{\alpha}^{*(95)}_{1000}] = [0,0.0818],
\end{equation*}
\begin{equation*}
    [\hb^{*(5)}_{1000},\hb^{*(95)}_{1000}] = [0,0.8690]
\end{equation*}
and
\begin{equation*}
    [\hat{\eta}^{*(5)}_{1000},\hat{\eta}^{*(95)}_{1000}] = [4.4340,60.631].
\end{equation*}
We see the $\ha$ and $\hb$ of the 1000 bootstrap samples and the CIs plotted in Figure \ref{fig:ci_lim_a_b_person_32}. Here we see two outliers in the top right corner, and we therefore zoom in more as in Figure \ref{fig:ci_lim_a_b_person_32_zoomed}. Here we see that many of the bootstrap samples gives $\ha$ and $\hb$ equal to zero. Thus, both of these intervals include zero. 
\begin{figure}
    \centering
    \begin{minipage}{0.48\textwidth}
        \centering
        \includegraphics[scale=0.37]{pictures/ci_lim_a_b_person32.png}
        \caption{ci lim person 32}
        \label{fig:ci_lim_a_b_person_32}
    \end{minipage}\hfill
    \begin{minipage}{0.48\textwidth}
        \centering
        \includegraphics[scale=0.37]{pictures/ci_lim_a_b_person32_zoomed.png}
        \caption{ci lim person 32 zoomed}
        \label{fig:ci_lim_a_b_person_32_zoomed}
    \end{minipage}
\end{figure}
In Figure \ref{fig:ci_lim_a_e_person_32} we see the $\ha$ and $\he$ values plotted and again zoomed in Figure \ref{fig:ci_lim_a_b_person_32_zoomed}. There are some outliers of $\he$ with very high values, but the CI still has a quite small upper limit. 
\begin{figure}
    \centering
    \begin{minipage}{0.48\textwidth}
        \centering
        \includegraphics[scale=0.37]{pictures/ci_lim_a_e_person32.png}
        \caption{ci lim person 32}
        \label{fig:ci_lim_a_e_person_32}
    \end{minipage}\hfill
    \begin{minipage}{0.48\textwidth}
        \centering
        \includegraphics[scale=0.37]{pictures/ci_lim_a_e_person32_zoomed.png}
        \caption{ci lim person 32 zoomed}
        \label{fig:ci_lim_a_e_person_32_zoomed}
    \end{minipage}
\end{figure}


\begin{figure}
    \centering
    \begin{minipage}{0.48\textwidth}
        \centering
        \includegraphics[scale=0.37]{pictures/ci_lim_b_e_person32.png}
        \caption{ci lim person 32}
        \label{fig:ci_lim_b_e_person_32}
    \end{minipage}\hfill
    \begin{minipage}{0.48\textwidth}
        \centering
        \includegraphics[scale=0.37]{pictures/ci_lim_b_e_person32_zoomed.png}
        \caption{ci lim person 32 zoomed}
        \label{fig:ci_lim_b_e_person_32_zoomed}
    \end{minipage}
\end{figure}

Individual number 11 has very high upper limits of both the CI for $\alpha$ and for $\beta$, and she is one of the two that has a CI for $\eta$ that includes zero. The CIs are
\begin{equation*}
    [\hat{\alpha}^{*(5)}_{1000},\hat{\alpha}^{*(95)}_{1000}] = [0,1092.9440],
\end{equation*}
\begin{equation*}
    [\hb^{*(5)}_{1000},\hb^{*(95)}_{1000}] = [0,1023.9252]
\end{equation*}
and
\begin{equation*}
    [\hat{\eta}^{*(5)}_{1000},\hat{\eta}^{*(95)}_{1000}] = [-5.6640,3.2192].
\end{equation*}

In Figures \ref{fig:ci_lim_a_b_person_11} and \ref{fig:ci_lim_a_e_person_11} we see $\ha$ and $\hb$ in addition to $\ha$ and $\he$ plotted for the 1000 bootstrap samples. These plots are zoomed in Figures \ref{fig:ci_lim_a_b_person_11_zoomed} and \ref{fig:ci_lim_a_e_person_11_zoomed}, respectively. We see also here that there are many high values of $\ha$, which again could be local maximum points. We also see quite high values of $\hb$, which might also be because of local maximum points. 
\begin{figure}
    \centering
    \begin{minipage}{0.48\textwidth}
        \centering
        \includegraphics[scale=0.37]{pictures/ci_lim_a_b_person11.png}
        \caption{ci lim person 11}
        \label{fig:ci_lim_a_b_person_11}
    \end{minipage}\hfill
    \begin{minipage}{0.48\textwidth}
        \centering
        \includegraphics[scale=0.37]{pictures/ci_lim_a_b_person11_zoomed.png}
        \caption{ci lim person 11 zoomed}
        \label{fig:ci_lim_a_b_person_11_zoomed}
    \end{minipage}
\end{figure}
\begin{figure}
    \centering
    \begin{minipage}{0.48\textwidth}
        \centering
        \includegraphics[scale=0.37]{pictures/ci_lim_a_e_person11.png}
        \caption{ci lim person 11}
        \label{fig:ci_lim_a_e_person_11}
    \end{minipage}\hfill
    \begin{minipage}{0.48\textwidth}
        \centering
        \includegraphics[scale=0.37]{pictures/ci_lim_a_e_person11_zoomed.png}
        \caption{ci lim person 11 zoomed}
        \label{fig:ci_lim_a_e_person_11_zoomed}
    \end{minipage}
\end{figure}
In Figure \ref{fig:ci_lim_b_e_person_11} we see $\hb$ and $\he$ for the 1000 bootstrap samples plotted, and zoomed in Figure \ref{fig:ci_lim_b_e_person_11_zoomed}.
\begin{figure}
    \centering
    \begin{minipage}{0.48\textwidth}
        \centering
        \includegraphics[scale=0.37]{pictures/ci_lim_b_e_person11.png}
        \caption{ci lim person 11}
        \label{fig:ci_lim_b_e_person_11}
    \end{minipage}\hfill
    \begin{minipage}{0.48\textwidth}
        \centering
        \includegraphics[scale=0.37]{pictures/ci_lim_b_e_person11_zoomed.png}
        \caption{ci lim person 11 zoomed}
        \label{fig:ci_lim_b_e_person_11_zoomed}
    \end{minipage}
\end{figure}

Individual 75 has CIs with length zero. These CIs are
\begin{equation*}
    [\hat{\alpha}^{*(5)}_{1000},\hat{\alpha}^{*(95)}_{1000}] = [0,0],
\end{equation*}
\begin{equation*}
    [\hb^{*(5)}_{1000},\hb^{*(95)}_{1000}] = [79.5448,79.5448]
\end{equation*}
and
\begin{equation*}
    [\hat{\eta}^{*(5)}_{1000},\hat{\eta}^{*(95)}_{1000}] = [45.69408,45.69408].
\end{equation*}
In \eqref{mles_lim_person75} we see that the MLEs for $\beta$ and $\eta$ are smaller than the values for the CIs (jeg aner faktisk ikke hvorfor det er sånn?? man får samme sekvens med valg, men forskjellige mleer, og jeg aner ikke hvorfor. såå hva skal jeg si om dette?)

We have now looked at the results when we have a uniform prior, thus that $\gamma=\kappa =1$. The next we will do is looking at how the results are influenced by a different prior. Thus, we look at the sensitivity of the hyperparameters $\gamma$ and $\kappa$.




\section{Non-uniform Prior?}
note to self: gamma and kappa smaller give more 'weight' to the colour of the boxes that are oepned. hence, we choose earlier because the prob that blue is majority is bigger here than for unif if one blue box is opened. 

Sentence about having seen results for uniform prior. We choose $\gamma=\kappa=0.5$, but there are many different priors one could try. but we believe that gamma and kappa are equal. 

\subsection{Maximum Likelihood Estimators}
sentece about starting with mles, and staritng with unlimted
\subsubsection{Unlimited}
sjekk om det er de samme outliersene som for uniform prior. ja, person 58 og 13. 
\begin{figure}
    \centering
    \begin{minipage}{0.48\textwidth}
        \centering
        \includegraphics[scale=0.37]{pictures/Gamma=kappa=0.5/plotted_mles_unlim_gk0.5.png}
        \caption{Mles unlimited, alpha and eta for all participants. $\gamma=\kappa=0.5$.    Not zoomed}
        \label{fig:gk0.5_mles_unlimited}
    \end{minipage}\hfill%\hspace{0.2cm}%\hfill
    \begin{minipage}{0.48\textwidth}
        \centering
        \includegraphics[scale=0.37]{pictures/Gamma=kappa=0.5/plotted_mles_unlim_gk0.5_zoomed.png}
        \caption{Mles unlimited, alpha and eta for all participants. $\gamma=\kappa=0.5$. Zoomed}
        \label{fig:gk0.5_mles_unlimited_zoomed}
    \end{minipage}
    \vfill
    \begin{minipage}{0.48\textwidth}
        \centering
        \includegraphics[scale=0.37]{pictures/Gamma=kappa=0.5/plotted_mles_unlim_gk0.5_zoomed2.png}
        \caption{Mles unlimited, alpha and eta for all participants. $\gamma=\kappa=0.5$. Zoomed even more.}
        \label{fig:gk0.5_mles_unlimited_zoomed2}
    \end{minipage}
\end{figure}




\subsection{Confidence Intervals}


\subsubsection{Unlimited}
plotting al cis except for perosn 13 with very high value of alpha
\begin{figure}
    \centering
    \includegraphics[scale=0.37]{pictures/Gamma=kappa=0.5/all_cis_alpha_unlim.png}
    \caption{All cis alpha except person 13, $\gamma=\kappa=0.5$.}
    \label{fig:gk0.5_all_cis_alpha_unlim}
\end{figure}

\begin{figure}
    \centering
    \includegraphics[scale=0.38]{pictures/Gamma=kappa=0.5/all_cis_eta_unlim.png}
    \caption{All cis eta except person 58, $\gamma=\kappa=0.5$.}
    \label{fig:gk0.5_all_cis_eta_unlim}
\end{figure}




\begin{figure}
    \centering
    \begin{minipage}{0.48\textwidth}
        \centering
        \includegraphics[scale=0.37]{pictures/Gamma=kappa=0.5/ci_unlim_person61_gk0.5.png}
        \caption{ci unlim person 61, gk0.5}
        \label{fig:ci_unlim_person_61_gk0.5}
    \end{minipage}\hfill
    \begin{minipage}{0.48\textwidth}
        \centering
        \includegraphics[scale=0.37]{pictures/Gamma=kappa=0.5/ci_unlim_person61_gk0.5_zoomed.png}
        \caption{ci unlim person 61 zoomed, gk0.5}
        \label{fig:ci_unlim_person_61_zoomed_gk0.5}
    \end{minipage}
\end{figure}


\subsubsection{Limited}

\begin{figure}
    \centering
    \includegraphics[scale=0.48]{pictures/Gamma=kappa=0.5/all_cis_alpha_lim.png}
    \caption{All cis $\alpha$, limited, $\gamma=\kappa=0.5$.}
    \label{fig:all_cis_alpha_lim_gk0.5}
\end{figure}

\begin{figure}
    \centering
    \includegraphics[scale=0.48]{pictures/Gamma=kappa=0.5/all_cis_beta_lim.png}
    \caption{All cis $\beta$, limited, $\gamma=\kappa=0.5$.}
    \label{fig:all_cis_beta_lim_gk0.5}
\end{figure}

\begin{figure}
    \centering
    \includegraphics[scale=0.48]{pictures/Gamma=kappa=0.5/all_cis_eta_lim.png}
    \caption{All cis $\eta$, limited, $\gamma=\kappa=0.5$.}
    \label{fig:all_cis_eta_lim_gk0.5}
\end{figure}


