\chapter{Results}

As we have found the maximum likelihood estimates and their respective confidence intervals, the next step is to show some of these results. However, we first present the Ideal Observer (IO) solutions for different values of the parameters, which depends on the expected losses. We first look at the situations where $\gamma=\kappa=1$, meaning that the prior distribution for $\Theta$ is uniform. Secondly, we have a look at how sensitive the results are to the hyperparameters $\gamma$ and $\kappa$ in the beta prior we have for $\Theta$.

\section{Uniform Prior for $\Theta$}
When we present the results, we start with the results where we have a uniform prior for $\Theta$. Recall that this means that it is equally likely that $\Theta$ takes any value between zero and one. We start with having a look at the probabilities that either blue or red are the majority colours. 

\subsection{Conditional Probabilities}
We will here have a look at the probability that red is the dominant colour and the probability that blue is the dominant colour, as shown in \eqref{redmajor_final} and \eqref{blue_major_final}, respectively. These probabilities can be represented for each possible combination of red and blue boxes. Thus, we can find those probabilities for all the trials the participants have done. 

We present the probabilities in Figure \ref{fig:probability_gamma_kappa_1} as a tree. The top node represents the situation where no boxes are opened. The probability that blue is the majority colour is then equal to the probability of red being the majority colour. This is represented as the proportion of blue and red inside the nodes, which in the top node are equal quantities. The circle around the node represent which of the colours that have the highest probability of being in the majority. In the top node, the probabilities are equal, and therefore, this circle is split in two. The node down to the left of the top node represents the situation where one box is opened, and that box is blue. One node down to the left of that one represents the situation where two boxes are opened, and both are blue, and so on. Similarly, the node down to the right of the top node represents the situation where one box that is red is opened and so forth down the tree. We see that in the last row of the tree, there is no middle node. This is because the last row represents the situations where twelve boxes are opened, and as there cannot be six of each colour, that node is not included in the tree. In the row above, we see that all the nodes are completely red or completely blue. That means that we can be sure what the majority colour is after eleven boxes are opened. This is because there cannot be six boxes of each of the colours. Then, if there are six of one colour and five of the other, we know that the colour with six boxes is the majority colour. 
\begin{figure}
    \centering
    \scalebox{0.4}{\input{tikz-trees/probability_gamma_kappa_1}}
    \caption[The probabilities of majority colour plotted. $\gamma=\kappa=1$]{A tree representing the probabilities that either red or blue are in the majority in the box task with a uniform prior. The top node is the situation where no boxes are opened, where we do not have any information. Hence, the probabilities are equal. The fraction that is blue inside the node is the same as the blue part. The circle around the nodes represents which colour that is most likely to be in the majority. Hence the circle is split between red and blue in the top node. The node down to the left is the situation when a blue box is opened, the node down to the right is when one red box is opened, and so forth.}
    \label{fig:probability_gamma_kappa_1}
\end{figure}

When we have these probabilities, the next step is to look at the Ideal Observer solution we have found.




\subsection{An Ideal Observer Solution in the Unlimited case}

As we have all the expected losses for each possible combination of opened boxes, we can present these similarly to the probabilities in Figure \ref{fig:probability_gamma_kappa_1}. 
The expected losses in the unlimited case are given in \eqref{exp_loss_blue}, \eqref{exp_loss_red} and \eqref{exp_loss_next_box_unlim}. In the unlimited case, we get different solutions for different values of $\alpha$. We have looked at numerous solutions, but only a handful of them will be presented here. 

Recall that an Ideal Observer solution is the solution we get when the decisions tied to the least expected loss are chosen each time a box is opened. In Figure \ref{fig:unlim_a0.0001_gk1}, we have visualised the expected losses and the decisions an Ideal Observer would do for a participant with $\alpha=0.0001$. As in Figure \ref{fig:probability_gamma_kappa_1}, the top node represents the situation where no boxes are opened, and the node down to the left represents the situation where one box is opened and that box is blue and so forth. The circles around the nodes represent the decision with the least expected loss, thus the decision that an Ideal Observer would make. A blue circle indicates that choosing blue as the majority colour has the least expected loss, and a red circle indicates that choosing red has. A green circle means that the decision to open the next box has the least expected loss. The colours inside the nodes represent what we could call the inverse of the expected losses. That means that if the decision of choosing red as the majority colour has a low expected loss, the amount of red inside that node is big. That means that the colour that represents the Ideal Observer solution is the most prominent in the different nodes. The inverse expected losses are found by adding together all the expected losses and then subtracting the expected loss in question. Later we are normalising these inverse expected losses as they do not sum to one. Let $\tau_i(\delta_i)$ be the inverse expected losses when $i$ boxes are opened. Then, the inverse expected loss for choosing blue as the majority colour is 
\begin{equation*}
    \tau_i(0) = \sum_{j=0}^2 \EE_{\delta_j}^i(\alpha) - \EE_0^i(\alpha).
\end{equation*}
Similarly, for red it would be
\begin{equation*}
    \tau_i(1) = \sum_{j=0}^2 \EE_{\delta_j}^i(\alpha) - \EE_1^i(\alpha),
\end{equation*}
and for opening the next box it will be
\begin{equation*}
    \tau_i(2) = \sum_{j=0}^2 \EE_{\delta_j}^i(\alpha) - \EE_2^i(\alpha).
\end{equation*}
We need to normalise these. The proportion of blue in each node would then be
\begin{equation*}
    \frac{\tau_i(0)}{\tau_i(0)+\tau_i(1)+\tau_i(2)}.
\end{equation*}
\begin{figure}
    \centering
    \scalebox{0.7}{\input{tikz-trees/unlim_a_0.0001_g_k_1}}
    \caption[IO solution, unlimited. $\alpha=0.0001$, $\gamma=\kappa=1$]{A decision tree for the unlimited version of the box task with $\alpha = 0.0001$ and $\gamma=\kappa=1$. Green circles around each node show that opening another box has the least expected loss, and blue and red circles show that the least expected loss is for choosing the majority colour to be blue and red, respectively. The colours inside the nodes represent the inverse expected losses. As in Figure \ref{fig:probability_gamma_kappa_1}, the top node is the situation before any boxes are opened, and the node down to the left of the top node is when one blue box is opened and so on.}
    \label{fig:unlim_a0.0001_gk1}
\end{figure}
This tree stops when there is a red or blue circle around the node. That is when the Ideal Observer would choose what the majority colour is, and since this is the Ideal Observer solution, we stop the decision tree there. 


As we can see in Figures \ref{fig:unlim_a0.0001_gk1}, \ref{fig:unlim_a0.01_gk1} and \ref{fig:unlim_a0.05_gk1}, where the $\alpha$ values are 0.0001, 0.01 and 0.05, respectively, the trees are slimmer for bigger values of $\alpha$. Recall that $\alpha$ is the penalty of opening a box and that the expected loss for choosing to open another box increases with it. Hence the threshold for when that expected loss surpasses the expected loss for choosing either blue or red as the majority colour decreases with increasing $\alpha$. Therefore, we decide at an earlier point when $\alpha$ is high, making the trees slimmer.
\begin{figure}
    \centering
    \begin{minipage}{0.45\textwidth} 
        \centering
        \scalebox{0.5}{\input{tikz-trees/unif_unlim_a0.01v2}}
        \caption[IO solution, unlimited. $\alpha=0.01$,$\gamma=\kappa=1$]{A decision tree for an unlimited trial with $\alpha = 0.01$ and $\gamma=\kappa=1$.
        We can interpret this tree in the same way as Figure \ref{fig:unlim_a0.0001_gk1} where the circles around each node shows which decision the Ideal Observer would do.}
        \label{fig:unlim_a0.01_gk1}
    \end{minipage}\hfill
    \begin{minipage}{0.45\textwidth}
        \centering
        \scalebox{0.5}{\input{tikz-trees/unlim_a0.05_gk1}}
        \caption[IO solution, unlimited. $\alpha=0.05$,$\gamma=\kappa=1$]{A decision tree in the unlimited case with $\alpha = 0.05$ and $\gamma=\kappa=1$ that can be understood in the same way as Figure \ref{fig:unlim_a0.0001_gk1} where the circles around each node shows which decision the Ideal Observer would do.}
        \label{fig:unlim_a0.05_gk1}
    \end{minipage}
\end{figure}



At some point, $\alpha$ could get so big that the ideal observer would decide what the majority colour is after only one box is opened. The expected loss for opening another box is dependent on both $\alpha$ and the expected losses for continuing to open boxes. In contrast, the expected losses for choosing the majority colour depend only on the probabilities that one of the colours is in the majority. For example, if the first box is red, the probability that red is in the majority increases. Therefore, if $\alpha$ is big enough, the expected loss for opening another box could be higher than the probabilities that one of the colours is in the majority; thus, the ideal observer would decide after one box is opened. This is the situation when $\alpha$ is 0.1 as in Figure \ref{fig:unlim_a0.1_gk1}. The expected loss before any boxes are opened is 0.5, both for choosing blue and red as the majority colour. For the choice of opening a box, the expected loss is 0.308. This is then the choice an ideal observer would make before any boxes are opened. If the box that opens is blue, the expected loss for choosing that blue is the majority colour is 0.208, 0.792 for choosing red, and 0.260 for opening another box. Hence, the ideal observer would decide that blue is the majority colour. This problem is symmetric. If the opened box is red, the expected loss for choosing that red is the majority colour is 0.208, 0.792 for choosing blue and 0.260 for opening another box. In that case, the expected loss is smallest when we choose red as the majority colour.
\begin{figure}
    \centering
    \scalebox{1}{\input{tikz-trees/unlim_a0.1_gk1}}
    \caption[IO solution, unlimited. $\alpha=0.1$,$\gamma=\kappa=1$]{A decision tree for an unlimited trial with $\alpha = 0.1$, that can be interpreted in the same way as Figure \ref{fig:unlim_a0.0001_gk1}}
    \label{fig:unlim_a0.1_gk1}
\end{figure}


As $\alpha$ is the loss we get when we open a box, we can imagine that it also could be zero. In Figure \ref{fig:unlim_a0_gk1} we see the decision tree for $\alpha=0$. When we have six boxes of one of the colours, for example, red, the expected loss of choosing red as the majority colour is zero, but so is the expected loss of opening the next box. Thus, an Ideal Observer would choose arbitrarily between those. However, we have decided here that the IO would rather choose the majority colour than open the next box if both of these expected losses are zero, such that one does not open any more boxes than necessary. We see that this tree resembles the tree where $\alpha=0.0001$ as shown in Figure \ref{fig:unlim_a0.0001_gk1}. This indicated that such a small value of $\alpha$ is very close to having $\alpha$ equal to zero. 
\begin{figure}
    \centering
    \scalebox{0.5}{\input{tikz-trees/unif_unlim_a0}}
    \caption[IO solution, unlimited. $\alpha=0$, $\gamma=\kappa=1$]{An Ideal Observer solution of the unlimited version of the box task with $\alpha = 0$ and $\gamma=\kappa=1$. This tree can be interpreted the same way as the tree in Figure \ref{fig:unlim_a0.0001_gk1}.  Here we choose that the IO chooses the majority colour if the expected loss of opening the next box is the same as for choosing the majority colour. These are both zero if there are six boxes of one of the colour that is displayed, which is the situation in all the nodes that have circles that are split between two colours.}
    \label{fig:unlim_a0_gk1}
\end{figure}

In Figure \ref{fig:IO_trial2_a0.01} we see the Ideal Observer solution in Trial 2 for an individual with $\alpha=0.01$. Trial 2 is as shown in Figure \ref{fig:trial2_order}. We see that the Ideal Observer would choose after six boxes are opened, hence before we can be completely sure that red is the majority colour, but the probability is 0.9958, so it is very likely that we choose the right colour here. The expected loss of choosing red is then 0.0042, whereas the expected loss of opening the next box is 0.0134.
We see that if a participant has an $\alpha=0.05$, then an Ideal Observer would choose after two boxes are opened in Trial 2, as shown in Figure \ref{fig:IO_trial2_a0.05}. 
Then, the penalty for opening the next box is much higher than in Figure \ref{fig:IO_trial2_a0.01}. Thus, the IO would choose after only two boxes are opened. 
%\begin{figure}
%    \centering
%    \scalebox{0.5}{\input{tikz-trees/test_of_trial2_unlim_a0.01_gamma_kappa_1}}
%    \caption{Trial 2, IO solution for a participant with $\alpha = 0.01$.}
%    \label{fig:IO_trial2_a0.01}
%\end{figure}
%\begin{figure}
%    \centering
%    \scalebox{0.5}{\input{tikz-trees/trial2_unlim_a0.05_gk1}}
%    \caption{Trial 2, IO solution for a participant with $\alpha = 0.05$.}
%    \label{fig:IO_trial2_a0.05}
%\end{figure}

\begin{figure}
    \centering
    \begin{minipage}{0.45\textwidth}
        \centering
        \scalebox{0.5}{\input{tikz-trees/trial2_unlim_a0.01_gk1}}
        \caption[IO Solution for Trial 2. $\alpha=0.01$,$\gamma=\kappa=1$]{This is an Ideal Observer solution for Trial 2 with $\alpha=0.01$ and $\gamma=\kappa=1$. The tree can be interpreted in the same way as Figure \ref{fig:unlim_a0.0001_gk1}.}
        \label{fig:IO_trial2_a0.01}
    \end{minipage}\hfill
    \begin{minipage}{0.45\textwidth}
        \centering
        \scalebox{0.5}{\input{tikz-trees/trial2_unlim_a0.05_gk1}}
        \caption[IO Solution for Trial 2. $\alpha=0.05$,$\gamma=\kappa=1$]{This is an Ideal Observer solution for Trial 2 with $\alpha=0.05$ and $\gamma=\kappa=1$. The tree can be interpreted in the same way as Figure \ref{fig:unlim_a0.0001_gk1}.}
        \label{fig:IO_trial2_a0.05}
    \end{minipage}
\end{figure}

As we have presented Ideal Observer solutions in the unlimited case for different values of $\alpha$, the next step is to show some of the solutions in the limited case. 




\subsection{An Ideal Observer Solution in the Limited case}
Having the expected losses in the limited case as given in \eqref{exp_loss_blue}, \eqref{exp_loss_red} and \eqref{exp_loss_limited_final}, we can visualise them in the same way as Figure \ref{fig:unlim_a0.0001_gk1}. In the limited trials, we have two parameters, $\alpha$ and $\beta$. Thus, we have solutions with both of these parameters varying. 

In Figures \ref{fig:lim_a0.01_b0.6_gk1} and \ref{fig:lim_a0.01_b0.4_gk1}, we see two solutions, both with $\alpha=0.01$. They have different values of $\beta$, namely $\beta=0.6$ and $0.4$, respectively. Both trees have the same width, but we see that the tree with the higher $\beta$ value is shorter. Thus, an Ideal Observer with $\beta=0.6$ would open fewer boxes than one with $\beta=0.4$, which is what we would imagine as $\beta$ is the loss of the test terminating. 
\begin{figure}
    \centering
    \begin{minipage}[t]{0.45\textwidth}
        \centering
        \scalebox{0.6}{\input{tikz-trees/lim_a0.01_b0.6_gk1}}
        \caption[IO solution, limited. $\alpha=0.01$, $\beta=0.6$ and $\gamma=\kappa=1$]{A decision tree for an unlimited trial with $\alpha = 0.01$, $\beta=0.6$ and $\gamma=\kappa=1$.
        We can interpret this tree in the same way as Figure \ref{fig:unlim_a0.0001_gk1} where the circles around each node shows which decision the Ideal Observer would do.}
        \label{fig:lim_a0.01_b0.6_gk1}
    \end{minipage}\hfill
    \begin{minipage}[t]{0.45\textwidth}
        \centering
        \scalebox{0.6}{\input{tikz-trees/lim_a0.01_b0.4_gk1}}
        \caption[IO solution, limited. $\alpha=0.01$, $\beta=0.4$ and $\gamma=\kappa=1$]{A decision tree in the limited case with $\alpha = 0.05$, $\beta=0.4$ and $\gamma=\kappa=1$ that can be understood in the same way as Figure \ref{fig:unlim_a0.0001_gk1} where the circles around each node shows which decision the Ideal Observer would do.}
        \label{fig:lim_a0.01_b0.4_gk1}
    \end{minipage}
\end{figure}


The trees in the limited case are, in general, slimmer than in the unlimited case. That is because of the penalty we get when the test terminates before we have made a decision. The expected losses for opening another box are bigger than in the unlimited case. Hence, in the limited case, these surpass the expected losses of choosing blue or red as the majority colour earlier than in the unlimited case. Small values of $\alpha$ and $\beta$ in combination makes the trees wider, as in Figure \ref{fig:lim_a0.0001_b0.2_gk1}.
\begin{figure}
    \centering
    \scalebox{0.8}{\input{tikz-trees/lim_a0.0001_b0.2_gk1}}
    \caption[IO solution, limited. $\alpha=0.0001, \beta=0.2$. $\gamma=\kappa=1$.]{A decision tree for an unlimited trial with $\alpha = 0.01$, $\beta=0.2$ and $\gamma=\kappa=1$.
    We can interpret this tree in the same way as Figure \ref{fig:unlim_a0.0001_gk1} where the circles around each node shows which decision the Ideal Observer would do.}
    \label{fig:lim_a0.0001_b0.2_gk1}
\end{figure}

As in the unlimited case, there are trials where the Ideal Observer solution is to choose the majority colour after one box is opened. This is the case in Figures \ref{fig:lim_a0.05_b0.4_gk1} and \ref{fig:lim_a0.05_b0.6_gk1}. The only thing that has changed from Figure \ref{fig:lim_a0.01_b0.4_gk1} to Figure \ref{fig:lim_a0.05_b0.4_gk1} and from Figure \ref{fig:lim_a0.01_b0.6_gk1} to Figure \ref{fig:lim_a0.05_b0.6_gk1} is the value of $\alpha$, which has increased from 0.01 to 0.05. In the cases with the higher values of $\alpha$, the expected loss for opening the second is larger than for choosing the majority colour. That results from these expected losses being dependent on the next expected losses, which again depend on the expected losses for opening another box after that and so on. Additionally, these could potentially be large if the amount of red and blue boxes are close to each other, meaning that we, for example, first open a red box, then a blue, then a red and so forth. 

\begin{figure}
    \centering
    \begin{minipage}[t]{0.45\textwidth} 
        \centering
        \scalebox{0.8}{\input{tikz-trees/lim_a0.05_b0.4_gk1}}
        \caption[IO solution limited. $\alpha=0.05$, $\beta=0.4$ and $\gamma=\kappa=1$.]{A decision tree for a limited trial with $\alpha = 0.05$, $\beta=0.4$ and $\gamma=\kappa=1$. It can bee interpreted as the tree in Figure \ref{fig:unlim_a0.0001_gk1}.}
        \label{fig:lim_a0.05_b0.4_gk1}
    \end{minipage}\hfill
    \begin{minipage}[t]{0.45\textwidth} 
        \centering
        \scalebox{0.8}{\input{tikz-trees/lim_a0.05_b0.4_gk1}}
        \caption[IO solution limited. $\alpha=0.05$, $\beta=0.6$ and $\gamma=\kappa=1$.]{A decision tree for a limited trial with $\alpha = 0.05$, $\beta=0.6$ and $\gamma=\kappa=1$ that can be interpreted in the same way as the tree in Figure \ref{fig:unlim_a0.0001_gk1}).}
        \label{fig:lim_a0.05_b0.6_gk1}
    \end{minipage}
\end{figure}

In Figure \ref{fig:trial8_IO_a0.01_b0.6_gk1}, we see the IO solution for Trial 8 where $\alpha=0.01$ and $\beta=0.6$. We see that an Ideal Observer would choose the majority colour after seven boxes are opened, where four are blue, and three are red. In Figure \ref{fig:trial8_IO_a0.0001_b0.2_gk1}, we see another IO solution for Trial 8, where $\alpha=0.0001$ and $\beta=0.2$. Here, an Ideal Observer would not choose before the test terminates, and that would be a failed trial. Thus, the Ideal Observer is not perfect, as it is based on expected losses based on the previously opened boxes and not based on what is actually going to happen.
\begin{figure}
    \centering
     \begin{minipage}[t]{0.45\textwidth}
        \centering
        \scalebox{0.7}{\input{tikz-trees/trial8_lim_a0.01_b0.6_gk1}}
        \caption[IO solution, Trial 8. $\alpha=0.01$, $\beta=0.6$ and $\gamma=\kappa=1$.]{This is an Ideal Observer solution for Trial 8 with $\alpha=0.01$, $\beta=0.6$ and $\gamma=\kappa=1$. The tree can be interpreted in the same way as Figure \ref{fig:unlim_a0.0001_gk1}}
        \label{fig:trial8_IO_a0.01_b0.6_gk1}
     \end{minipage}\hfill
     \begin{minipage}[t]{0.45\textwidth}
        \centering
        \scalebox{0.7}{\input{tikz-trees/trial8_lim_a0.0001_b0.2_gk1}}
        \caption[IO solution, Trial 8. $\alpha=0.0001$, $\beta=0.2$ and $\gamma=\kappa=1$.]{This is an Ideal Observer solution for Trial 8 with $\alpha=0.01$, $\beta=0.2$ and $\gamma=\kappa=1$. The tree can be interpreted in the same way as Figure \ref{fig:unlim_a0.0001_gk1}}
        \label{fig:trial8_IO_a0.0001_b0.2_gk1}
     \end{minipage}
\end{figure}

%\begin{figure}
%    \centering
%    \scalebox{0.8}{\input{tikz-trees/trial8_lim_a0.01_b0.6_gk1}}
%    \caption[IO solution, trial 8. $\alpha=0.01$, $\beta=0.6$ and $\gamma=\kappa=1$.]{IO solution, trial 8. $\alpha=0.01$, $\beta=0.6$ and $\gamma=\kappa=1$.}
    %\label{fig:trial8_IO_a0.01_b0.6_gk1}
%\end{figure}


%\begin{figure}
%    \centering
%    \scalebox{0.8}{\input{tikz-trees/trial8_lim_a0.0001_b0.2_gk1}}
%    \caption[IO solution, trial 8. $\alpha=0.0001$, $\beta=0.2$ and $\gamma=\kappa=1$.]{IO solution, trial 8. $\alpha=0.0001$, $\beta=0.2$ and $\gamma=\kappa=1$.}
    %\label{fig:trial8_IO_a0.0001_b0.2_gk1}
%\end{figure}


We have now presented some of the Ideal Observer solutions we have found and will continue to present some of the results of the decision model we have defined. 




\subsection{Maximum Likelihood Estimates}
\label{chapter:mles}
As we have presented some Ideal Observer solutions, we will now look at the parameter estimates we have found for each participant. Recall that we find the maximum likelihood estimates (MLEs) by minimising the negative log-likelihood using the L-BFGS-B algorithm as described in Chapter \ref{section:mles}.


\subsubsection{Unlimited}
We start with the unlimited case, where we have the parameters $\alpha$ and $\eta$. For each participant, we have found the maximum likelihood estimates of both of these parameters, denoted $\ha$ and $\he$. These are plotted in Figure \ref{fig:plot_all_mles_unlim_zoom0}. We see one extreme value of each of the estimates, $\ha$ and $\he$. To get a better picture of the values that are not extreme, we zoom in closer to zero for both parameters. This is done in Figure \ref{fig:plot_all_mles_unlim_zoom1}, and we have zoomed even more in Figure \ref{fig:plot_all_mles_unlim_zoom2}. Many of the participants have $\hat{\alpha}$ equal to or close to zero, meaning that they have none or little loss of opening boxes. This is not surprising as the task is neither long nor hard to complete, and we would imagine that many of the participants open many boxes. 



\begin{figure}
    \centering
    \includegraphics[scale=0.7]{pictures/plotted_mles_unlim_gk1.pdf}
    \caption[MLEs of $\alpha$ and $\eta$, unlimited with $\gamma=\kappa=1$.]{The MLEs for all the participants plotted for the unlimited case of the box task with $\gamma=\kappa=1$. $\ha$ is on the horizontal axis and $\he$ on the vertical.}
    \label{fig:plot_all_mles_unlim_zoom0}
\end{figure}

\begin{figure}
    \centering
    \includegraphics[scale=0.7]{pictures/plotted_mles_unlim_gk1_zoom1.pdf}
    \caption[MLEs of $\alpha$ and $\eta$, unlimited with $\gamma=\kappa=1$, zoomed.]{The MLEs for all the participants plotted for the unlimited case of the box task with $\gamma=\kappa=1$. Here we have zoomed in closer to zero.}
    \label{fig:plot_all_mles_unlim_zoom1}
\end{figure}

\begin{figure}
    \centering
    \includegraphics[scale=0.7]{pictures/plotted_mles_unlim_gk1_zoom2.pdf}
    \caption[MLEs of $\alpha$ and $\eta$, unlimited with $\gamma=\kappa=1$, zoomed more]{The MLEs for all the participants plotted for the unlimited case of the box task with $\gamma=\kappa=1$. Here we have zoomed in closer to zero even more than in Figure \ref{fig:plot_all_mles_unlim_zoom2}.}
    \label{fig:plot_all_mles_unlim_zoom2}
\end{figure}

 

Recall that high values of $\eta$ indicate that the participant makes the decisions with the least expected losses, and $\eta$ is infinity when the participant tends to make the decisions with the least excepted loss each time a box is opened.  
The log-likelihood function is almost flat for high values of $\eta$. That means that the stopping criterion for the optimisation algorithm will be met several places for high values of $\eta$. Thus, if the true value of $\he$ is infinity, we could find that it is, for example, 10000 because the stopping criterion is met there. Therefore, we find a threshold for $\eta$ where we can say that all values above that threshold are so high that they go to infinity. Then, we can say that if a participant has $\he$ above that threshold, she always makes the decisions with the least expected loss. This threshold depends on the difference in the two lowest expected losses, but we can, for example, find one for when the difference is $0.01$.  If we, for example, have a majority of red boxes, then the expected loss of choosing red as the majority colour is quite low, but so could the expected loss of opening the next box be. Consider, a situation where we have $\EE_0^i(\vp)=0.98$, $\EE_1^i(\vp)=0.02$ and $\EE_2^i(\vp)=0.01$. Then, the decision to open the next box has the lowest expected loss, but the decision to choose red as the majority colour is not far away. We then want the threshold value of $\eta$ to be so high that the probability that the participant chooses to open the next box is close to one. If $\eta=1000$, the probability that the participant chooses to open the next box given these expected losses, is $0.99995$. Thus, we set $\eta=1000$ as a threshold for when the participant tends to
always makes the choices that have the least expected loss.

 
If we look at the extreme values in Figure \ref{fig:plot_all_mles_unlim_zoom0}, we find one participant with a very high value of $\he$ and small value of $\ha$. This is individual 58, who has MLEs
\begin{equation}
\label{mles_unlim_person58}
    \begin{aligned}
        \ha &= 0.0016,\\
        \he &= 443422.7.
    \end{aligned}
\end{equation}
In each of the three unlimited trials, this individual chooses the majority colour exactly when there are six of one of the colours, which is when we can be completely sure what the true majority colour is. That means that individual 58 chooses after seven boxes are opened in Trial 2, and she then chooses red. In Trials 3 and 4, she chooses after 10 and 9 boxes are opened, respectively. Thus, she always chooses the decision with the least expected loss, which are the decisions an Ideal Observer would make, and $\he$ is therefore above the threshold value of 1000. Individual 58 has $\ha=0.0016$, which is relatively small. That might be because she does not open any more boxes than necessary. She might then have a small loss of opening boxes or some reward of finishing early. This $\ha$ value is so small that it would give an IO solution similar to the one in Figure \ref{fig:unlim_a0.0001_gk1}, such that one always chooses after six boxes of one of the colours have been opened. 



Looking at the other extreme value in Figure \ref{fig:plot_all_mles_unlim_zoom0}, which is individual number 13, we see that she has a high value of $\ha$ and a small value of $\he$. In fact, the value of $\eta$ is negative. The values are
\begin{equation}
\label{mles_unlim_person13}
    \begin{aligned}
        \ha &= 4.2224,\\
        \he &= -0.4290.
    \end{aligned}
\end{equation}
In Trial 2, she chooses after opening two boxes, where both boxes are red. In both Trial 3 and Trial 4, she chooses when three boxes are opened, where two of them are blue, and one is red. She then chooses red as the majority colour despite the fact that choosing blue as the majority colour has a lower expected loss. Thus, she tends to choose decisions with higher expected losses, and therefore has a negative estimate of $\eta$. She also chooses quite early; thus, she gets a high estimate of $\alpha$. However, an Ideal Observer with this high value of $\alpha$ would always choose after one box is opened.


In Figure \ref{fig:plot_all_mles_unlim_zoom1} we see another participant that has a high value of $\ha$. This is participant 44 that has MLEs
\begin{equation}
\label{mles_unlim_person44}
    \begin{aligned}
        \ha &= 0.1585,\\
        \he &= 176.9.
    \end{aligned}
\end{equation}
In all three unlimited trials, she chooses what she thinks is the dominant colour after opening one box. This is why she has a higher value of $\ha$ than most of the other participants. She always chooses the colour of that first box as the majority colour, meaning that if the first box is red, she chooses red as the majority colour. Then the expected loss of choosing red for this participant is 0.2083, whereas the expected loss of opening the next box is 0.3373. Thus, she also chooses the alternative with the least expected loss and gets a pretty high value of $\he$.


If we look at a more typical person, we find, for example, individual number 61. She has
\begin{equation}
\label{mles_unilim_person61}
    \begin{aligned}
        \ha &= 0.0135,\\
        \he &= 19.9432.
    \end{aligned}
\end{equation}
In the unlimited trials, she chooses what she thinks is the majority colour after five, six and four boxes are opened. She chooses the majority colour before she can be entirely sure and therefore has $\ha$ larger than zero. However, when she chooses majority colour, she chooses the colour with the least expected loss and thus has a positive $\he$. An IO with the estimates of individual 61 would choose after 3, 10 and 9 boxes were opened. Thus her decisions do not coincide with the IO decisions, but they are not far away.  
\begin{figure}
    \centering
    \scalebox{0.7}{\input{tikz-trees/unlim_a0.0135_g1_k1}}
    \caption[Ideal Observer solution individual 61, unlimited. $\gamma=\kappa=1$]{An Ideal Observer solution of the box task in the unlimited case for individual number 61 with a uniform prior, such that $\gamma=\kappa=1$. She has $\ha=0.0135$. This tree can be interpreted in the same way as the tree in Figure \ref{fig:unlim_a0.0001_gk1}.}
    \label{fig:IO_sol_individual61}
\end{figure}

Having looked at the MLEs in the unlimited case, we now continue with the limited trials. 


\subsubsection{Limited}
In the limited version, we have three parameters, $\alpha$, $\beta$ and $\eta$, and we have found maximum likelihood estimates for these for all of the 76 participants. The MLEs of $\alpha$ and $\eta$ for all participants are plotted in Figure \ref{fig:mles_limited_alpha_eta}, and we have zoomed in on that plot in Figure \ref{fig:mles_limited_alpha_eta_zoomed}. We see that many of the participants have $\hat{\alpha}=0$. In fact, all participants except four have $\ha=0$. We also see that four of the participants have $\he$ higher than the threshold value of 1000, meaning that they make good choices each time a box is opened. What is not so easy to see is that the two participants with the highest values of $\ha$ have negative values of $\he$. This indicates that they make choices with high expected losses and that they have high costs of opening new boxes. 
\begin{figure}
    \centering
    \begin{minipage}{0.48\textwidth}
        \centering
        \includegraphics[scale=0.36]{pictures/plotted_mles_limited_alpha_eta_gk1.pdf}
        \caption[MLEs of $\alpha$ and $\eta$, limited. $\gamma=\kappa=1$]{Maximum likelihood estimates of $\alpha$ and $\eta$ for all participants in the limited version of the box task. $\gamma=\kappa=1$.}
        \label{fig:mles_limited_alpha_eta}
    \end{minipage}\hfill
    \begin{minipage}{0.48\textwidth}
        \centering
        \includegraphics[scale=0.36]{pictures/plotted_mles_limited_alpha_eta_gk1_zoomed.pdf}
        \caption[MLEs of $\alpha$ and $\eta$ zoomed, limited. $\gamma=\kappa=1$]{MLEs of $\alpha$ and $\eta$ in the limited case. Zoomed in on the plot in Figure \ref{fig:mles_limited_alpha_eta}.}
        \label{fig:mles_limited_alpha_eta_zoomed}
    \end{minipage}
\end{figure}

In Figure \ref{fig:mles_limited_alpha_beta} we have plotted the MLEs of $\alpha$ and $\beta$ for all participants. Again we see that many participants have $\ha=0$. This might indicate that $\alpha$ is unnecessary to include in the limited version. Both $\alpha$ and $\beta$ are values tied to whether we choose the majority colour early or not. Thus, it might be enough only to include $\beta$. It is also not obvious how the MLEs give weight to $\alpha$ compared to $\beta$.
 
\begin{figure}
    \centering
    \includegraphics[scale=0.7]{pictures/plotted_mles_limited_alpha_beta_gk1.pdf}
    \caption[MLEs of $\alpha$ and $\beta$, limited. $\gamma=\kappa=1$]{Maximum likelihood estimates of $\alpha$ and $\beta$ for all participants in the limited version of the box task. $\gamma=\kappa=1$.}
    \label{fig:mles_limited_alpha_beta}
\end{figure}



We have plotted the MLEs of $\beta$ and $\eta$ together in Figure \ref{fig:mles_limited_beta_eta}. Again we see that four of the participants have high values of $\he$. Three of these have values of $\hb$ close to one, which might indicate that they are afraid of the test terminating and thus choose early, but that they choose the colour that is most likely to be in the majority. Zooming in on the plot as in Figure \ref{fig:mles_limited_beta_eta_zoomed}, we see that the majority of the participants have $\he$ values between 10 and 80 and $\hb$ values between zero and 0.7. We also see that some participants have $\hb$ equal to zero. 
\begin{figure}
    \centering
    \begin{minipage}{0.48\textwidth}
        \centering
        \includegraphics[scale=0.36]{pictures/plotted_mles_limited_beta_eta_gk1.pdf}
        \caption[MLEs of $\beta$ and $\eta$, limited. $\gamma=\kappa=1$]{Maximum likelihood estimates of $\beta$ and $\eta$ for all participants in the limited version of the box task. $\gamma=\kappa=1$.}
        \label{fig:mles_limited_beta_eta}
    \end{minipage}
    \hfill
    \begin{minipage}{0.48\textwidth}
        \centering
        \includegraphics[scale=0.36]{pictures/plotted_mles_limited_beta_eta_zoomed_gk1.pdf}
        \caption[MLEs of $\beta$ and $\eta$ zoomed, limited. $\gamma=\kappa=1$]{MLEs of $\beta$ and $\eta$ in the limited case. Zoomed in on the plot in Figure \ref{fig:mles_limited_beta_eta}.}
        \label{fig:mles_limited_beta_eta_zoomed}
    \end{minipage}
\end{figure}


In Figures \ref{fig:mles_limited_alpha_eta} and \ref{fig:mles_limited_beta_eta} we see a participant with a very high value of $\he$. This is individual number 70, and she has  parameter estimates
\begin{equation}
\label{mles_lim_person70}
    \begin{aligned}
        \ha &= 0.0015,\\
        \hb &= 0.7929,\\
        \he &= 23851.9.
    \end{aligned}
\end{equation}
She chooses what she thinks is the majority colour after either two or three boxes are opened in the limited trials. When there are two boxes of the same colour, she chooses that colour as the majority colour. In Figure \ref{fig:IO_sol_person_70} we see the Ideal Observer solution for an individual with the values given in \eqref{mles_lim_person70}. We see that the IO would do the exact same thing as individual number 70 has done, that is, choose when we have two boxes of the same colour, and then choose that colour as the dominant colour. In Trial 5, that is after two boxes are opened as the first two boxes are blue. This is visualised in Figure \ref{fig:IO_sol_perosn_70_trial5}. In Trial 6, both the IO and participant number 70 chooses after three boxes are opened, as seen in Figure \ref{fig:IO_sol_person70_trial6}.
\begin{figure}
    \centering
    \scalebox{0.7}{\input{tikz-trees/lim_a0.0015_b0.7929_g1_k1}}
    \caption[Ideal Observer solution individual 70, limited. $\gamma=\kappa=1$]{An Ideal Observer solution for individual number 70 in the limited version of the box task with $\gamma=\kappa=1$.}
    \label{fig:IO_sol_person_70}
\end{figure}

\begin{figure}
    \centering
    \begin{minipage}{0.48\textwidth}
        \centering
        \scalebox{0.7}{\input{tikz-trees/IO sol person 70, trial 5}}
        \caption[Ideal Observer solution individual 70 in trial 5. $\gamma=\kappa=1$]{An Ideal Observer solution of Trial 5 for individual number 70 where $\gamma=\kappa=1$.}
        \label{fig:IO_sol_perosn_70_trial5}
    \end{minipage}
    \hfill
    \begin{minipage}{0.48\textwidth}
        \centering
        \scalebox{0.7}{\input{tikz-trees/IO_sol_perosn70_trial6}}
        \caption[Ideal Observer solution individual 70 in trial 6. $\gamma=\kappa=1$]{An Ideal Observer solution of Trial 6 for individual number 70 where $\gamma=\kappa=1$.}
        \label{fig:IO_sol_person70_trial6}
    \end{minipage}
\end{figure}

We have two individuals with high values of $\ha$. These are participants 11 and 13. They both have $\hb=0$ and negative values of $\he$. These two individuals can be interpreted the same way. Therefore, we present only the participant with the highest $\ha$ here, participant number 11. Her parameter estimates are
\begin{equation}
\label{mles_lim_person11}
    \begin{aligned}
        \ha &= 1.1798,\\
        \hb &= 0.0,\\
        \he &= -1.9538.
    \end{aligned}
\end{equation}
She chooses after two or three boxes are opened, and she tends to choose the colour in the minority, not majority, out of the opened boxes. That is the reason for $\he$ being negative. $\hb$ is a measure of the loss one gets when the test terminates. If the test terminates, this counts as a failed trial. It also counts as a failed trial if the participant chooses the wrong colour as the majority colour. This individual does not seem to care if she chooses the wrong colour as the majority colour, and we might believe that, in the same way, she does not care whether the test terminates or not. That might be the reason that $\hb$ is zero. However, as she chooses after two and three boxes are opened, this indicates some loss of opening boxes; thus, we get the high value of $\ha$. 
Earlier, we discussed that $\alpha$ might be unnecessary in the limited trials as so many participants have $\ha=0$. However, for individual number 11 and the other participant with the high value of $\ha$, this parameter might be needed to express some penalty of opening boxes as we have that $\hb=0$.
In Figure \ref{fig:IO_sol_person11_limited_gk1} we see that an Ideal Observer with the same estimates as individual number 11 would choose the majority colour before any boxes are opened. The expected loss of choosing the majority colour then is 0.5 as it is the probability that the opposite colour is in the majority. The expected loss of opening the first box is much higher due to the high value of $\ha$. 
\begin{figure}
    \centering
    \scalebox{0.7}{\input{tikz-trees/lim_a1.1798_b0_g1_k1}}
    \caption[Ideal Observer solution individual 11, limited. $\gamma=\kappa=1$]{An Ideal Observer solution for individual number 11 in the limited version of the box task with $\gamma=\kappa=1$.}
    \label{fig:IO_sol_person11_limited_gk1}
\end{figure}


In Figures \ref{fig:mles_limited_alpha_beta} and \ref{fig:mles_limited_beta_eta} we see participant number 75 that has a high value of $\hb$. Her parameter estimates are
\begin{equation}
\label{mles_lim_person75}
    \begin{aligned}
        \ha &= 0.0517,\\
        \hb &= 2.219,\\
        \he &= 70.87.
    \end{aligned}
\end{equation}
This participant chooses after one box is opened in all six limited trials. This is the reason for the high value of $\hb$. At the same time, individual 75 always chooses the colour of that first box as the majority colour, which is the colour with the least expected loss. The expected loss of opening the next box might be lower than the expected loss of choosing that as the majority colour. However, these expected losses are often close to each other, whereas the expected loss of choosing the other colour as the majority is often further away. Thus, she tends to choose decisions with low expected losses, but they might not be the decisions with the lowest expected loss. The value of $\he$ is, therefore, relatively high.
%, but not so high that it reaches the threshold value for $\eta$. However, that threshold value is based on expected losses that differ in value with $0.01$. Here, the expected losses differ more as the parameter estimates are quite high. Thus, the threshold value of $\eta$ might be a lot smaller in this situation. 

If we look at a more typical person, we find, for example, individual number 40. She has parameter estimates
\begin{equation}
\label{mles_lim_person40}
    \begin{aligned}
        \ha &= 0.0,\\
        \hb &= 0.4414,\\
        \he &= 38.00.
    \end{aligned}
\end{equation}
She opens between 2 and 5 boxes in all the trials except Trial 8. In all of these trials, she chooses the most probable colour as the colour that she believes is the majority. Thus, $\he$ is reasonably high. In Trial 8, she opens nine boxes and tries to open the tenth when the test terminates. In that trial, there are never two boxes of the same colour opened after each other, and the probability that one of the colours is the majority colour is quite low. 

As the MLEs are presented for the different parameters, we continue with presenting their respective confidence intervals. 







\subsection{Confidence Intervals}
\label{chapter:results_cis}
We have presented an Ideal Observer solution of the box task and the maximum likelihood estimates for different participants. Now, we will discuss some of the confidence intervals we have found. Recall that these are found by finding the MLEs of 1000 bootstrap samples for each participant and then finding the 5-th and 95-th percentiles, as discussed in Chapter \ref{chapter:CIs_chap3}. 

\subsubsection{Unlimited}
\label{chapter:cis_unlimited}
We start with the confidence intervals in the unlimited case. In Figure \ref{fig:all_cis_alpha_unlim_v2} we see the confidence intervals for $\alpha$. The whole interval for individual number 13 is not included as it is very long. Recall that the MLE of $\alpha$ for person 13 is very large, and we also have a very large value of the upper limit of the CI for $\alpha$, $\ha_{1000}^{(95)}$. We see that many of the CIs include zero, meaning that many participants might not have that small loss of opening the next box. 
\begin{figure}
    \centering
    \includegraphics[scale=0.37]{pictures/all_cis_unlim_alpha.png}
    \caption[CIs for $\alpha$, unlimited. $\gamma=\kappa=1$]{Confidence intervals for all the participants for $\alpha$ in the unlimited version of the box task. We see that individual number 13 has an interval outside the range of this plot. $\gamma=\kappa=1$.}
    \label{fig:all_cis_alpha_unlim_v2}
\end{figure}



In Figure \ref{fig:all_cis_eta_unlim_v2} we see all the CIs in the unlimited case for $\eta$. We see that some of the participants have the whole CI above 1000, the threshold value we defined for $\he$. We can for these participants conclude that they always make decisions with small expected losses. We also see that many of the CIs include the threshold value. In Figure \ref{fig:all_cis_eta_unlim_zoomed} we have zoomed in on the CIs and added a line at zero. Only one CI include zero, the CI for individual number 13. Recall that she has a negative value of $\he$ and a very high $\ha$.
\begin{figure}
    \centering
    \includegraphics[scale=0.38]{pictures/test_cis_eta_unlim.png}
    \caption[CIs for $\eta$, unlimited. $\gamma=\kappa=1$]{Confidence intervals for each participant for $\eta$ in the unlimited version of the box task. $\gamma=\kappa=1$.}
    \label{fig:all_cis_eta_unlim_v2}
\end{figure}

\begin{figure}
    \centering
    \includegraphics[scale=0.38]{pictures/all_cis_unlim_eta_zoomed.png}
    \caption[CIs for $\eta$ zoomed, unlimited. $\gamma=\kappa=1$]{Confidence intervals of $\eta$ for each participant in the unlimited trials of the box task with $\gamma=\kappa=1$, zoomed.}
    \label{fig:all_cis_eta_unlim_zoomed}
\end{figure}


In Chapter \ref{chapter:mles} we discussed individual 61 that is a more typical person. Her MLEs are given in \eqref{mles_unilim_person61}.
We have 1000 bootstrap samples and thus 1000 values of both $\hat{\alpha}$ and $\he$ for this participant. These are plotted in Figure \ref{fig:ci_unlim_person_61}. There, we have also plotted the confidence interval as black lines. We see that most of the bootstrap samples are accumulated in the bottom left corner. Thus, we zoom in there in Figure \ref{fig:ci_unlim_person_61_zoomed}, where we also have plotted the CI. We have that
\begin{equation*}
    [\hat{\alpha}^{*(5)}_{1000},\hat{\alpha}^{*(95)}_{1000}] = [0,0.0362]
\end{equation*}
and
\begin{equation*}
    [\hat{\eta}^{*(5)}_{1000},\hat{\eta}^{*(95)}_{1000}] = [10.0449,110.3661].
\end{equation*}
We see that the confidence interval for $\alpha$ includes zero. Recall that having $\ha=0$ means that one does not have any loss of opening boxes. Additionally, we see that the whole interval for $\eta$ is above zero, which means that individual number 61 makes decisions with low expected losses. However, they might not always be the decisions with the lowest expected loss. 


\begin{figure}
    \centering
    \begin{minipage}{0.48\textwidth}
        \centering
        \includegraphics[scale=0.37]{pictures/ci_unlim_person61.png}
        \caption[MLEs of bootstrap samples individual 61, unlimited]{All of the MLEs of the 1000 bootstrap samples plotted for individual number 61 in the unlimited case with $\gamma=\kappa=1$. The confidence intervals for the two parameters are also included.}
        \label{fig:ci_unlim_person_61}
    \end{minipage}\hfill
    \begin{minipage}{0.48\textwidth}
        \centering
        \includegraphics[scale=0.37]{pictures/ci_unlim_person61_zoomed.png}
        \caption[MLEs of bootstrap samples individual 61, unlimited, zoomed]{Here we have zoomed in on the bootstrap samples and confidence intervals that are plotted in Figure \ref{fig:ci_unlim_person_61}. This is for individual number 61 in the unlimited case with $\gamma=\kappa=1$.}
        \label{fig:ci_unlim_person_61_zoomed}
    \end{minipage}
\end{figure}

In Chapter \ref{chapter:mles} we also discussed individual number 13 that has a high value of $\ha$, as seen in \eqref{mles_unlim_person13}, compared to the other participants. The 1000 bootstrap samples for participant number 13 are plotted in Figure \ref{fig:ci_unlim_person_13}, and zoomed on the $\he$ axis in Figure \ref{fig:ci_unlim_person_13_zoomed}. The CIs are
\begin{equation*}
    [\hat{\alpha}^{*(5)}_{1000},\hat{\alpha}^{*(95)}_{1000}] = [0,1246.3510]
\end{equation*}
and
\begin{equation*}
    [\hat{\eta}^{*(5)}_{1000},\hat{\eta}^{*(95)}_{1000}] = [-9.9272,18.3986].
\end{equation*}
We see that many of the values of $\ha$ are very high, much higher than the MLE; thus, $\hat{\alpha}^{*(95)}_{1000}$ is very high. That means that the estimates for this individual are uncertain. Thus, the model might not be a good fit for this participant and the choices she makes. That might be because the expected loss is based on the next decisions that will be made. We have decided that these decisions are the decisions that an Ideal Observer would make, the decisions with the least expected losses. However, this participant tends to make decisions with high expected losses, meaning that the decisions we include in the model are not so relevant for this individual. Thus, we might conclude that this model is not a great fit for participants that make decisions with high expected losses. 
\begin{figure}
    \centering
    \begin{minipage}{0.48\textwidth}
        \centering
        \includegraphics[scale=0.37]{pictures/ci_unlim_person13.png}
        \caption[MLEs of bootstrap samples individual 13, unlimited]{All of the MLEs of the 1000 bootstrap samples plotted for individual number 13 in the unlimited case with $\gamma=\kappa=1$. The confidence intervals for the two parameters are also included.}
        \label{fig:ci_unlim_person_13}
    \end{minipage}\hfill
    \begin{minipage}{0.48\textwidth}
        \centering
        \includegraphics[scale=0.37]{pictures/ci_unlim_person13_zoomed.png}
        \caption[MLEs of bootstrap samples individual 13, unlimited, zoomed]{Zoomed in on the bootstrap samples and confidence intervals that are plotted in Figure \ref{fig:ci_unlim_person_61}. This is for individual number 13 in the unlimited case with $\gamma=\kappa=1$.}
        \label{fig:ci_unlim_person_13_zoomed}
    \end{minipage}
\end{figure}
 


Another participant with extreme values we looked at in Chapter \ref{chapter:mles} is individual number 58. The MLEs are given in \ref{mles_unlim_person58}. Her value of $\he$ is above the threshold value, which makes the probabilities in \eqref{probabilities_bootstrap} be approximate either zero or one. Thus, when we draw decisions based on those probabilities, we will always end up with the same decisions, and those are the decisions that the participant have made. All the simulated decisions are identical to the decisions the participant has made, and the MLEs will be identical. Thus, the length of the two CIs will be zero, and the values will be equal to the MLEs. Hence, the CIs are
\begin{equation*}
    [\hat{\alpha}^{*(5)}_{1000},\hat{\alpha}^{*(95)}_{1000}] = [0.0016,0.0016]
\end{equation*}
and
\begin{equation*}
    [\hat{\eta}^{*(5)}_{1000},\hat{\eta}^{*(95)}_{1000}] = [443422.7,443422.7].
\end{equation*}
Thus, parametric bootstrapping might not be a satisfactory method to find confidence intervals for the participants that tend to make the  decisions with the least expected loss. 

Having shown some of the confidence intervals for the unlimited trials, we continue with the limited trials.












\subsubsection{Limited}
We will now have a look at the confidence intervals in the limited case. In Figure \ref{fig:all_cis_alpha_lim} we see the CIs for $\alpha$ for all of the participants. Individual number 11 has a much larger upper limit of the CI than the range of the axis here; thus, the CI continues outside the plot. We also see that participant 13 has a higher interval than the other participants. These two are also the individuals with the high values of $\ha$ in Figure \ref{fig:mles_limited_alpha_eta}. We also see that all participants except these two have upper limits smaller than 0.2, meaning that most participants have none or a only a small loss of opening the next box. 
\begin{figure}
    \centering
    \includegraphics[scale=0.37]{pictures/all_cis_lim_alpha.png} %wrong name, right plot
    \caption[CIs for $\alpha$, limited. $\gamma=\kappa=1$]{Confidence intervals for $\alpha$ in the limited case of the box task with $\gamma=\kappa=1$ for each participant. Individual number 11 has a much higher value of the upper limit than the range of the axis here. }
    \label{fig:all_cis_alpha_lim}
\end{figure}

In Figure \ref{fig:all_cis_beta}, we have plotted all the confidence intervals for $\beta$ in the limited case. Again, we see that individual 11 has a large interval that spans beyond the axis. Many of the intervals include zero. Having $\hb=0$ means that one does not feel any loss if the test terminates, although this is defined as a failed trial. We also see that most participants have upper limits below one, meaning that failed trials are not disastrous for most participants. 
\begin{figure}
    \centering
    \includegraphics[scale=0.38]{pictures/all_cis_lim_beta.png}
    \caption[CIs for $\beta$, limited. $\gamma=\kappa=1$]{Confidence intervals for $\beta$ in the limited case of the box task with $\gamma=\kappa=1$ for each participant. As in Figure \ref{fig:all_cis_alpha_lim} participant 11 has a long interval.}
    \label{fig:all_cis_beta}
\end{figure}

We have also plotted the confidence interval for $\eta$ for each participant. This is shown in Figure \ref{fig:all_cis_eta_lim}. The CI for participant 70 is not included here as it is much higher than the axis range. There are only two CIs that include zero, the ones for participants 11 and 13. The rest of the intervals are above zero. That indicates that most participants make choices with little expected loss, whereas individuals 11 and 13 might tend to make decisions with higher expected losses. Many participants have long intervals, which might mean that there is uncertainty tied to their estimates. 
\begin{figure}
    \centering
    \includegraphics[scale=0.37]{pictures/all_cis_lim_eta.png}
    \caption[CIs for $\eta$, limited. $\gamma=\kappa=1$]{Confidence intervals for $\eta$ in the limited case of the box task with $\gamma=\kappa=1$ for each participant. Participant 70 has a too high CI to be included here.}
    \label{fig:all_cis_eta_lim}
\end{figure}


We have three participants where the confidence intervals for all three parameters have length zero. These are individuals 21, 70 and 75. As for individual 75 in the unlimited case, they have very high values of $\he$, which makes the probabilities of each of the decisions as seen in \eqref{probabilities_bootstrap} be approximately zero or approximately one. Thus, all the simulated decisions are the same as the decisions they have made. Therefore, all of the 1000 MLEs are the same, and finding the percentiles gives the same value as the MLEs. It should be noted that individual 75 has $\he=70.87$ as seen in \eqref{mles_lim_person75}, which is far below the threshold value of 1000 that we defined for $\eta$. She has a pretty high estimate of $\beta$, which makes the expected loss of opening the next box relatively high. Therefore, the expected losses differ considerably, and it takes a much lower value of $\he$ for the probabilities in \eqref{probabilities_bootstrap} to be approximately zero or one. Thus, $\he=70.87$ is a high value for individual number 75.


In Figures \ref{fig:all_cis_alpha_lim} and \ref{fig:all_cis_beta} we see that individual 11 has long confidence intervals for $\alpha$ and $\beta$. In Figure \ref{fig:ci_lim_a_b_person_11} we have plotted $\ha$ and $\hb$ of the 1000 bootstrap samples for individual 11 together with the confidence intervals for $\alpha$ and $\beta$.
We have zoomed in on that plot in Figure \ref{fig:ci_lim_a_b_person_11_zoomed}. Additionally, we have plotted the MLEs and the confidence intervals of $\alpha$ and $\eta$ in Figure \ref{fig:ci_lim_a_e_person_11} and zoomed in on that plot in Figure \ref{fig:ci_lim_a_e_person_11_zoomed}.
The confidence intervals are 
\begin{equation*}
    [\hat{\alpha}^{*(5)}_{1000},\hat{\alpha}^{*(95)}_{1000}] = [0.2935,649.1],
\end{equation*}
\begin{equation*}
    [\hb^{*(5)}_{1000},\hb^{*(95)}_{1000}] = [0,16.74]
\end{equation*}
and
\begin{equation*}
    [\hat{\eta}^{*(5)}_{1000},\hat{\eta}^{*(95)}_{1000}] = [-10.45,-0.0013].
\end{equation*}
We see also here that there are many high values of $\ha$, which again give long intervals that indicate an uncertain estimate of $\alpha$. Furthermore, there are some extreme values of $\hb$. The CI has an upper limit at 16.74, which is relatively high compared to the other participants. Thus, there is some uncertainty tied to the estimate of both $\alpha$ and $\beta$ for individual 11, indicating that this model is not a good fit. As discussed for individual 13 in the unlimited version, this might be because we assume Ideal Observer decisions when we find the expected losses of opening the next box. These decisions are not that relevant for participant 11 in the limited case as she tends to make decisions with high expected losses. She chooses the colour in the minority multiple times, meaning that she chooses the decisions with the highest expected loss. 
\begin{figure}
    \centering
    \begin{minipage}{0.48\textwidth}
        \centering
        \includegraphics[scale=0.37]{pictures/ci_lim_a_b_person11.png}
        \caption[MLEs for $\alpha$ and $\beta$ for bootstrap samples individual 11, limited]{All of the MLEs for $\alpha$ and $\beta$ of the 1000 bootstrap samples plotted for individual number 11 in the limited case with $\gamma=\kappa=1$. The confidence intervals for the two parameters are also included.}
        \label{fig:ci_lim_a_b_person_11}
    \end{minipage}\hfill
    \begin{minipage}{0.48\textwidth}
        \centering
        \includegraphics[scale=0.37]{pictures/ci_lim_a_b_person11_zoomed.png}
        \caption[MLEs for $\alpha$ and $\beta$ of bootstrap samples individual 11, unlimited, zoomed]{Here we have zoomed in on the bootstrap samples and confidence intervals that are plotted in Figure \ref{fig:ci_lim_a_b_person_11}. This is for individual number 11 in the limited case with $\gamma=\kappa=1$.}
        \label{fig:ci_lim_a_b_person_11_zoomed}
    \end{minipage}
\end{figure}

\begin{figure}
    \centering
    \begin{minipage}{0.48\textwidth}
        \centering
        \includegraphics[scale=0.37]{pictures/ci_lim_a_e_person11.png}
        \caption[MLEs for $\alpha$ and $\eta$ for bootstrap samples individual 11, limited]{All of the MLEs for $\alpha$ and $\beta$ of the 1000 bootstrap samples plotted for individual number 11 in the limited case with $\gamma=\kappa=1$. The confidence intervals for the two parameters are also included.}
        \label{fig:ci_lim_a_e_person_11}
    \end{minipage}\hfill
    \begin{minipage}{0.48\textwidth}
        \centering
        \includegraphics[scale=0.37]{pictures/ci_lim_a_e_person11_zoomed.png}
        \caption[MLEs for $\alpha$ and $\eta$ of bootstrap samples individual 11, unlimited, zoomed]{Here we have zoomed in on the bootstrap samples and confidence intervals that are plotted in Figure \ref{fig:ci_lim_a_e_person_11}. This is for individual number 11 in the limited case with $\gamma=\kappa=1$.}
        \label{fig:ci_lim_a_e_person_11_zoomed}
    \end{minipage}
\end{figure}

In Figure \ref{fig:ci_lim_b_e_person_11} we see $\hb$ and $\he$ of participant number 11 for the 1000 bootstrap samples plotted, and zoomed in Figure \ref{fig:ci_lim_b_e_person_11_zoomed}. We see that the whole interval for $\eta$ is below zero. This is a strong indicator that individual 11 makes many choices with high expected losses.
\begin{figure}
    \centering
    \begin{minipage}{0.48\textwidth}
        \centering
        \includegraphics[scale=0.37]{pictures/ci_lim_b_e_person11.png}
        \caption[MLEs for $\beta$ and $\eta$ for bootstrap samples individual 11, limited]{All of the MLEs for $\beta$ and $\eta$ of the 1000 bootstrap samples plotted for individual number 11 in the limited case with $\gamma=\kappa=1$. The confidence intervals for the two parameters are also included.}
        \label{fig:ci_lim_b_e_person_11}
    \end{minipage}\hfill
    \begin{minipage}{0.48\textwidth}
        \centering
        \includegraphics[scale=0.37]{pictures/ci_lim_b_e_person11_zoomed.png}
        \caption[MLEs for $\beta$ and $\eta$ of bootstrap samples individual 11, unlimited, zoomed]{Here we have zoomed in on the bootstrap samples and confidence intervals that are plotted in Figure \ref{fig:ci_lim_b_e_person_11}. This is for individual number 11 in the limited case with $\gamma=\kappa=1$.}
        \label{fig:ci_lim_b_e_person_11_zoomed}
    \end{minipage}
\end{figure}

In Figure \ref{fig:ci_lim_a_b_person40}, we have plotted the MLEs of $\alpha$ and $\beta$ for the 1000 bootstrap samples of individual 40 that is a more typical person. We see that $\ha$ and $\hb$ tend to not be zero at the same time, indicating that she gets some loss of opening boxes, but it differs whether the MLE is putting weight on $\alpha$ or $\beta$. In Figure \ref{fig:ci_lim_a_e_person_40} we have plotted all $\ha$ and $\he$ together, and zoomed in on that plot in Figure \ref{fig:ci_lim_a_e_person_40_zoomed}. Here we see that there are many high values of $\he$, and that the confidence interval is long. The values of $\hb$ and $\he$ are plotted in Figure \ref{fig:ci_lim_b_e_person_40} and we have zoomed in Figure \ref{fig:ci_lim_b_e_person_40_zoomed}. 
The confidence intervals are 
\begin{equation*}
    [\hat{\alpha}^{*(5)}_{1000},\hat{\alpha}^{*(95)}_{1000}] = [0,0.0665],
\end{equation*}
\begin{equation*}
    [\hb^{*(5)}_{1000},\hb^{*(95)}_{1000}] = [0,0.6763]
\end{equation*}
and
\begin{equation*}
    [\hat{\eta}^{*(5)}_{1000},\hat{\eta}^{*(95)}_{1000}] = [4.2926,31.287].
\end{equation*}
\begin{figure}
    \centering
    \includegraphics[scale=0.5]{pictures/ci_lim_a_b_person40.png}
    \caption[MLEs for $\alpha$ and $\beta$ for bootstrap samples individual 40, limited]{All of the MLEs for $\alpha$ and $\beta$ of the 1000 bootstrap samples plotted for individual number 40 in the limited case with $\gamma=\kappa=1$. The confidence intervals for the two parameters are also included.}
    \label{fig:ci_lim_a_b_person40}
\end{figure}
\begin{figure}
    \centering
    \begin{minipage}{0.48\textwidth}
        \centering
        \includegraphics[scale=0.37]{pictures/ci_lim_a_e_person40.png}
        \caption[MLEs for $\alpha$ and $\eta$ for bootstrap samples individual 40, limited]{All of the MLEs for $\alpha$ and $\eta$ of the 1000 bootstrap samples plotted for individual number 40 in the limited case with $\gamma=\kappa=1$. The confidence intervals for the two parameters are also included.}
        \label{fig:ci_lim_a_e_person_40}
    \end{minipage}\hfill
    \begin{minipage}{0.48\textwidth}
        \centering
        \includegraphics[scale=0.37]{pictures/ci_lim_a_e_person40_zoomed.png}
        \caption[MLEs for $\alpha$ and $\eta$ of bootstrap samples individual 40, unlimited, zoomed]{Here we have zoomed in on the bootstrap samples and confidence intervals that are plotted in Figure \ref{fig:ci_lim_a_e_person_40}. This is for individual number 11 in the limited case with $\gamma=\kappa=1$.}
        \label{fig:ci_lim_a_e_person_40_zoomed}
    \end{minipage}
\end{figure}
\begin{figure}
    \centering
    \begin{minipage}{0.48\textwidth}
        \centering
        \includegraphics[scale=0.37]{pictures/ci_lim_b_e_person40.png}
        \caption[MLEs for $\beta$ and $\eta$ for bootstrap samples individual 40, limited]{All of the MLEs for $\beta$ and $\eta$ of the 1000 bootstrap samples plotted for individual number 40 in the limited case with $\gamma=\kappa=1$. The confidence intervals for the two parameters are also included.}
        \label{fig:ci_lim_b_e_person_40}
    \end{minipage}\hfill
    \begin{minipage}{0.48\textwidth}
        \centering
        \includegraphics[scale=0.37]{pictures/ci_lim_b_e_person40_zoomed.png}
        \caption[MLEs for $\beta$ and $\eta$ of bootstrap samples individual 40, unlimited, zoomed]{Here we have zoomed in on the bootstrap samples and confidence intervals that are plotted in Figure \ref{fig:ci_lim_b_e_person_40}. This is for individual number 11 in the limited case with $\gamma=\kappa=1$.}
        \label{fig:ci_lim_b_e_person_40_zoomed}
    \end{minipage}
\end{figure}

We have now looked at the results when we have a uniform prior, meaning that $\gamma=\kappa =1$. Next, we look at how the results are influenced when we use a different prior. Thus, we look at the sensitivity of to the hyperparameters $\gamma$ and $\kappa$.





\section{Sensitivity to Hyperparameters}
The results we have discussed so far have all been for a uniform prior of $\Theta$. 
Recall that $\Theta$ is the success probability in the Bernoulli distribution we have for the $X_i$'s, that are the colours of the boxes as described in \eqref{def_of_Xi}, where we later conditioned on there not being six blue and six red boxes. We have a beta prior for $\Theta$ with hyperparameters $\gamma$ and $\kappa$, seen in \eqref{theta_with_beta_prior}. As we can see in Figure \ref{fig:pdf_beta_distr}, having $\gamma=\kappa=1$ is the same as having a uniform prior for $\Theta$. We will now have a look at how the results are affected when we use a different prior. 

As discussed in Chapter \ref{section_notation}, the participants are told that one of the colours always is in the majority. Therefore, one might think that the probability that there are more of one of the colours is higher than the probability that there are six of each of the colours. Thus, we want a prior more like the purple or orange lines in Figure \ref{fig:pdf_beta_distr}. We choose the purple line where $\gamma=\kappa=0.5$.


Having a uniform prior for $\Theta$, we have found MLEs for all the parameters and confidence intervals tied to each of them for each of the participants. We will now do the same with a prior having $\gamma=\kappa=0.5$, and compare the results.
With these values of the hyperparameters, the model put more weight on the colours of the boxes that are opened. 
For example, suppose many of the opened boxes are blue. In that case, the probability that blue is the majority colour is higher in the model with the new prior, resulting in a lower expected loss of choosing blue as the majority colour. 
%If there, for example, are many red boxes that are opened, we have that the probability that red is the majority colour is higher with the non-uniform prior than with the uniform. Thus, the expected loss of red as the majority colour is lower now than with the uniform prior. Then, if one chooses the majority colour early, the expected loss is closer to the lowest expected loss.

\subsection{Unlimited}
When we look at the sensitivity to hyperparameters, we start with the results for the unlimited version.

In Figure \ref{fig:sensitivity_mls_unlim} we have plotted all the MLEs for both priors. The green dots are the MLEs in the model with the uniform prior for $\Theta$, and the orange points are the MLEs in the model with the new prior.
We see that the participants that had extreme values with the uniform prior still have extreme values with the new prior, but the values differ considerably. The highest value of $\he$ is remarkably lower, but it is still above that threshold value we defined for $\eta$. That might be because of the flat log-likelihood function, making the high estimates of $\eta$ somewhat uncertain, as discussed in Chapter \ref{chapter:mles}. Thus, the large change in $\he$ might not be because of the new prior but because of the numerical optimisation. 
If we zoom in on the plot in Figure \ref{fig:sensitivity_mls_unlim}, as we have done in Figure \ref{fig:sensitivity_mls_unlim_zoom1}, we see that the participants with high, but not extreme, values of $\he$ or $\ha$ have shifted their MLEs substantially. 
However, zooming even more, as in Figure \ref{fig:sensitivity_mls_unlim_zoom2}, we see that the MLEs of the participants that do not have extreme or high values are shifted a little, but not considerably, with some exceptions. All participants who did not have $\ha=0$ before have shifted the values of $\ha$ closer to zero with the new prior. 
%That is because, with $\gamma=\kappa=0.5$, the model put more weight on the colours of the boxes that are opened. For example, if many of the opened boxes are blue, then the probability that blue is the majority colour is higher in the model with the new prior. That means that if a participant chooses early, these decisions are more compatible with the model with the lower values of $\gamma$  and $\kappa$. Thus, it is reasonable that we have smaller values of $\ha$ for the new model. 
Most of the participants with $\ha=0$ in the first model have the same in the alternative model. We also see that most of these participants have the same or about the same value of $\he$, perhaps slightly shifted upwards, with the new prior. For the other participants, there are, with some exceptions, no considerable differences in the values of $\he$. Some participants get higher values of $\he$, and others get lower values without any apparent pattern. 
\begin{figure}
    \centering
    \includegraphics[scale=0.7]{pictures/Sensitivity/mles_unlim.pdf}
    \caption[MLEs for prior with $\gamma=\kappa=1$ and $\gamma=\kappa=0.5$, unlimited]{
    Maximum likelihood estimates in the unlimited version of the box task. The green dots represent MLEs where we have a uniform prior for $\Theta$, that is, $\gamma=\kappa=1$. The orange dots are the MLEs where $\gamma=\kappa=0.5$.}
    \label{fig:sensitivity_mls_unlim}
\end{figure}
\begin{figure}
    \centering
    \includegraphics[scale=0.7]{pictures/Sensitivity/mles_unlim_zoom1.pdf}
    \caption[Zoomed in on the MLEs in Figure \ref{fig:sensitivity_mls_unlim}]{MLEs for two different priors in the unlimited case of the box task. This is the same plot as in Figure \ref{fig:sensitivity_mls_unlim} zoomed in.}
    \label{fig:sensitivity_mls_unlim_zoom1}
\end{figure}
\begin{figure}
    \centering
    \includegraphics[scale=0.7]{pictures/Sensitivity/mles_unlim_zoom2.pdf}
    \caption[Zoomed in on the MLEs in Figure \ref{fig:sensitivity_mls_unlim_zoom1}]{The plot of MLEs in Figure \ref{fig:sensitivity_mls_unlim_zoom1} zoomed.}
    \label{fig:sensitivity_mls_unlim_zoom2}
\end{figure}



In Figure \ref{fig:sensitivity_unlim_cis_alpha} we see the confidence intervals for $\alpha$. The green lines are the CIs we found earlier with the uniform prior, and the orange lines represent the CIs when we have the beta prior for $\Theta$ with $\gamma=\kappa=0.5$. As for the MLEs, we see that the confidence intervals are close to each other. Many of the upper limits are slightly shifted to the left, with some exceptions. Again, we see that the interval of individual 13 is long, such that the upper limit is outside of this plot. These upper limits for the old and new prior are quite similar. 
\begin{figure}
    \centering
    \includegraphics[scale=0.37]{pictures/Sensitivity/ci_unlim_alpha.png}
    \caption[CIs for $\alpha$ for all participants with two different priors, unlimited]{
    Confidence intervals for $\alpha$ for all of the 76 participants in the unlimited version of the box task. The green intervals represent the situation where we have a uniform prior for $\Theta$, that is, $\gamma=\kappa=1$. The orange lines are the intervals for a prior where $\gamma=\kappa=0.5$.}
    \label{fig:sensitivity_unlim_cis_alpha}
\end{figure}


Figure \ref{fig:sensitivity_unlim_cis_eta} displays the confidence interval for $\eta$ for each participant. We also have here that the orange lines are the CIs in the case with the new prior and the green lines are the CIs we found in the case with the uniform prior. In Figure \ref{fig:sensitivity_unlim_cis_eta_zoomed} we have zoomed in closer to zero to get a better view of the participants with lower values of $\he$. These confidence intervals differ more than the intervals for $\alpha$. 
Some are shorter than before, and others are longer, without any clear pattern of which intervals that is. Some intervals are slightly shifted to the right, but those are mostly the intervals that are longer than the original intervals. The upper limits are mainly higher than the original, and the new lower limits are often close to the old ones. 
However, these higher upper limits might be because of the flat log-likelihood function as discussed in Chapter \ref{chapter:mles}.
\begin{figure}
    \centering
    \includegraphics[scale=0.36]{pictures/Sensitivity/ci_unlim_eta.png}
    \caption[CIs for $\eta$ for all participants with two different priors, unlimited]{
    Confidence intervals for $\eta$ for all of the 76 participants in the unlimited version of the box task. The green intervals represent the situation where we have a uniform prior for $\Theta$, that is, $\gamma=\kappa=1$. The orange lines are the intervals for a prior where $\gamma=\kappa=0.5$.}
    \label{fig:sensitivity_unlim_cis_eta}
\end{figure}
\begin{figure}
    \centering
    \includegraphics[scale=0.36]{pictures/Sensitivity/ci_unlim_eta_zoomed.png}
    \caption[CIs for $\eta$, unlimited. Zoomed]{The plot in Figure \ref{fig:sensitivity_unlim_cis_eta} zoomed.}
    \label{fig:sensitivity_unlim_cis_eta_zoomed}
\end{figure}

Thus, we see that the unlimited version is not very sensitive when changing the hyperparameters from 1 to 0.5. The MLEs of $\eta$ do not seem to change much, whereas the MLEs of $\alpha$ tend to be a bit smaller. However, there are no large changes in the confidence intervals. 


%the model will now predict that they choose earlier, thus, they are more consisten with the best choices as in general people tend to choose early, at least earlier than an IO (or earlier than they would need to do if they would choose the alternative with the least exp loss). 


%note to self: gamma and kappa smaller give more 'weight' to the colour of the boxes that are oepned. hence, we choose earlier because the prob that blue is majority is bigger here than for unif if one blue box is opened. 

\subsection{Limited}
We continue looking at the estimates and confidence intervals using a new prior for $\Theta$, this time in the limited case of the box task. 

In the previous results, where we have a uniform prior, we have that many values of $\ha$ are zero in the limited version. In Figure \ref{fig:sensitivity_mles_lim_a_e} we have plotted both the new and the old estimates of $\alpha$ and $\eta$. The green dots are the estimates for the model with the uniform prior, and the orange dots are the new estimates with the beta prior having hyperparameters $\gamma=\kappa=0.5$. 
We see that all participants that have $\ha=0$ with the uniform prior, still have that with the non-uniform prior. 
The two participants with high values of $\ha$, individuals 11 and 13, get even higher values of $\ha$. Their values of $\he$ are slightly higher with the new prior. 
There are three participants that had values of $\ha$ slightly higher than zero that with the new prior have $\ha=0$. 
Most participants get a lower value of $\he$ with the non-uniform prior. The majority of the values are only shifted a little downwards, except some that get a huge difference in the values. These are participants that have huge values of $\he$ from before with the uniform prior. We discussed earlier that the log-likelihood function is flat for high values of $\eta$ and that the stopping criterion in the optimisation can be met several places when $\eta$ is high. That might be the reason for the large change in the value of $\he$. 
A few participants get higher values of $\he$, but if the values are higher it is not by a lot. 
\begin{figure}
    \centering
    \includegraphics[scale=0.7]{pictures/Sensitivity/mles_lim_a_e.pdf}
    \caption[MLEs of $\alpha$ and $\eta$ for prior with $\gamma=\kappa=1$ and $\gamma=\kappa=0.5$, limited]{
    Maximum likelihood estimates of $\alpha$ and $\eta$ in the limited version of the box task. The green dots represent MLEs where we have a uniform prior for $\Theta$, that is, $\gamma=\kappa=1$. The orange dots are the MLEs where $\gamma=\kappa=0.5$.}
    \label{fig:sensitivity_mles_lim_a_e}
\end{figure}

We have plotted the MLEs for $\alpha$ and $\beta$ together in Figure \ref{fig:sensitivity_mles_lim_a_b}. We see also here participants 11 and 13 with the high values of $\ha$. Their values of $\hb$ were zero with the uniform prior and stay zero with the new prior. We also see one participant that increases the value of $\hb$ considerably. That is individual number 75. Recall that this participant has confidence intervals of length zero because of the high value of $\he$. Her MLEs for the situation where we have a uniform prior are given in \eqref{mles_lim_person75}. The log-likelihood function is also quite flat for big values of $\alpha$ or $\beta$, meaning that the same argument for high differences in $\he$ holds for $\hb$ as well.  
\begin{figure}
    \centering
    \includegraphics[scale=0.7]{pictures/Sensitivity/mles_lim_a_b.pdf}
    \caption[MLEs of $\alpha$ and $\beta$ for prior with $\gamma=\kappa=1$ and $\gamma=\kappa=0.5$, limited]{
    Maximum likelihood estimates of $\alpha$ and $\beta$ in the limited version of the box task. The green dots represent MLEs where we have a uniform prior for $\Theta$, that is, $\gamma=\kappa=1$. The orange dots are the MLEs where $\gamma=\kappa=0.5$.}
    \label{fig:sensitivity_mles_lim_a_b}
\end{figure}

The plot for $\hb$ and $\he$ together is shown in Figure \ref{fig:sensitivity_mles_lim_b_e}. Here, we again see participant 75 that gets a much higher $\hb$. She gets a smaller value of $\he$, but again, that might be because of the flat log-likelihood function. 
\begin{figure}
    \centering
    \includegraphics[scale=0.7]{pictures/Sensitivity/mles_lim_b_e.pdf}
    \caption[MLEs of $\beta$ and $\eta$ for prior with $\gamma=\kappa=1$ and $\gamma=\kappa=0.5$, limited]{
    Maximum likelihood estimates of $\beta$ and $\eta$ in the limited version of the box task. The green dots represent MLEs where we have a uniform prior for $\Theta$, that is, $\gamma=\kappa=1$. The orange dots are the MLEs where $\gamma=\kappa=0.5$.}
    \label{fig:sensitivity_mles_lim_b_e}
\end{figure}

If we zoom in on the plot in Figure \ref{fig:sensitivity_mles_lim_b_e}, as in Figure \ref{fig:sensitivity_mles_lim_b_e_zoomed}, we see that most participants, with some exceptions, get smaller values of both $\hb$ and $\he$. 
All the participants that had $\hb=0$ with the uniform prior still have that with the non-uniform prior. 
%More participants have $\hb=0$ now than with the uniform prior. 
All the other participants, except participant 75, get slightly smaller values of $\hb$, resulting in more participants getting $\hb=0$ with the new prior.
%If there, for example, are many red boxes that are opened, we have that the probability that red is the majority colour is higher with the non-uniform prior than with the uniform. Thus, the expected loss of red as the majority colour is lower now than with the uniform prior. Then, if one chooses the majority colour early, the expected loss is closer to the lowest expected loss. Therefore, one is not to the same degree interpreted as being afraid of the test terminating when choosing early. Thus, many of the values of $\hb$ are lower here. 
%Many of the participants chooses what they think is the majority colour early, meaning that they choose when few boxes are opened. With the new prior giving lower expected losses of choosing majority colour early, that means that the participants make decisions closer to the decision that has the lowest expected loss. Thus, we get higher values of $\he$ if we use the new prior with $\gamma=\kappa=0.5$.
\begin{figure}
    \centering
    \includegraphics[scale=0.7]{pictures/Sensitivity/mles_lim_b_e_zoomed.pdf}
    \caption[MLEs of $\beta$ and $\eta$, zoomed]{The plot in Figure \ref{fig:sensitivity_mles_lim_b_e}, zoomed.}
    \label{fig:sensitivity_mles_lim_b_e_zoomed}
\end{figure}

In general, we get smaller values of all of the estimates of all three parameters, with some exceptions, with the non-uniform prior for $\Theta$.

In Figure \ref{fig:sensitivity_ci_lim_alpha_zoom1}, we have plotted all the confidence intervals for $\alpha$ in both the case where we have a uniform prior and the case where we have a non-uniform prior. As before, the green lines are the intervals when we have the uniform prior, and the orange lines when the prior is non-uniform. We see that the upper limit of the CI for participant 11 is higher than the upper limit here. A plot including the whole interval for this person can be found in Appendix \ref{appendix_CIs}. Here we have also included a plot that zooms in on the x-axis in Figure \ref{fig:sensitivity_ci_lim_alpha_zoom1}.
We see that many of the intervals are pretty similar for both priors. However, we see that participants 6, 21 and 70, who had intervals of length zero, actually get an interval with the new prior. That is because their new estimates of $\eta$ are much lower; thus, the probabilities in \eqref{probabilities_bootstrap} are not zero or one anymore. In contrast, we have participant 75 that still has length zero of the confidence interval.
%47.98, 97.79 and 36.17 are the new values of $\he$. old values are 4183.0, 6253.5 and 23851.9. 
\begin{figure}
    \centering
    \includegraphics[scale=0.38]{pictures/Sensitivity/ci_lim_alpha_zoom1.png}
    \caption[CIs for $\alpha$ for all participants with two different priors, limited]{Confidence intervals for $\alpha$ for all of the 76 participants in the limited version of the box task. The green intervals represent the situation where we have a uniform prior for $\Theta$, that is, $\gamma=\kappa=1$. The orange lines are the intervals for a prior where $\gamma=\kappa=0.5$.}
    \label{fig:sensitivity_ci_lim_alpha_zoom1}
\end{figure}

We have plotted the confidence intervals for $\beta$ for all participants with the two different priors in Figure \ref{fig:sensitivity_ci_lim_beta_zoom}.
As for $\alpha$, we see that participants 21 and 70 no longer have intervals of length zero, but that individual 75 still has. We also get that participants 6 and 44 get much longer confidence intervals for $\beta$ with the new prior. The rest of the intervals are quite similar with the two different priors. 
\begin{figure}
    \centering
    \includegraphics[scale=0.37]{pictures/Sensitivity/ci_lim_beta_zoom1.png}
    \caption[CIs for $\beta$ for all participants with two different priors, limited]{Confidence intervals for $\beta$ for all of the 76 participants in the limited version of the box task. The green intervals represent the situation where we have a uniform prior for $\Theta$, that is, $\gamma=\kappa=1$. The orange lines are the intervals for a prior where $\gamma=\kappa=0.5$.}
    \label{fig:sensitivity_ci_lim_beta_zoom}
\end{figure}

The confidence intervals for $\eta$ are plotted in Figure \ref{fig:sensitivity_ci_lim_eta}. Again, we see that individual 21 and 70  get new intervals with length larger than zero and that individual 75 does not. As for the confidence interval for $\beta$ for individual 44, the interval of $\eta$ is much longer with the new prior. Along with this, individual 6 gets non-overlapping confidence intervals for $\eta$. The rest of the intervals are close for the two different priors. Some intervals are now shorter, and some are longer. 
\begin{figure}
    \centering
    \includegraphics[scale=0.37]{pictures/Sensitivity/ci_lim_eta_zoomed.png}
    \caption[CIs for $\eta$ for all participants with two different priors, limited]{Confidence intervals for $\eta$ for all of the 76 participants in the limited version of the box task. The green intervals represent the situation where we have a uniform prior for $\Theta$, that is, $\gamma=\kappa=1$. The orange lines are the intervals for a prior where $\gamma=\kappa=0.5$. The old interval for person 70 is a scalar that has value 23851.9, thus it is outside the rage of this plot.}
    \label{fig:sensitivity_ci_lim_eta}
\end{figure}


As we have seen, the parameters estimates in the limited version are more affected by the change of prior than in the unlimited version. In the limited, all three parameters seem to get slightly smaller values, whereas only $\ha$ and not $\he$ in the unlimited seem to be smaller. However, for both cases, there seem not to be any large changes in the confidence intervals. 