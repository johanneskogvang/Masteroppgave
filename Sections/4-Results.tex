\chapter{Results}

As we have found the maximum likelihood estimates and their respective confidence intervals, next step is to show some of these results. However, we will firstly introduce the Ideal Observer solutions for different values of the parameters, which depends on the expected losses. We firstly look at the situations where $\gamma=\kappa=1$, thus that the prior is uniform. 

\section{Uniform Prior}
When we present the results, we start with the results where we have a uniform prior. Recall that this means that it is equally likely that $\theta$ is anywhere between 0 and 1. We start with having a look at the probabilities that either blue or red are the majority colours. 

\subsection{Conditional Probabilities}
We will here have a look at the probability that blue is the dominant colour, and the probability that red is the dominant colour, as shown in \eqref{blue_major_final} and \eqref{redmajor_final}, respectively. These probabilities can be represented for each possible combination of blue and red boxes. Thus, we can find those probabilities for all the trials the participants have done. 

We present the probabilities in Figure \ref{fig:probability_gamma_kappa_1}. Here, the top node represents the situation where no boxes are opened. The probability that blue is the majority colour is then equal to the probability of red being the majority colour. This is represented as the proportion of blue and red inside the nodes, which in this case are equal quantities. The circle around the node represent which of the colours that have the highest probability of being in majority. In the top node, the probabilities are equal, thus, this circle is split in two. The node down to the left of the top node represents the situation where one box is opened, and that box is blue. One node down to the left of that one again represents the situation where two boxes are opened and both are blue, and so on. Similarly, the node down to the right of the top node represents the situation where one box is opened, and that box is red and so fourth down the tree. We see that in the last row of the tree, the middle node is missing. This is because the last row represents the situations where twelve boxes are opened, and as there cannot be six of each colours, that node is not included in the tree. In the row above, we see that all the nodes are completely red or completely blue. That means that we can be sure what the majority colour is after eleven boxes are opened. This is because there cannot be six boxes of each of the colours. Then, if there are six of one colour and five of the other, we know that the colour with six boxes is the majority colour. 
\begin{figure}
    \centering
    \scalebox{0.4}{\input{tikz-trees/probability_gamma_kappa_1}}
    \caption[Probabilities, majority colour. $\gamma=\kappa=1$]{Probabilities, $\gamma=\kappa =1$.}
    \label{fig:probability_gamma_kappa_1}
\end{figure}



When we have these probabilities, the next step is to look at the Ideal Observer solution we have found.




\subsection{An Ideal Observer Solution in the Unlimited case}

As we have all the expected losses for each possible combination of opened boxes, we can present these similarly to the probabilities in Figure \ref{fig:probability_gamma_kappa_1}. 
The expected losses in the unlimited case is as given in \eqref{exp_loss_blue}, \eqref{exp_loss_red} and \eqref{exp_loss_next_box_unlim}. In the unlimited case, we get different solutions for different values of $\alpha$. We have looked at numerous solutions, but only a handful of them will be presented here. 

Recall that an Ideal Observer solution is a solution where the decisions tied to the least expected loss is chosen each time a box is opened. In Figure \ref{fig:unlim_a0.0001_gk1}, we see the expected losses for an individual with $\alpha=0.0001$ visualised. As in Figure \ref{fig:probability_gamma_kappa_1}, the top node represents the situation where no boxes are opened, and the node down to the left represents the situation where one box is opened, and that box is blue and so forth. The circles around the nodes represents the decision with the least expected loss, thus the decision that an Ideal Observer would make. A blue circle indicates that choosing blue as the majority colour has the least expected loss, and a red circle indicates that choosing red has the least expected loss. A green circle means that the the decision to open the next box has the least expected loss. The colours inside the nodes represent what we could call the inverse of the expected losses. That means that if the decision of choosing red as the majority colour has a low expected loss, the amount of red inside that node is big. That means that the colour that represents the Ideal Observer solution is the most prominent in the different nodes. The inverse expected losses are found by adding together all the expected losses and then subtracting the expected loss in question. Late we are normalising these inverse expected losses as they do not sum to one. Let $\tau_i(\delta_i)$ be the inverse expected losses. Then, the inverse expected loss for choosing blue as the majority colour is 
\begin{equation*}
    \tau_i(0) = \sum_{j=0}^2 \EE_{\delta_j}^i(\alpha) - \EE_0^i(\alpha).
\end{equation*}
Similarly, for red it would be
\begin{equation*}
    \tau_i(1) = \sum_{j=0}^2 \EE_{\delta_j}^i(\alpha) - \EE_1^i(\alpha),
\end{equation*}
and for opening the next box it will be
\begin{equation*}
    \tau_i(2) = \sum_{j=0}^2 \EE_{\delta_j}^i(\alpha) - \EE_2^i(\alpha).
\end{equation*}
We need to normalise these. The proportion of blue in each node would then be
\begin{equation*}
    \frac{\tau_i(0)}{\tau_i(0)+\tau_i(1)+\tau_i(2)}.
\end{equation*}
\begin{figure}
    \centering
    \scalebox{0.7}{\input{tikz-trees/unlim_a_0.0001_g_k_1}}
    \caption[IO solution, unlimited. $\alpha=0.0001$, $\gamma=\kappa=1$]{Unlimited, $\alpha = 0.0001$, $\gamma=\kappa=1$.}
    \label{fig:unlim_a0.0001_gk1}
\end{figure}


As we can see in Figures \ref{fig:unlim_a0.0001_gk1}, \ref{fig:unlim_a0.01_gk1} and \ref{fig:unlim_a0.05_gk1}, where the $\alpha$ values are 0.0001, 0.01 and 0.05, respectively, the trees are slimmer for bigger values of $\alpha$. Recall that $\alpha$ is the penalty of opening a box and that the expected loss for choosing to open another box increases with it. Hence the threshold for when that expected loss surpasses the expected loss for choosing either blue or red as majority colour decreases with increasing $\alpha$. Therefore, we make a decision at an earlier point, which makes the trees slimmer.
\begin{figure}
    \centering
    \begin{minipage}{0.45\textwidth} 
        \centering
        \scalebox{0.5}{\input{tikz-trees/unif_unlim_a0.01v2}}
        \caption[IO solution, unlimited. $\alpha=0.01$,$\gamma=\kappa=1$]{A decision tree for an unlimited trial with $\alpha = 0.01$. 
        We can interpret this tree in the same way as Figure (input here) where the circles around each node shows which decision the Ideal Observer would do.}
        \label{fig:unlim_a0.01_gk1}
    \end{minipage}\hfill
    \begin{minipage}{0.45\textwidth} 
        \centering
        \scalebox{0.5}{\input{tikz-trees/unlim_a0.05_gk1}}
        \caption[IO solution, unlimited. $\alpha=0.05$,$\gamma=\kappa=1$]{A decision tree in the unlimited case with $\alpha = 0.05$ that can be understood in the same way as Figure (input here) where the circles around each node shows which decision the Ideal Observer would do.}
        \label{fig:unlim_a0.05_gk1}
    \end{minipage}
\end{figure}



At some point, $\alpha$ could get so big that the ideal observer would decide what the majority colour is after only one box is opened. The expected loss for opening another box is dependent on both $\alpha$ and the expected losses for continuing to open boxes. In contrast, the expected losses for choosing the majority colour are only dependent on the probabilities that one of the colours is in majority. For example, if the first box is red, the probability that red is in majority increases. Therefore, if $\alpha$ is big enough, the expected loss for opening another box could be higher than the probabilities that one of the colours is in majority; thus the ideal observer would decide after one box is opened. This is the situation when $\alpha$ is 0.1 as in Figure \ref{fig:unlim_a0.1_gk1}. Here, the expected loss before any boxes are opened is 0.5 both for choosing blue and red as the majority colour. For the choice of opening a box, the expected loss is 0.308. This is then the choice an ideal observer would make before any boxes are opened. If the box that opens is blue, the expected loss for choosing that blue is the majority colour is 0.208, 0.792 for choosing red, and 0.260 for opening another box. Hence, the ideal observer would decide that blue is the majority colour. This problem is symmetric. That means that if the opened box is red, the expected loss for choosing that red is the majority colour is 0.208, 0.792 for choosing blue and 0.260 for opening another box. In this case, the expected loss is smallest when we choose red as the majority colour.
\begin{figure}
    \centering
    \scalebox{1}{\input{tikz-trees/unlim_a0.1_gk1}}
    \caption[IO solution, unlimited. $\alpha=0.1$,$\gamma=\kappa=1$]{A decision tree for an unlimited trial with $\alpha = 0.1$, that can be interpreted in the same way as Figure (input here).}
    \label{fig:unlim_a0.1_gk1}
\end{figure}


As $\alpha$ is the loss we get when we open a box, we can imagine that it also could be zero. In Figure \ref{fig:unlim_a0_gk1} we see the decision tree for $\alpha=0$. When we have six boxes of one of the colours, for example red, the expected loss of choosing red as the majority colour is zero, but so is the expected loss of opening the next box. Thus, and Ideal Observer would choose arbitrarily between those. However, we have decided here that the IO would rather choose majority colour than to open the next box if both of the expected losses are zero, such that one does not open any more boxes than necessary. We see that this tree resembles the tree where $\alpha=0.001$ as shown in Figure \ref{fig:unlim_a0.0001_gk1}. This indicated that such a small value of $\alpha$ is almost the same as having $\alpha$ equal to zero. 
\begin{figure}
    \centering
    \scalebox{0.5}{\input{tikz-trees/unif_unlim_a0}}
    \caption[IO solution, unlimited. $\alpha=0$, $\gamma=\kappa=1$]{Unlimited, $\alpha = 0$, $\gamma=\kappa=1$. Here we choose that the IO chooses majority colour if the expected loss of opening the next box is the same as for choosing majority colour (which both are zero if there are six of one of the colours. The expected loss for opening the next box will always be zero, in the whole trial).}
    \label{fig:unlim_a0_gk1}
\end{figure}

In Figure \ref{fig:IO_trial2_a0.01} we see the Ideal Observer solution in Trial 2 for an individual with $\alpha=0.01$. Here we see that the Ideal Observer would choose after six boxes are opened, hence before we can be completely sure that red is the majority colour, but the probability is .... (find this one), so it is very likely that we choose the right colour here. The expected loss of choosing red is then (1-that prob), hence very low. 
We see that if a participant has an $\alpha=0.05$, then an Ideal Observer would choose after two boxes are opened, as shown in Figure \ref{fig:IO_trial2_a0.05}.Then, the penalty for opening the next box is much higher than in Figure \ref{fig:IO_trial2_a0.01}, thus, the IO would choose sooner. 

%\begin{figure}
%    \centering
%    \scalebox{0.5}{\input{tikz-trees/test_of_trial2_unlim_a0.01_gamma_kappa_1}}
%    \caption{Trial 2, IO solution for a participant with $\alpha = 0.01$.}
%    \label{fig:IO_trial2_a0.01}
%\end{figure}
%\begin{figure}
%    \centering
%    \scalebox{0.5}{\input{tikz-trees/trial2_unlim_a0.05_gk1}}
%    \caption{Trial 2, IO solution for a participant with $\alpha = 0.05$.}
%    \label{fig:IO_trial2_a0.05}
%\end{figure}

\begin{figure}
    \centering
    \begin{minipage}{0.45\textwidth}
        \centering
        \scalebox{0.5}{\input{tikz-trees/trial2_unlim_a0.01_gk1}}
        \caption[IO solution for Trial 2. $\alpha=0.01$,$\gamma=\kappa=1$]{Trial 2, IO solution for a participant with $\alpha = 0.01$.}
        \label{fig:IO_trial2_a0.01}
    \end{minipage}\hfill
    \begin{minipage}{0.45\textwidth}
        \centering
        \scalebox{0.5}{\input{tikz-trees/trial2_unlim_a0.05_gk1}}
        \caption[IO solution for Trial 2. $\alpha=0.05$,$\gamma=\kappa=1$]{Trial 2, IO solution for a participant with $\alpha = 0.05$.}
        \label{fig:IO_trial2_a0.05}
    \end{minipage}
\end{figure}

As we have presented Ideal Observer solutions in the unlimited case for different values of $\alpha$, the next step is to show some of the solutions in the limited case. 

\subsection{An Ideal Observer Solution in the Limited case}
Having the expected losses in the limited case as given in \eqref{exp_loss_blue}, \eqref{exp_loss_red} and \eqref{exp_loss_limited_final}, we can visualise them in the same way as Figure \ref{fig:unlim_a0.0001_gk1}. In the limited trials, we have to parameters, $\alpha$ and $\beta$. Thus, we have solutions with both of these parameters varying. 

In Figures \ref{fig:lim_a0.01_b0.6_gk1} and \ref{fig:lim_a0.01_b0.4_gk1}, we see two solutions, both with $\alpha=0.01$. They have different values of $\beta$, 0.6 and 0.4 respectively. Both trees have the same width, but we see that the tree with the higher $\beta$ value is shorter. Thus, an Ideal Observer with $\beta=0.6$ would open fewer boxes than one with $\beta=0.4$, which is what we would imagine as $\beta$ is the loss of the test terminating. 
\begin{figure}
    \centering
    \begin{minipage}[t]{0.45\textwidth}
        \centering
        \scalebox{0.8}{\input{tikz-trees/lim_a0.01_b0.6_gk1}}
        \caption[Limited something]{Limited, $\alpha=0.01$, $\beta=0.6$. $\gamma=\kappa=1$.}
        \label{fig:lim_a0.01_b0.6_gk1}
    \end{minipage}\hfill
    \begin{minipage}[t]{0.45\textwidth}
        \centering
        \scalebox{0.8}{\input{tikz-trees/lim_a0.01_b0.4_gk1}}
        \caption[Limited something]{Limited, $\alpha=0.01$, $\beta=0.4$. $\gamma=\kappa=1$.}
        \label{fig:lim_a0.01_b0.4_gk1}
    \end{minipage}
\end{figure}


The trees in the limited case are in general slimmer than in the unlimited case. This is because of the penalty we get when the test terminates before we have made a decision. The expected losses for opening another box in the limited case are bigger than in the unlimited case. Hence, in the limited case, these surpass the expected losses of choosing blue or red as majority colour earlier than in the unlimited case. Small values of $\alpha$ and $\beta$ in combination makes the trees wider, as in Figure \ref{fig:lim_a0.0001_b0.2_gk1}.
\begin{figure}
    \centering
    \scalebox{0.8}{\input{tikz-trees/lim_a0.0001_b0.2_gk1}}
    \caption[IO solution, limited. $\alpha=0.0001, \beta=0.2$. $\gamma=\kappa=1$.]{IO solution, limited. $\alpha=0.0001, \beta=0.2$. $\gamma=\kappa=1$.}
    \label{fig:lim_a0.0001_b0.2_gk1}
\end{figure}

As in the unlimited case, there are trials where the ideal observer solution is to choose the majority colour after one box is opened. This is the case in Figures \ref{fig:lim_a0.05_b0.4_gk1} and \ref{fig:lim_a0.05_b0.6_gk1}. The only thing that has changed from Figure \ref{fig:lim_a0.01_b0.4_gk1} to Figure \ref{fig:lim_a0.05_b0.4_gk1} and from Figure \ref{fig:lim_a0.01_b0.6_gk1} to Figure \ref{fig:lim_a0.05_b0.6_gk1} is the $\alpha$ value, which has increased from 0.01 to 0.05. In the cases with the bigger $\alpha$ values, the expected loss for opening box two is bigger than for choosing the majority colour. This is a result of these expected losses being dependent on the next expected losses, which again depend on the expected losses for opening another box after that and so on. Additionally, these could potentially be big if the amount of red and blue boxes are close to each other, meaning that we for example first open a red box, then a blue, then a red and so forth. 

\begin{figure}
    \centering
    \begin{minipage}[t]{0.45\textwidth} 
        \centering
        \scalebox{0.8}{\input{tikz-trees/lim_a0.05_b0.4_gk1}}
        \caption{A decision tree for a limited trial with $\alpha = 0.05$, $\beta=0.4$ and $\gamma=\kappa=1$. It can bee interpreted as the tree in Figure (input here!).}
        \label{fig:lim_a0.05_b0.4_gk1}
    \end{minipage}\hfill
    \begin{minipage}[t]{0.45\textwidth} 
        \centering
        \scalebox{0.8}{\input{tikz-trees/lim_a0.05_b0.4_gk1}}
        \caption{A decision tree for a limited trial with $\alpha = 0.05$, $\beta=0.6$ and $\gamma=\kappa=1$ that can be interpreted in the same way as the tree in Figure (input here!).}
        \label{fig:lim_a0.05_b0.6_gk1}
    \end{minipage}
\end{figure}

In Figure \ref{fig:trial8_IO_a0.01_b0.6_gk1}, we see the IO solution for Trial 8 where $\alpha=0.01$ and $\beta=0.6$. We see that an Ideal Observer would choose majority colour after seven boxes are opened, where four are blue and three are red. In Figure \ref{fig:trial8_IO_a0.0001_b0.2_gk1}, we see another IO solution for Trial 8, where $\alpha=0.0001$ and $\beta=0.2$. Here, an Ideal Observer would not choose before the test terminates, and that would be a failed trial. This, the Ideal Observer is not perfect, as it is based on expected losses based on the previously opened boxes, and not based on what actually is going to happen.

\begin{figure}
    \centering
     \begin{minipage}[t]{0.45\textwidth}
        \centering
        \scalebox{0.7}{\input{tikz-trees/trial8_lim_a0.01_b0.6_gk1}}
        \caption[IO solution, Trial 8. $\alpha=0.01$, $\beta=0.6$ and $\gamma=\kappa=1$.]{IO solution, Trial 8. $\alpha=0.01$, $\beta=0.6$ and $\gamma=\kappa=1$.}
        \label{fig:trial8_IO_a0.01_b0.6_gk1}
     \end{minipage}\hfill
     \begin{minipage}[t]{0.45\textwidth}
        \centering
        \scalebox{0.7}{\input{tikz-trees/trial8_lim_a0.0001_b0.2_gk1}}
        \caption[IO solution, Trial 8. $\alpha=0.0001$, $\beta=0.2$ and $\gamma=\kappa=1$.]{IO solution, Trial 8. $\alpha=0.0001$, $\beta=0.2$ and $\gamma=\kappa=1$.}
        \label{fig:trial8_IO_a0.0001_b0.2_gk1}
     \end{minipage}
\end{figure}

%\begin{figure}
%    \centering
%    \scalebox{0.8}{\input{tikz-trees/trial8_lim_a0.01_b0.6_gk1}}
%    \caption[IO solution, trial 8. $\alpha=0.01$, $\beta=0.6$ and $\gamma=\kappa=1$.]{IO solution, trial 8. $\alpha=0.01$, $\beta=0.6$ and $\gamma=\kappa=1$.}
    %\label{fig:trial8_IO_a0.01_b0.6_gk1}
%\end{figure}


%\begin{figure}
%    \centering
%    \scalebox{0.8}{\input{tikz-trees/trial8_lim_a0.0001_b0.2_gk1}}
%    \caption[IO solution, trial 8. $\alpha=0.0001$, $\beta=0.2$ and $\gamma=\kappa=1$.]{IO solution, trial 8. $\alpha=0.0001$, $\beta=0.2$ and $\gamma=\kappa=1$.}
    %\label{fig:trial8_IO_a0.0001_b0.2_gk1}
%\end{figure}

sentence about where we are and what we will do next. 






\subsection{Maximum Likelihood Estimates}
\label{chapter:mles}
As we have presented some Ideal Observer solutions, we will now have a look at the parameter estimates we have found for each of the participants. 


\subsubsection{Unlimited}
Presentere mles i plott. Så velge ut noen og vise hva de gjør vs hva en IO med deres parametere ville gjort. 

In the unlimited version, we have the parameters $\alpha$ and $\eta$. We have found the maximum likelihood estimates for both of these for each participant. These are plotted in Figure \ref{fig:plot_all_mles_unlim_zoom0}. We see that there are some outliers of both $\ha$ and $\he$. To get a better picture of the other values, we zoom in closer to zero for both parameters. This is done i Figure \ref{fig:plot_all_mles_unlim_zoom1}, and we have zoomed even more in Figure \ref{fig:plot_all_mles_unlim_zoom2}. Many of the participants have $\hat{\alpha}$ equal to or close to zero, meaning that they have none or little loss of opening boxes. 
(litt usikker på hva jeg skal si om disse plottene?)
\begin{comment}
\begin{figure}
    \centering
    \begin{minipage}{0.45\textwidth}
        \centering
        \includegraphics[scale=0.4]{pictures/plotted_mles_unlim_gk1.png}
        \caption[All MLEs plotted, unlimited]{Caption}
        \label{fig:plot_all_mles_unlim_zoom0}
    \end{minipage}\hfill
    \begin{minipage}{0.45\textwidth}
        \centering
        \includegraphics[scale=0.4]{pictures/plotted_mles_unlim_gk1_zoom1.png}
        \caption[Some MLEs plotted, unlimited]{Caption}
        \label{fig:plot_all_mles_unlim_zoom1}
    \end{minipage}
\end{figure}
\end{comment}
\begin{figure}
    \centering
    \includegraphics[scale=0.7]{pictures/plotted_mles_unlim_gk1.png}
    \caption[All MLEs plotted, unlimited]{Caption}
    \label{fig:plot_all_mles_unlim_zoom0}
\end{figure}

\begin{figure}
    \centering
    \includegraphics[scale=0.7]{pictures/plotted_mles_unlim_gk1_zoom1.png}
    \caption[Some MLEs plotted, unlimited]{Caption}
    \label{fig:plot_all_mles_unlim_zoom1}
\end{figure}

\begin{figure}
    \centering
    \includegraphics[scale=0.7]{pictures/plotted_mles_unlim_gk1_zoom2.png}
    \caption[Some MLEs plotted, unlimited]{Caption}
    \label{fig:plot_all_mles_unlim_zoom2}
\end{figure}


 
If we look at the outliers in Figure \ref{fig:plot_all_mles_unlim_zoom0}, we find one participant with a very high value of $\eta$ and small value of $\alpha$. This is individual 58. In each of the three unlimited trials, this individual chooses the majority colour exactly when there are six of one of the colours, which is when we can be completely sure what the true majority colour is. That means that individual 58 chooses after seven boxes are opened in Trial 2, and she then chooses red. In Trials 3 and 4 she chooses after 10 and 9 boxes are opened, respectively. Thus, she always chooses the decision with the least expected loss. This is the reason for the estimate of $\eta$ being so high. (something about this almost being the same as eta = infinity?) Individual 58 has $\alpha=0.0016$, which is quite small. However, this might be because she does not open any more boxes than necessary. This might indicate a small loss of opening boxes, or some kind of reward of finishing early. However, this $\alpha$ value is so small that it would give an IO solution similar to the one in Figure \ref{fig:unlim_a0.0001_gk1}, such that one always chooses after six of one of the colours have been displayed. 

Looking at the other outlier in Figure \ref{fig:plot_all_mles_unlim_zoom0}, Individual 13, we see that she has a high value of $\alpha$ and a small value of $\eta$. In fact, the value of $\eta$ is negative,  with $\hat{\eta}=-0.4290$ and $\hat{\alpha}=4.2224$. In Trial 2, she chooses after two boxes are opened, where both boxes are red. In both Trial 3 and Trial 4, she chooses when three boxes are opened, where two of them are blue and one is red. She then chooses red as the majority colour despite the fact that choosing blue as the majority colour has lower expected loss. Thus, she tends to choose the decisions with higher expected losses, and therefore she has a negative estimate of $\eta$. She also chooses quite early, thus she gets a high estimate of $\alpha$. However, an ideal obs with this high alpha would always choose after 1 box. (hvorfor har jeg da fått en så høy alpha når denne personen velger etter to og tre bokser?)


If we look at one of the individuals that is not an outlier, we find, for example, individual 61. She has $\ha=0.0135$ and $\he=19.9432$. In the unlimited trials, she chooses what she thinks is the majority colour after five, six and four boxes are opened. She chooses majority colour before she can be completely sure, and therefore has $\ha>0$. When she chooses however, she chooses the colour with the least expected loss, and thus have a positive $\he$. An IO with the parameters equal to individual 61s estimates would choose after 3, 10 and 9 boxes were opened, this her decisions do not coincide with the IO decisions. 
\begin{figure}
    \centering
    \scalebox{0.7}{\input{tikz-trees/unlim_a0.0135_g1_k1}}
    \caption{IO sol unlim individual 61. $\ha=0.0135$.}
    \label{fig:IO_sol_individual61}
\end{figure}




\subsubsection{Limited}
In the limited version, we have three parameters, $\alpha$, $\beta$ and $\eta$, and we have found maximum likelihood estimates for these for all of the 76 participants. The MLEs of $\alpha$ and $\eta$ for all participants are plotted in Figure \ref{fig:mles_limited_alpha_eta}. We see that many of the participants have $\hat{\alpha}=0$. (why?? talk about that it might be unnecessary to have alpha in lmited model? ). 
There are two prominent outliers, one with $\hat{\eta}=30.7573$ and another with $\hat{\alpha}=2.2997$. There are participants number 75 and 11, respectively. 
\begin{figure}
    \centering
    \includegraphics[scale=0.7]{pictures/plotted_mles_limited_alpha_eta_gk1.png}
    \caption{Mles limited, alpha and eta for all participants. Bytt ut disse plottene så du får på en hatt!!}
    \label{fig:mles_limited_alpha_eta}
\end{figure}

%Talk about the two other plots here, and the zoomed ones. 
In Figure \ref{fig:mles_limited_alpha_beta} we have plotted the MLEs of $\alpha$ and $\beta$ for all participants. We see an individual with a high value if $\hat{\beta}$. This is the same individual that has the high $\hat{\eta}$ value in Figure \ref{fig:mles_limited_alpha_eta}, individual 75. She is also seen in the top right corner of Figure \ref{fig:mles_limited_beta_eta} that displays $\hat{\beta}$ and $\hat{\eta}$ for all participants.
\begin{figure}
    \centering
    \begin{minipage}{0.48\textwidth}
        \centering
        \includegraphics[scale=0.38]{pictures/plotted_mles_limited_alpha_beta_gk1.png}
        \caption{Mles limited, alpha and beta for all participants. Not zoomed}
        \label{fig:mles_limited_alpha_beta}
    \end{minipage}\hfill%\hspace{0.2cm}%\hfill
    \begin{minipage}{0.48\textwidth}
        \centering
        \includegraphics[scale=0.38]{pictures/plotted_mles_limited_alpha_beta_zoomed_gk1.png}
        \caption{Mles limited, alpha and beta for participants, zoomed}
        \label{fig:mles_limited_alpha_beta_zoomed}
    \end{minipage}
\end{figure}
%\begin{figure}
%    \centering
%    \includegraphics[scale=0.7]{pictures/plotted_mles_limited_alpha_beta_gk1.png}
%    \caption{Mles limited, alpha and beta for all participants}
%    \label{fig:mles_limited_alpha_beta}
%\end{figure}
%\begin{figure}
%    \centering
%    \includegraphics[scale=0.7]{pictures/plotted_mles_limited_alpha_beta_zoomed_gk1.png}
%    \caption{Mles limited, alpha and beta for all participants, zoomed}
%    \label{fig:mles_limited_alpha_beta_zoomed}
%\end{figure}
\begin{figure}
    \centering
    \includegraphics[scale=0.7]{pictures/plotted_mles_limited_beta_eta_gk1.png}
    \caption{Mles limited, beta and eta for all participants}
    \label{fig:mles_limited_beta_eta}
\end{figure}
Zooming in more on the plot in Figure \ref{fig:mles_limited_alpha_beta}, like in Figure \ref{fig:mles_limited_alpha_beta_zoomed}, we see that many participants have $\ha=0$, and that $\hb$ typically is between 0.1 and 0.6. (what more should I say about this?? why is it like this? so many that have alpha=0??). In Figure \ref{fig:mles_limited_beta_eta_zoomed} we have zoomed in on the plot in Figure \ref{fig:mles_limited_beta_eta}. Here we see that many of the $\hb$ values are zero, and the ones different from zero is spread around between 0.1 and 0.6 as seen in the $\ha$-$\hb$ plot. We also see that participants with low $\he$ tends to have low $\hb$. WHY?? 

\begin{figure}
    \centering
    \includegraphics[scale=0.7]{pictures/plotted_mles_limited_beta_eta_zoomed_gk1.png}
    \caption{Mles limited, beta and eta for all participants, zoomed}
    \label{fig:mles_limited_beta_eta_zoomed}
\end{figure}

This is all about individual 75, write sentecne about that:
He has parameter estimates $\hat{\alpha}=0$, $\hat{\beta}=40.7103$ and $\hat{\eta}=30.7573$. This participant chooses after one box is opened in all of the six limited trials, thus, the high value of $\hb$. At the same time, individual 75 always chooses the colour of that first box as the majority colour, which is the colour with the least expected loss. The expected loss of opening the next box might be lower than the expected loss of choosing that as the majority colour. However, these expected losses are often close to each other, whereas the expected loss of choosing the other colour as the majority is often further away. Thus, she tends to choose decisions with low expected losses. That is the reason for the high value of $\he$ compared to the other participants. (but why is alpha 0?). In Figure \ref{fig:IO_sol_person_75_lim} we see the IO solution for a participant with the parameters as individual number 75 has. We see that an IO with these estimates also would choose after one box is opened in all trials. 
\begin{figure}
    \centering
    \scalebox{0.8}{\input{tikz-trees/lim_a0_b40.71_g1_k1}}
    \caption[IO solution for individual number 75, limited]{IO sol for individual 75}
    \label{fig:IO_sol_person_75_lim}
\end{figure}

The other outlier in Figure \ref{fig:mles_limited_alpha_eta} is individual number 11 with $\ha=2.2997$, $\hb=0$ and $\he=-0.8474$. We also see her as an outlier in Figure \ref{fig:mles_limited_alpha_beta} that shows the MLEs of $\alpha$ and $\beta$ in the limited trial. This participant tends to choose the alternatives with the highest expected loss, and thus has a negative value of $\he$. Making those decisions also indicated that one are not afraid to make wrong choices, thus $\hb=0$. (why is $\ha=2.2997$??) An individual with these parameter estimates has IO solution as shown in Figure \ref{fig:IO_sol_person_11_lim}. Having such a high value of $\ha$ makes the expected loss of opening the next box higher than the expected loss of choosing the majority colour before any boxes are opened. Recall that the expected loss of for example choosing red as the majority colour is the probability that blue is the majority colour given the colours of the boxes that are opened, as seen in \eqref{exp_loss_red}. As no boxes are opened, this probability is 0.5. The expected loss of opening the first box is $\alpha$ plus the expected loss when the first box is opened as seen in \eqref{exp_loss_limited_final}. Thus, the expected loss of opening the next box is much higher than the expected loss of choosing between blue and red randomly before any boxes are opened. (somethin about alpha being necessary when teh participants chooses badly, bc than beta is zero, but if they still open few boxes they tend to be reluctant to open to many. thus, tehy get a higher alpha value. Also say that these arguments hold for the other person with alpha different from zero.)
\begin{figure}
    \centering
    \scalebox{0.8}{\input{tikz-trees/lim_a2.2997_b0_g1_k1}}
    \caption[IO solution for individual number 11, limited]{IO sol for individual number 11}
    \label{fig:IO_sol_person_11_lim}
\end{figure}




If we look at an individual that has estimates more in the middle of the range, we find, for example, individual 32. She has  $\ha=0$, $\hb=0.2377$, $\he=7.4835$. The IO solution for someone with these parameters is shown in Figure \ref{fig:IO_sol_lim_person32and33}. We see that we wait much longer before choosing here than for individuals 75 and 11. This is because the parameter estimates are much lower, thus the expected loss of opening the next box is lower than in Figures \ref{fig:IO_sol_person_75_lim} and \ref{fig:IO_sol_person_11_lim}.
Individual 32 mostly chooses majority colour in Trial 5 after two boxes are opened, after three are opened in Trial 3, and after four in the last limited trials. An IO with the same parameters would actually end up with Trials 6, 8 and 9 terminating. thus, one might argue that individual 32 makes better choices than the IO. 
\begin{figure}
    \centering
    \scalebox{0.7}{\input{tikz-trees/lim_a0.0_b0.2377_g1_k1}}
    \caption{IO sol individuals 32 and 33 (similiar)}
    \label{fig:IO_sol_lim_person32and33}
\end{figure}


Individuals 32 and 33 have same estimates of alpha and beta, but different eta, discuss that??

%for example person 28, $\ha=0$, $\hb=0.3628$ and $\he=10.5168$ ish. 

%\begin{figure}
%    \centering
%   \scalebox{0.7}{\input{tikz-trees/lim_a0.0_b0.3628_g1_k1}}
%    \caption{IO sol individual number 28}
%    \label{fig:IO_sol_lim_person28}
%\end{figure}









\subsection{Confidence Intervals}
We have presented and Ideal Observer solution of the box task and the maximum likelihood estimates for different participants. Now, we will show some of the confidence intervals that we have found. 

\subsubsection{Unlimited}
We start with the CIs for the unlimited case. In Figure \ref{fig:all_cis_alpha_unlim_v2} we see the confidence intervals for each person for $\alpha$ except for individual 13. THe reason for her not being included here is that the percentiles in confidence interval is very large. Recall that the MLE of $\alpha$ for person 13 is very large, and we also have large values of $\ha_{1000}^{(5)}$ and $\ha_{1000}^{(95)}$. 

Plot of all confidence intervals
\begin{figure}
    \centering
    \includegraphics[scale=0.36]{pictures/all_cis_unlim_alpha_v2.png}
    \caption{All ci for $\alpha$ except for individual 13 plotted}
    \label{fig:all_cis_alpha_unlim_v2}
\end{figure}




In Chapter \ref{chapter:mles} we talked about individual 61 that has MLEs in the middle of the range of the MLEs. The MLEs are
\begin{equation*}
    \begin{aligned}
        \ha &= 0.0135\\
        \he &= 19.9432.
    \end{aligned}
\end{equation*}
For this person we have 1000 bootstrap samples and thus 1000 values of both $\hat{\alpha}$ and $\he$. These are plotted in Figure \ref{fig:ci_unlim_person_61}. There, we have also plotted the confidence interval as black lines. We see that most of the bootstrap samples are accumulated in the bottom left corner. Thus we zoom in there in Figure \ref{fig:ci_unlim_person_61_zoomed}, where we also have plotted the CI. We have that
\begin{equation*}
    [\hat{\alpha}^{*(5)}_{1000},\hat{\alpha}^{*(95)}_{1000}] = [0,0.0362]
\end{equation*}
and
\begin{equation*}
    [\hat{\eta}^{*(5)}_{1000},\hat{\eta}^{*(95)}_{1000}] = [10.0449,110.3661].
\end{equation*}
(jeg vet ikke helt hva jeg skal si om disse CI??)

\begin{figure}
    \centering
    \begin{minipage}{0.48\textwidth}
        \centering
        \includegraphics[scale=0.37]{pictures/ci_unlim_person61.png}
        \caption{ci unlim person 61}
        \label{fig:ci_unlim_person_61}
    \end{minipage}\hfill
    \begin{minipage}{0.48\textwidth}
        \centering
        \includegraphics[scale=0.37]{pictures/ci_unlim_person61_zoomed.png}
        \caption{ci unlim person 61 zoomed}
        \label{fig:ci_unlim_person_61_zoomed}
    \end{minipage}
\end{figure}

In Chapter \ref{chapter:mles} we also talked about individual number 13 that had a high $\ha$ compared to the other participants. Her MLEs are
\begin{equation*}
    \begin{aligned}
        \ha &= 4.2224\\
        \he &= -0.4290.
    \end{aligned}
\end{equation*}
The 1000 bootstrap samples for participant number 13 are plotted in Figure \ref{fig:ci_unlim_person_13}, and zoomed on the $\he$ axis in Figure \ref{fig:ci_unlim_person_13_zoomed}. The CIs are
\begin{equation*}
    [\hat{\alpha}^{*(5)}_{1000},\hat{\alpha}^{*(95)}_{1000}] = [0,1246.3510]
\end{equation*}
and
\begin{equation*}
    [\hat{\eta}^{*(5)}_{1000},\hat{\eta}^{*(95)}_{1000}] = [-9.9272,18.3986].
\end{equation*}
We see that many of the values of $\ha$ are very high, much higher than the MLE, thus the upper limit of the CI is very high.  It might look like we have found local minimum points in the negative log likelihood function many times (jeg er ikke helt sikker på dette, men det kan være??). Having values of $\ha$ this high indicates that one does not open any boxes before choosing, whereas this participant actually open two or three boxes before choosing majority colour. Thus, the more relevant data points might be the ones closer to $\ha=0$. 

persn 13: might look like we find local minimums in many of the cases. 
maybe see what the samples look like for alpha between 0 and 5? as 
\begin{figure}
    \centering
    \begin{minipage}{0.48\textwidth}
        \centering
        \includegraphics[scale=0.37]{pictures/ci_unlim_person13.png}
        \caption{ci unlim person 13}
        \label{fig:ci_unlim_person_13}
    \end{minipage}\hfill
    \begin{minipage}{0.48\textwidth}
        \centering
        \includegraphics[scale=0.37]{pictures/ci_unlim_person13_zoomed.png}
        \caption{ci unlim person 13 zoomed}
        \label{fig:ci_unlim_person_13_zoomed}
    \end{minipage}
\end{figure}
\begin{figure}
    \centering
    \includegraphics[scale=0.7]{pictures/ci_unlim_person13_zoomed2.png}
    \caption{ci unlim person 13 zoomed even more. Kanskje ikke zoome såå mye siden mle er på4.2???}
    \label{fig:ci_unlim_person_13_zoomed2}
\end{figure}

Another outlier we looked at in Chapter \ref{chapter:mles} is individual number 58. The MLEs are 
\begin{equation*}
    \begin{aligned}
        \ha &= 0.0016\\
        \he &= 443422.7.
    \end{aligned}
\end{equation*}
Having such a high value of $\he$ makes the probabilities in \eqref{probabilities_bootstrap} be approximate either zero or one. This, when we draw decisions based on those probabilities, we will always end up with the same decisions, and those are the decisions that the participant have made. Thus, all the simulated decisions are identical to the decisions the participant has made, and the MLEs will be identical. Thus, the length of the two CIs will be zero, and the values will be equal to the MLEs. Hence, the CIs are
\begin{equation*}
    [\hat{\alpha}^{*(5)}_{1000},\hat{\alpha}^{*(95)}_{1000}] = [0.0016,0.0016]
\end{equation*}
and
\begin{equation*}
    [\hat{\eta}^{*(5)}_{1000},\hat{\eta}^{*(95)}_{1000}] = [443422.7,443422.7].
\end{equation*}
We also see in Figure \ref{fig:ci_unlim_person_58} that all the data points are collected at one spot. 
\begin{figure}
    \centering
    \includegraphics[scale=0.7]{pictures/ci_unlim_person58.png}
    \caption{ci unlim person 58}
    \label{fig:ci_unlim_person_58}
\end{figure}

Having shown some of the confidence intervals for the unlimited trials we continue with the limited trials.

\subsubsection{Limited}

CIs for person 32:
\begin{equation*}
    [\hat{\alpha}^{*(5)}_{1000},\hat{\alpha}^{*(95)}_{1000}] = [0,0.0818],
\end{equation*}
\begin{equation*}
    [\hb^{*(5)}_{1000},\hb^{*(95)}_{1000}] = [0,0.8690]
\end{equation*}
and
\begin{equation*}
    [\hat{\eta}^{*(5)}_{1000},\hat{\eta}^{*(95)}_{1000}] = [4.4340,60.631].
\end{equation*}

\begin{figure}
    \centering
    \begin{minipage}{0.48\textwidth}
        \centering
        \includegraphics[scale=0.37]{pictures/ci_lim_a_b_person32.png}
        \caption{ci lim person 32}
        \label{fig:ci_lim_a_b_person_32}
    \end{minipage}\hfill
    \begin{minipage}{0.48\textwidth}
        \centering
        \includegraphics[scale=0.37]{pictures/ci_lim_a_b_person32_zoomed.png}
        \caption{ci lim person 32 zoomed}
        \label{fig:ci_lim_a_b_person_32_zoomed}
    \end{minipage}
\end{figure}

\begin{figure}
    \centering
    \begin{minipage}{0.48\textwidth}
        \centering
        \includegraphics[scale=0.37]{pictures/ci_lim_a_e_person32.png}
        \caption{ci lim person 32}
        \label{fig:ci_lim_a_e_person_32}
    \end{minipage}\hfill
    \begin{minipage}{0.48\textwidth}
        \centering
        \includegraphics[scale=0.37]{pictures/ci_lim_a_e_person32_zoomed.png}
        \caption{ci lim person 32 zoomed}
        \label{fig:ci_lim_a_e_person_32_zoomed}
    \end{minipage}
\end{figure}


\begin{figure}
    \centering
    \begin{minipage}{0.48\textwidth}
        \centering
        \includegraphics[scale=0.37]{pictures/ci_lim_b_e_person32.png}
        \caption{ci lim person 32}
        \label{fig:ci_lim_b_e_person_32}
    \end{minipage}\hfill
    \begin{minipage}{0.48\textwidth}
        \centering
        \includegraphics[scale=0.37]{pictures/ci_lim_b_e_person32_zoomed.png}
        \caption{ci lim person 32 zoomed}
        \label{fig:ci_lim_b_e_person_32_zoomed}
    \end{minipage}
\end{figure}



CIs for person 31:
\begin{equation*}
    [\hat{\alpha}^{*(5)}_{1000},\hat{\alpha}^{*(95)}_{1000}] = [0,1092.9440],
\end{equation*}
\begin{equation*}
    [\hb^{*(5)}_{1000},\hb^{*(95)}_{1000}] = [0,1023.9252]
\end{equation*}
and
\begin{equation*}
    [\hat{\eta}^{*(5)}_{1000},\hat{\eta}^{*(95)}_{1000}] = [-5.6640,3.2192].
\end{equation*}

\begin{figure}
    \centering
    \begin{minipage}{0.48\textwidth}
        \centering
        \includegraphics[scale=0.37]{pictures/ci_lim_a_b_person11.png}
        \caption{ci lim person 11}
        \label{fig:ci_lim_a_b_person_11}
    \end{minipage}\hfill
    \begin{minipage}{0.48\textwidth}
        \centering
        \includegraphics[scale=0.37]{pictures/ci_lim_a_b_person11_zoomed.png}
        \caption{ci lim person 11 zoomed}
        \label{fig:ci_lim_a_b_person_11_zoomed}
    \end{minipage}
\end{figure}

\begin{figure}
    \centering
    \begin{minipage}{0.48\textwidth}
        \centering
        \includegraphics[scale=0.37]{pictures/ci_lim_a_e_person11.png}
        \caption{ci lim person 11}
        \label{fig:ci_lim_a_e_person_11}
    \end{minipage}\hfill
    \begin{minipage}{0.48\textwidth}
        \centering
        \includegraphics[scale=0.37]{pictures/ci_lim_a_e_person11_zoomed.png}
        \caption{ci lim person 11 zoomed}
        \label{fig:ci_lim_a_e_person_11_zoomed}
    \end{minipage}
\end{figure}


\begin{figure}
    \centering
    \begin{minipage}{0.48\textwidth}
        \centering
        \includegraphics[scale=0.37]{pictures/ci_lim_b_e_person11.png}
        \caption{ci lim person 11}
        \label{fig:ci_lim_b_e_person_11}
    \end{minipage}\hfill
    \begin{minipage}{0.48\textwidth}
        \centering
        \includegraphics[scale=0.37]{pictures/ci_lim_b_e_person11_zoomed.png}
        \caption{ci lim person 11 zoomed}
        \label{fig:ci_lim_b_e_person_11_zoomed}
    \end{minipage}
\end{figure}



CIs for person 75:
\begin{equation*}
    [\hat{\alpha}^{*(5)}_{1000},\hat{\alpha}^{*(95)}_{1000}] = [0,0],
\end{equation*}
\begin{equation*}
    [\hb^{*(5)}_{1000},\hb^{*(95)}_{1000}] = [79.5448,79.5448]
\end{equation*}
and
\begin{equation*}
    [\hat{\eta}^{*(5)}_{1000},\hat{\eta}^{*(95)}_{1000}] = [45.69408,45.69408].
\end{equation*}







\section{Non-uniform Prior?}
note to self: gamma nd kappa smaller give more 'weight' to the colour of the boxes that are oepned. hence, we choose earlier because the prob that blue is majority is bigger here than for unif if one blue box is opened. 

Sentence about having seen results for uniform prior. We choose $\gamma=\kappa=0.5$, but there are many different priors one could try. but we believe that gamma and kappa are equal. 

\subsection{Maximum Likelihood Estimators}
sentece about starting with mles, and staritng with unlimted
\subsubsection{Unlimited}
sjekk om det er de samme outliersene som for uniform prior. ja, person 58 og 13. 
\begin{figure}
    \centering
    \begin{minipage}{0.48\textwidth}
        \centering
        \includegraphics[scale=0.37]{pictures/Gamma=kappa=0.5/plotted_mles_unlim_gk0.5.png}
        \caption{Mles unlimited, alpha and eta for all participants. $\gamma=\kappa=0.5$.    Not zoomed}
        \label{fig:gk0.5_mles_unlimited}
    \end{minipage}\hfill%\hspace{0.2cm}%\hfill
    \begin{minipage}{0.48\textwidth}
        \centering
        \includegraphics[scale=0.37]{pictures/Gamma=kappa=0.5/plotted_mles_unlim_gk0.5_zoomed.png}
        \caption{Mles unlimited, alpha and eta for all participants. $\gamma=\kappa=0.5$. Zoomed}
        \label{fig:gk0.5_mles_unlimited_zoomed}
    \end{minipage}
    \vfill
    \begin{minipage}{0.48\textwidth}
        \centering
        \includegraphics[scale=0.37]{pictures/Gamma=kappa=0.5/plotted_mles_unlim_gk0.5_zoomed2.png}
        \caption{Mles unlimited, alpha and eta for all participants. $\gamma=\kappa=0.5$. Zoomed even more.}
        \label{fig:gk0.5_mles_unlimited_zoomed2}
    \end{minipage}
\end{figure}




\subsection{Confidence Intervals}


\subsubsection{Unlimited}
\begin{figure}
    \centering
    \begin{minipage}{0.48\textwidth}
        \centering
        \includegraphics[scale=0.37]{pictures/Gamma=kappa=0.5/ci_unlim_person61_gk0.5.png}
        \caption{ci unlim person 61, gk0.5}
        \label{fig:ci_unlim_person_61_gk0.5}
    \end{minipage}\hfill
    \begin{minipage}{0.48\textwidth}
        \centering
        \includegraphics[scale=0.37]{pictures/Gamma=kappa=0.5/ci_unlim_person61_gk0.5_zoomed.png}
        \caption{ci unlim person 61 zoomed, gk0.5}
        \label{fig:ci_unlim_person_61_zoomed_gk0.5}
    \end{minipage}
\end{figure}