\chapter{Results}

As we have found the maximum likelihood estimates and their respective confidence intervals, the next step is to show some of these results. However, we first present the Ideal Observer (IO) solutions for different values of the parameters, which depends on the expected losses. We firstly look at the situations where $\gamma=\kappa=1$, thus that the prior distribution for $\Theta$ is uniform. 

\section{Uniform Prior}
When we present the results, we start with the results where we have a uniform prior for $\Theta$. Recall that this means that it is equally likely that $\theta$ is anywhere between 0 and 1. We start with having a look at the probabilities that either blue or red are the majority colours. 

\subsection{Conditional Probabilities}
We will here have a look at the probability that red is the dominant colour, and the probability that blue is the dominant colour, as shown in \eqref{redmajor_final} and \eqref{blue_major_final}, respectively. These probabilities can be represented for each possible combination of blue and red boxes. Thus, we can find those probabilities for all the trials the participants have done. 

We present the probabilities in Figure \ref{fig:probability_gamma_kappa_1}. In the tree, the top node represents the situation where no boxes are opened. The probability that blue is the majority colour is then equal to the probability of red being the majority colour. This is represented as the proportion of blue and red inside the nodes, which in this case are equal quantities. The circle around the node represent which of the colours that have the highest probability of being in majority. In the top node, the probabilities are equal, thus, this circle is split in two. The node down to the left of the top node represents the situation where one box is opened, and that box is blue. One node down to the left of that one again represents the situation where two boxes are opened and both are blue, and so on. Similarly, the node down to the right of the top node represents the situation where one box is opened, and that box is red and so fourth down the tree. We see that in the last row of the tree, the middle node is missing. This is because the last row represents the situations where twelve boxes are opened, and as there cannot be six of each colour, that node is not included in the tree. In the row above, we see that all the nodes are completely red or completely blue. That means that we can be sure what the majority colour is after eleven boxes are opened. This is because there cannot be six boxes of each of the colours. Then, if there are six of one colour and five of the other, we know that the colour with six boxes is the majority colour. 
\begin{figure}
    \centering
    \scalebox{0.4}{\input{tikz-trees/probability_gamma_kappa_1}}
    \caption[The probabilities of majority colour plotted. $\gamma=\kappa=1$]{A tree representing the probabilities that either red or blue are in majority in the box task with a uniform prior. The top node is the situation where no boxes are opened, where we do not have any information. Hence, the probabilities are equal, and the fraction that is blue inside the node is the same as the blue part. The circle around the nodes represents which colour that is most likely to be in majority, hence the circle is split between red and blue in the top node. The node down to the left is the situation when a blue box is opened, the node down to the right is when one red box is opened, and so forth.}
    \label{fig:probability_gamma_kappa_1}
\end{figure}



When we have these probabilities, the next step is to look at the Ideal Observer solution we have found.




\subsection{An Ideal Observer Solution in the Unlimited case}

As we have all the expected losses for each possible combination of opened boxes, we can present these similarly to the probabilities in Figure \ref{fig:probability_gamma_kappa_1}. 
The expected losses in the unlimited case is as given in \eqref{exp_loss_blue}, \eqref{exp_loss_red} and \eqref{exp_loss_next_box_unlim}. In the unlimited case, we get different solutions for different values of $\alpha$. We have looked at numerous solutions, but only a handful of them will be presented here. 

Recall that an Ideal Observer solution is a solution where the decisions tied to the least expected loss is chosen each time a box is opened. In Figure \ref{fig:unlim_a0.0001_gk1}, we have visualised the expected losses and the decisions an Ideal Observer would do for a participant with $\alpha=0.0001$. As in Figure \ref{fig:probability_gamma_kappa_1}, the top node represents the situation where no boxes are opened, and the node down to the left represents the situation where one box is opened, and that box is blue and so forth. The circles around the nodes represent the decision with the least expected loss, thus the decision that an Ideal Observer would make. A blue circle indicates that choosing blue as the majority colour has the least expected loss, and a red circle indicates that choosing red has the least expected loss. A green circle means that the the decision to open the next box has the least expected loss. The colours inside the nodes represent what we could call the inverse of the expected losses. That means that if the decision of choosing red as the majority colour has a low expected loss, the amount of red inside that node is big. That means that the colour that represents the Ideal Observer solution is the most prominent in the different nodes. The inverse expected losses are found by adding together all the expected losses and then subtracting the expected loss in question. Later we are normalising these inverse expected losses as they do not sum to one. Let $\tau_i(\delta_i)$ be the inverse expected losses. Then, the inverse expected loss for choosing blue as the majority colour is 
\begin{equation*}
    \tau_i(0) = \sum_{j=0}^2 \EE_{\delta_j}^i(\alpha) - \EE_0^i(\alpha).
\end{equation*}
Similarly, for red it would be
\begin{equation*}
    \tau_i(1) = \sum_{j=0}^2 \EE_{\delta_j}^i(\alpha) - \EE_1^i(\alpha),
\end{equation*}
and for opening the next box it will be
\begin{equation*}
    \tau_i(2) = \sum_{j=0}^2 \EE_{\delta_j}^i(\alpha) - \EE_2^i(\alpha).
\end{equation*}
We need to normalise these. The proportion of blue in each node would then be
\begin{equation*}
    \frac{\tau_i(0)}{\tau_i(0)+\tau_i(1)+\tau_i(2)}.
\end{equation*}
\begin{figure}
    \centering
    \scalebox{0.7}{\input{tikz-trees/unlim_a_0.0001_g_k_1}}
    \caption[IO solution, unlimited. $\alpha=0.0001$, $\gamma=\kappa=1$]{A decision tree for the unlimited version of the box task with $\alpha = 0.0001$ and $\gamma=\kappa=1$. Green circles around each node show that opening another box has the least expected loss, and blue and red circles show that the least expected loss is for choosing the majority colour to be blue and red respectively. The colours inside the nodes represent the inverse expected losses. As in Figure \ref{fig:probability_gamma_kappa_1}, the top node is the situation before any boxes are opened, and the node down to the left of the top node is when one blue box is opened and so on.}
    \label{fig:unlim_a0.0001_gk1}
\end{figure}
This tree stops when there is a red or blue circle around the node. That is when the Ideal Observer would choose what the majority colour is, and since this is the Ideal Observer solution, we stop the decision tree there. 


As we can see in Figures \ref{fig:unlim_a0.0001_gk1}, \ref{fig:unlim_a0.01_gk1} and \ref{fig:unlim_a0.05_gk1}, where the $\alpha$ values are 0.0001, 0.01 and 0.05, respectively, the trees are slimmer for bigger values of $\alpha$. Recall that $\alpha$ is the penalty of opening a box and that the expected loss for choosing to open another box increases with it. Hence the threshold for when that expected loss surpasses the expected loss for choosing either blue or red as majority colour decreases with increasing $\alpha$. Therefore, we make a decision at an earlier point when $\alpha$ is high, which makes the trees slimmer.
\begin{figure}
    \centering
    \begin{minipage}{0.45\textwidth} 
        \centering
        \scalebox{0.5}{\input{tikz-trees/unif_unlim_a0.01v2}}
        \caption[IO solution, unlimited. $\alpha=0.01$,$\gamma=\kappa=1$]{A decision tree for an unlimited trial with $\alpha = 0.01$ and $\gamma=\kappa=1$.
        We can interpret this tree in the same way as Figure \ref{fig:unlim_a0.0001_gk1} where the circles around each node shows which decision the Ideal Observer would do.}
        \label{fig:unlim_a0.01_gk1}
    \end{minipage}\hfill
    \begin{minipage}{0.45\textwidth}
        \centering
        \scalebox{0.5}{\input{tikz-trees/unlim_a0.05_gk1}}
        \caption[IO solution, unlimited. $\alpha=0.05$,$\gamma=\kappa=1$]{A decision tree in the unlimited case with $\alpha = 0.05$ and $\gamma=\kappa=1$ that can be understood in the same way as Figure \ref{fig:unlim_a0.0001_gk1} where the circles around each node shows which decision the Ideal Observer would do.}
        \label{fig:unlim_a0.05_gk1}
    \end{minipage}
\end{figure}



At some point, $\alpha$ could get so big that the ideal observer would decide what the majority colour is after only one box is opened. The expected loss for opening another box is dependent on both $\alpha$ and the expected losses for continuing to open boxes. In contrast, the expected losses for choosing the majority colour are only dependent on the probabilities that one of the colours is in majority. For example, if the first box is red, the probability that red is in majority increases. Therefore, if $\alpha$ is big enough, the expected loss for opening another box could be higher than the probabilities that one of the colours is in majority; thus the ideal observer would decide after one box is opened. This is the situation when $\alpha$ is 0.1 as in Figure \ref{fig:unlim_a0.1_gk1}. Here, the expected loss before any boxes are opened is 0.5 both for choosing blue and red as the majority colour. For the choice of opening a box, the expected loss is 0.308. This is then the choice an ideal observer would make before any boxes are opened. If the box that opens is blue, the expected loss for choosing that blue is the majority colour is 0.208, 0.792 for choosing red, and 0.260 for opening another box. Hence, the ideal observer would decide that blue is the majority colour. This problem is symmetric. That means that if the opened box is red, the expected loss for choosing that red is the majority colour is 0.208, 0.792 for choosing blue and 0.260 for opening another box. In that case, the expected loss is smallest when we choose red as the majority colour.
\begin{figure}
    \centering
    \scalebox{1}{\input{tikz-trees/unlim_a0.1_gk1}}
    \caption[IO solution, unlimited. $\alpha=0.1$,$\gamma=\kappa=1$]{A decision tree for an unlimited trial with $\alpha = 0.1$, that can be interpreted in the same way as Figure \ref{fig:unlim_a0.0001_gk1}}
    \label{fig:unlim_a0.1_gk1}
\end{figure}


As $\alpha$ is the loss we get when we open a box, we can imagine that it also could be zero. In Figure \ref{fig:unlim_a0_gk1} we see the decision tree for $\alpha=0$. When we have six boxes of one of the colours, for example red, the expected loss of choosing red as the majority colour is zero, but so is the expected loss of opening the next box. Thus, and Ideal Observer would choose arbitrarily between those. However, we have decided here that the IO would rather choose majority colour than to open the next box if both of these expected losses are zero, such that one does not open any more boxes than necessary. We see that this tree resembles the tree where $\alpha=0.0001$ as shown in Figure \ref{fig:unlim_a0.0001_gk1}. This indicated that such a small value of $\alpha$ is very close to having $\alpha$ equal to zero. 
\begin{figure}
    \centering
    \scalebox{0.5}{\input{tikz-trees/unif_unlim_a0}}
    \caption[IO solution, unlimited. $\alpha=0$, $\gamma=\kappa=1$]{An Ideal Observer solution of the unlimited version of the box task with $\alpha = 0$ and $\gamma=\kappa=1$. This tree can be interpreted the same way as the tree in Figure \ref{fig:unlim_a0.0001_gk1}.  Here we choose that the IO chooses majority colour if the expected loss of opening the next box is the same as for choosing majority colour. These are both zero if there are six boxes of one of the colour that are displayed, which is the situation in all the nodes that have circles that are split between two colours.}
    \label{fig:unlim_a0_gk1}
\end{figure}

In Figure \ref{fig:IO_trial2_a0.01} we see the Ideal Observer solution in Trial 2 for an individual with $\alpha=0.01$. Trial 2 is as shown in Figure \ref{fig:trial2_order}. We see that the Ideal Observer would choose after six boxes are opened, hence before we can be completely sure that red is the majority colour, but the probability is .... (find this one), so it is very likely that we choose the right colour here. The expected loss of choosing red is then (1-that prob), hence very low. 
We see that if a participant has an $\alpha=0.05$, then an Ideal Observer would choose after two boxes are opened, as shown in Figure \ref{fig:IO_trial2_a0.05}. Then, the penalty for opening the next box is much higher than in Figure \ref{fig:IO_trial2_a0.01}, thus, the IO would choose after only two boxes are opened. 

%\begin{figure}
%    \centering
%    \scalebox{0.5}{\input{tikz-trees/test_of_trial2_unlim_a0.01_gamma_kappa_1}}
%    \caption{Trial 2, IO solution for a participant with $\alpha = 0.01$.}
%    \label{fig:IO_trial2_a0.01}
%\end{figure}
%\begin{figure}
%    \centering
%    \scalebox{0.5}{\input{tikz-trees/trial2_unlim_a0.05_gk1}}
%    \caption{Trial 2, IO solution for a participant with $\alpha = 0.05$.}
%    \label{fig:IO_trial2_a0.05}
%\end{figure}

\begin{figure}
    \centering
    \begin{minipage}{0.45\textwidth}
        \centering
        \scalebox{0.5}{\input{tikz-trees/trial2_unlim_a0.01_gk1}}
        \caption[IO Solution for Trial 2. $\alpha=0.01$,$\gamma=\kappa=1$]{This is an Ideal Observer solution for Trial 2 with $\alpha=0.01$ and $\gamma=\kappa=1$. The tree can be interpreted in the same way as Figure \ref{fig:unlim_a0.0001_gk1}.}
        \label{fig:IO_trial2_a0.01}
    \end{minipage}\hfill
    \begin{minipage}{0.45\textwidth}
        \centering
        \scalebox{0.5}{\input{tikz-trees/trial2_unlim_a0.05_gk1}}
        \caption[IO Solution for Trial 2. $\alpha=0.05$,$\gamma=\kappa=1$]{This is an Ideal Observer solution for Trial 2 with $\alpha=0.05$ and $\gamma=\kappa=1$. The tree can be interpreted in the same way as Figure \ref{fig:unlim_a0.0001_gk1}.}
        \label{fig:IO_trial2_a0.05}
    \end{minipage}
\end{figure}

As we have presented Ideal Observer solutions in the unlimited case for different values of $\alpha$, the next step is to show some of the solutions in the limited case. 




\subsection{An Ideal Observer Solution in the Limited case}
Having the expected losses in the limited case as given in \eqref{exp_loss_blue}, \eqref{exp_loss_red} and \eqref{exp_loss_limited_final}, we can visualise them in the same way as Figure \ref{fig:unlim_a0.0001_gk1}. In the limited trials, we have two parameters, $\alpha$ and $\beta$. Thus, we have solutions with both of these parameters varying. 

In Figures \ref{fig:lim_a0.01_b0.6_gk1} and \ref{fig:lim_a0.01_b0.4_gk1}, we see two solutions, both with $\alpha=0.01$. They have different values of $\beta$, namely $\beta=0.6$ and $0.4$, respectively. Both trees have the same width, but we see that the tree with the higher $\beta$ value is shorter. Thus, an Ideal Observer with $\beta=0.6$ would open fewer boxes than one with $\beta=0.4$, which is what we would imagine as $\beta$ is the loss of the test terminating. 
\begin{figure}
    \centering
    \begin{minipage}[t]{0.45\textwidth}
        \centering
        \scalebox{0.6}{\input{tikz-trees/lim_a0.01_b0.6_gk1}}
        \caption[IO solution, limited. $\alpha=0.01$, $\beta=0.6$ and $\gamma=\kappa=1$]{A decision tree for an unlimited trial with $\alpha = 0.01$, $\beta=0.6$ and $\gamma=\kappa=1$.
        We can interpret this tree in the same way as Figure \ref{fig:unlim_a0.0001_gk1} where the circles around each node shows which decision the Ideal Observer would do.}
        \label{fig:lim_a0.01_b0.6_gk1}
    \end{minipage}\hfill
    \begin{minipage}[t]{0.45\textwidth}
        \centering
        \scalebox{0.6}{\input{tikz-trees/lim_a0.01_b0.4_gk1}}
        \caption[IO solution, limited. $\alpha=0.01$, $\beta=0.4$ and $\gamma=\kappa=1$]{A decision tree in the limited case with $\alpha = 0.05$, $\beta=0.4$ and $\gamma=\kappa=1$ that can be understood in the same way as Figure \ref{fig:unlim_a0.0001_gk1} where the circles around each node shows which decision the Ideal Observer would do.}
        \label{fig:lim_a0.01_b0.4_gk1}
    \end{minipage}
\end{figure}


The trees in the limited case are in general slimmer than in the unlimited case. This is because of the penalty we get when the test terminates before we have made a decision. The expected losses for opening another box are bigger than in the unlimited case. Hence, in the limited case, these surpass the expected losses of choosing blue or red as majority colour earlier than in the unlimited case. Small values of $\alpha$ and $\beta$ in combination makes the trees wider, as in Figure \ref{fig:lim_a0.0001_b0.2_gk1}.
\begin{figure}
    \centering
    \scalebox{0.8}{\input{tikz-trees/lim_a0.0001_b0.2_gk1}}
    \caption[IO solution, limited. $\alpha=0.0001, \beta=0.2$. $\gamma=\kappa=1$.]{A decision tree for an unlimited trial with $\alpha = 0.01$, $\beta=0.2$ and $\gamma=\kappa=1$.
    We can interpret this tree in the same way as Figure \ref{fig:unlim_a0.0001_gk1} where the circles around each node shows which decision the Ideal Observer would do.}
    \label{fig:lim_a0.0001_b0.2_gk1}
\end{figure}

As in the unlimited case, there are trials where the Ideal Observer solution is to choose the majority colour after one box is opened. This is the case in Figures \ref{fig:lim_a0.05_b0.4_gk1} and \ref{fig:lim_a0.05_b0.6_gk1}. The only thing that has changed from Figure \ref{fig:lim_a0.01_b0.4_gk1} to Figure \ref{fig:lim_a0.05_b0.4_gk1} and from Figure \ref{fig:lim_a0.01_b0.6_gk1} to Figure \ref{fig:lim_a0.05_b0.6_gk1} is the value of $\alpha$, which has increased from 0.01 to 0.05. In the cases with the higher values of $\alpha$, the expected loss for opening box two is larger than for choosing the majority colour. This is a result of these expected losses being dependent on the next expected losses, which again depend on the expected losses for opening another box after that and so on. Additionally, these could potentially be large if the amount of red and blue boxes are close to each other, meaning that we for example first open a red box, then a blue, then a red and so forth. 

\begin{figure}
    \centering
    \begin{minipage}[t]{0.45\textwidth} 
        \centering
        \scalebox{0.8}{\input{tikz-trees/lim_a0.05_b0.4_gk1}}
        \caption[IO solution limited. $\alpha=0.05$, $\beta=0.4$ and $\gamma=\kappa=1$.]{A decision tree for a limited trial with $\alpha = 0.05$, $\beta=0.4$ and $\gamma=\kappa=1$. It can bee interpreted as the tree in Figure \ref{fig:unlim_a0.0001_gk1}.}
        \label{fig:lim_a0.05_b0.4_gk1}
    \end{minipage}\hfill
    \begin{minipage}[t]{0.45\textwidth} 
        \centering
        \scalebox{0.8}{\input{tikz-trees/lim_a0.05_b0.4_gk1}}
        \caption[IO solution limited. $\alpha=0.05$, $\beta=0.6$ and $\gamma=\kappa=1$.]{A decision tree for a limited trial with $\alpha = 0.05$, $\beta=0.6$ and $\gamma=\kappa=1$ that can be interpreted in the same way as the tree in Figure \ref{fig:unlim_a0.0001_gk1}).}
        \label{fig:lim_a0.05_b0.6_gk1}
    \end{minipage}
\end{figure}

In Figure \ref{fig:trial8_IO_a0.01_b0.6_gk1}, we see the IO solution for Trial 8 where $\alpha=0.01$ and $\beta=0.6$. We see that an Ideal Observer would choose majority colour after seven boxes are opened, where four are blue and three are red. In Figure \ref{fig:trial8_IO_a0.0001_b0.2_gk1}, we see another IO solution for Trial 8, where $\alpha=0.0001$ and $\beta=0.2$. Here, an Ideal Observer would not choose before the test terminates, and that would be a failed trial. Thus, the Ideal Observer is not perfect, as it is based on expected losses based on the previously opened boxes, and not based on what is actually going to happen.
\begin{figure}
    \centering
     \begin{minipage}[t]{0.45\textwidth}
        \centering
        \scalebox{0.7}{\input{tikz-trees/trial8_lim_a0.01_b0.6_gk1}}
        \caption[IO solution, Trial 8. $\alpha=0.01$, $\beta=0.6$ and $\gamma=\kappa=1$.]{This is an Ideal Observer solution for Trial 8 with $\alpha=0.01$, $\beta=0.6$ and $\gamma=\kappa=1$. The tree can be interpreted in the same way as Figure \ref{fig:unlim_a0.0001_gk1}}
        \label{fig:trial8_IO_a0.01_b0.6_gk1}
     \end{minipage}\hfill
     \begin{minipage}[t]{0.45\textwidth}
        \centering
        \scalebox{0.7}{\input{tikz-trees/trial8_lim_a0.0001_b0.2_gk1}}
        \caption[IO solution, Trial 8. $\alpha=0.0001$, $\beta=0.2$ and $\gamma=\kappa=1$.]{This is an Ideal Observer solution for Trial 8 with $\alpha=0.01$, $\beta=0.2$ and $\gamma=\kappa=1$. The tree can be interpreted in the same way as Figure \ref{fig:unlim_a0.0001_gk1}}
        \label{fig:trial8_IO_a0.0001_b0.2_gk1}
     \end{minipage}
\end{figure}

%\begin{figure}
%    \centering
%    \scalebox{0.8}{\input{tikz-trees/trial8_lim_a0.01_b0.6_gk1}}
%    \caption[IO solution, trial 8. $\alpha=0.01$, $\beta=0.6$ and $\gamma=\kappa=1$.]{IO solution, trial 8. $\alpha=0.01$, $\beta=0.6$ and $\gamma=\kappa=1$.}
    %\label{fig:trial8_IO_a0.01_b0.6_gk1}
%\end{figure}


%\begin{figure}
%    \centering
%    \scalebox{0.8}{\input{tikz-trees/trial8_lim_a0.0001_b0.2_gk1}}
%    \caption[IO solution, trial 8. $\alpha=0.0001$, $\beta=0.2$ and $\gamma=\kappa=1$.]{IO solution, trial 8. $\alpha=0.0001$, $\beta=0.2$ and $\gamma=\kappa=1$.}
    %\label{fig:trial8_IO_a0.0001_b0.2_gk1}
%\end{figure}


We have now presented some of the Ideal Observer solutions we have found, and will continue to present some of the results tied to the decision model we have defined. 





\subsection{Maximum Likelihood Estimates}
\label{chapter:mles}
As we have presented some Ideal Observer solutions, we will now have a look at the parameter estimates we have found for each of the participants. Recall that we find the maximum likelihood estimates (MLEs) by minimising the negative log likelihood using the L-BFGS-B algorithm as described in Chapter \ref{section:mles}.


\subsubsection{Unlimited}
We start with the unlimited case, where we have the parameters $\alpha$ and $\eta$. For each participant we have found the maximum likelihood estimates of both of these parameters, denoted $\ha$ and $\he$. These are plotted in Figure \ref{fig:plot_all_mles_unlim_zoom0}. We see that there is one extreme value of each of the estimates, $\ha$ and $\he$. To get a better picture of the values that are not extreme, we zoom in closer to zero for both parameters. This is done in Figure \ref{fig:plot_all_mles_unlim_zoom1}, and we have zoomed even more in Figure \ref{fig:plot_all_mles_unlim_zoom2}. Many of the participants have $\hat{\alpha}$ equal to or close to zero, meaning that they have none or little loss of opening boxes. This is not surprising as the task is neither long or hard to complete, and we would imagine that many of the participants open a lot of boxes. 

\begin{comment}
\begin{figure}
    \centering
    \begin{minipage}{0.45\textwidth}
        \centering
        \includegraphics[scale=0.4]{pictures/plotted_mles_unlim_gk1.png}
        \caption[All MLEs plotted, unlimited]{Caption}
        \label{fig:plot_all_mles_unlim_zoom0}
    \end{minipage}\hfill
    \begin{minipage}{0.45\textwidth}
        \centering
        \includegraphics[scale=0.4]{pictures/plotted_mles_unlim_gk1_zoom1.png}
        \caption[Some MLEs plotted, unlimited]{Caption}
        \label{fig:plot_all_mles_unlim_zoom1}
    \end{minipage}
\end{figure}
\end{comment}


\begin{figure}
    \centering
    \includegraphics[scale=0.7]{pictures/plotted_mles_unlim_gk1.png}
    \caption[MLEs of $\alpha$ and $\eta$, unlimited with $\gamma=\kappa=1$.]{The MLEs for all the participants plotted for the unlimited case of the box task with $\gamma=\kappa=1$.}
    \label{fig:plot_all_mles_unlim_zoom0}
\end{figure}

\begin{figure}
    \centering
    \includegraphics[scale=0.7]{pictures/plotted_mles_unlim_gk1_zoom1.png}
    \caption[MLEs of $\alpha$ and $\eta$, unlimited with $\gamma=\kappa=1$, zoomed.]{The MLEs for all the participants plotted for the unlimited case of the box task with $\gamma=\kappa=1$. Here we have zoomed in closer to zero.}
    \label{fig:plot_all_mles_unlim_zoom1}
\end{figure}

\begin{figure}
    \centering
    \includegraphics[scale=0.7]{pictures/plotted_mles_unlim_gk1_zoom2.png}
    \caption[MLEs of $\alpha$ and $\eta$, unlimited with $\gamma=\kappa=1$, zoomed more]{The MLEs for all the participants plotted for the unlimited case of the box task with $\gamma=\kappa=1$. Here we have zoomed in closer to zero even more than in Figure \ref{fig:plot_all_mles_unlim_zoom2}.}
    \label{fig:plot_all_mles_unlim_zoom2}
\end{figure}

 

Recall that high values of $\eta$ indicates that the participant makes the decisions with the least expected losses, and $\eta$ is infinity when the participant makes the decisions with the least excepted loss each time a box is opened.  
The log likelihood function is almost flat for high values of $\eta$. That means that the stopping criterion for the optimisation algorithm will be met several places for high values of $\eta$. Thus, if the true value of $\he$ is infinity, we could find that it is for example 10000 because the stopping criterion is met there. We therefore find a threshold for $\eta$ where we can say that all values above that threshold are so high that they go to infinity. Then, we can say that if a participant has $\he$ above that threshold, she always makes the decisions with the least expected loss. This threshold depends on the difference in the two lowest expected losses, but we can for example find one for when the difference is $0.01$.  If we for example have a majority of red boxes, then the expected loss of choosing red as the majority colour is quite low, but so could the expected loss of opening the next box be. Consider, a situation where we have $\EE_0^i(\vp)=0.98$, $\EE_1^i(\vp)=0.02$ and $\EE_2^i(\vp)=0.01$. Then, the decision to open the net box has the lowest expected loss, but the decision to choose red as majority colour is not far away. We then want the threshold value of $\eta$ to so high that the probability that the participant chooses to open the next box is close to one. If $\eta=1000$, the probability that the participant chooses to open the next box given these expected losses, is $0.99995$. Thus, we set $\eta=1000$ as a threshold for when the participant
always makes the choices that have the least expected loss.

 
If we look at the extreme values in Figure \ref{fig:plot_all_mles_unlim_zoom0}, we find one participant with a very high value of $\he$ and small value of $\ha$. This is individual 58, who has MLEs
\begin{equation}
\label{mles_unlim_person58}
    \begin{aligned}
        \ha &= 0.0016,\\
        \he &= 443422.7.
    \end{aligned}
\end{equation}
In each of the three unlimited trials, this individual chooses the majority colour exactly when there are six of one of the colours, which is when we can be completely sure what the true majority colour is. That means that individual 58 chooses after seven boxes are opened in Trial 2, and she then chooses red. In Trials 3 and 4 she chooses after 10 and 9 boxes are opened, respectively. Thus, she always chooses the decision with the least expected loss, which are the decisions an Ideal Observer would make, and $\he$ is therefore above the threshold value of 1000. Individual 58 has $\ha=0.0016$, which is quite small. This might be because she does not open any more boxes than necessary. She might then have a small loss of opening boxes, or some kind of reward of finishing early. This $\ha$ value is so small that it would give an IO solution similar to the one in Figure \ref{fig:unlim_a0.0001_gk1}, such that one always chooses after six boxes of one of the colours have been opened. 

Looking at the other extreme value in Figure \ref{fig:plot_all_mles_unlim_zoom0}, which is individual number 13, we see that she has a high value of $\ha$ and a small value of $\he$. In fact, the value of $\eta$ is negative. The values are
\begin{equation}
\label{mles_unlim_person13}
    \begin{aligned}
        \ha &= 4.2224,\\
        \he &= -0.4290.
    \end{aligned}
\end{equation}
In Trial 2, she chooses after two boxes are opened, where both boxes are red. In both Trial 3 and Trial 4, she chooses when three boxes are opened, where two of them are blue and one is red. She then chooses red as the majority colour despite the fact that choosing blue as the majority colour has a lower expected loss. Thus, she tends to choose the decisions with higher expected losses, and therefore she has a negative estimate of $\eta$. She also chooses quite early, thus she gets a high estimate of $\alpha$. However, an Ideal Observer with this high value of $\alpha$ would always choose after one box is opened.

If we look at a more typical person, we find, for example, individual number 61. She has
\begin{equation}
\label{mles_unilim_person61}
    \begin{aligned}
        \ha &= 0.0135,\\
        \he &= 19.9432.
    \end{aligned}
\end{equation}
In the unlimited trials, she chooses what she thinks is the majority colour after five, six and four boxes are opened. She chooses majority colour before she can be completely sure, and therefore has $\ha>0$. When she chooses however, she chooses the colour with the least expected loss, and thus have a positive $\he$. An IO with the estimates of individual 61 would choose after 3, 10 and 9 boxes were opened, thus her decisions do not coincide with the IO decisions, but they are not far away.  
\begin{figure}
    \centering
    \scalebox{0.7}{\input{tikz-trees/unlim_a0.0135_g1_k1}}
    \caption[IO solution of individual number 61 with $\ha=0.0135$ and $\gamma=\kappa=1$]{Here we see and Ideal Observer solution of the box task in the unlimited case for individual number 61 with a uniform prior, such that $\gamma=\kappa=1$. She has $\ha=0.0135$. This tree can be interpreted in the same way as the tree in Figure \ref{fig:unlim_a0.0001_gk1}.}
    \label{fig:IO_sol_individual61}
\end{figure}

Having looked at the MLEs in the unlimited case, we now continue with the limited trials. 


\subsubsection{Limited}
In the limited version, we have three parameters, $\alpha$, $\beta$ and $\eta$, and we have found maximum likelihood estimates for these for all of the 76 participants. The MLEs of $\alpha$ and $\eta$ for all participants are plotted in Figure \ref{fig:mles_limited_alpha_eta}. We see that many of the participants have $\hat{\alpha}=0$. In fact, all participants except four have $\ha=0$. We also see that four of the participants have $\he$ higher than the threshold value of 1000, meaning that they make good choices each time a box is opened. What is not so easy to see is that the two participants with the highest values of $\ha$ have negative values of $\he$. This indicates that they make choices with high expected losses and that they have high costs of opening new boxes. 
\begin{figure}
    \centering
    \begin{minipage}{0.48\textwidth}
        \centering
        \includegraphics[scale=0.38]{pictures/plotted_mles_limited_alpha_eta_gk1.png}
        \caption{Mles limited, alpha and eta for all participants. Not zoomed}
        \label{fig:mles_limited_alpha_eta}
    \end{minipage}\hfill
    \begin{minipage}{0.48\textwidth}
        \centering
        \includegraphics[scale=0.38]{pictures/plotted_mles_limited_alpha_eta_gk1_zoomed.png}
        \caption{Mles limited, alpha and eta for participants, zoomed}
        \label{fig:mles_limited_alpha_eta_zoomed}
    \end{minipage}
\end{figure}

In Figure \ref{fig:mles_limited_alpha_beta} we have plotted the MLEs of $\alpha$ and $\beta$ for all participants. Again we see that many participants have $\ha=0$. This might indicate that $\alpha$ is unnecessary to include in the limited version. Both $\alpha$ and $\beta$ are values tied to choosing early or not, thus, it might be enough to only include $\beta$. It is also not obvious how the MLEs are interpreting(?) $\alpha$ and $\beta$. 
\begin{figure}
    \centering
    \includegraphics[scale=0.38]{pictures/plotted_mles_limited_alpha_beta_gk1.png}
    \caption{Mles limited, alpha and beta for all participants.}
    \label{fig:mles_limited_alpha_beta}
\end{figure}



We have also plotted the MLEs of $\beta$ and $\eta$ together in Figure \ref{fig:mles_limited_beta_eta}. Again we see that four of the participants have high values of $\he$. Three of these have $\hb$ values close to one, which might indicate that they are afraid of the test terminating, and thus choose early, but that they choose the colour that is most likely to be in majority. Zooming in on the plot as in Figure \ref{fig:mles_limited_beta_eta_zoomed}, we see that the majority of the participants have $\he$ values between 10 and 80 and $\hb$ values between zero and 0.7. We also see that some participants have $\hb$ equal to zero. 
\begin{figure}
    \centering
    \begin{minipage}{0.48\textwidth}
        \centering
        \includegraphics[scale=0.38]{pictures/plotted_mles_limited_beta_eta_gk1.png}
        \caption{Mles limited, beta and eta for all participants}
        \label{fig:mles_limited_beta_eta}
    \end{minipage}
    \hfill
    \begin{minipage}{0.48\textwidth}
        \centering
        \includegraphics[scale=0.38]{pictures/plotted_mles_limited_beta_eta_zoomed_gk1.png}
        \caption{Mles limited, beta and eta for all participants, zoomed}
        \label{fig:mles_limited_beta_eta_zoomed}
    \end{minipage}
\end{figure}


In Figures \ref{fig:mles_limited_alpha_eta} and \ref{fig:mles_limited_beta_eta} we see a participant with a very high value of $\he$. This is individual number 70, and she has  parameter estimates
\begin{equation}
\label{mles_lim_person70}
    \begin{aligned}
        \ha &= 0.0015,\\
        \hb &= 0.7929,\\
        \he &= 23851.9.
    \end{aligned}
\end{equation}
She chooses what she thinks is the majority colour after either two or three boxes are opened in the limited trials. When there are two boxes of the same colour, she chooses that colour as the majority colour. In Figure \ref{fig:IO_sol_person_70} we see the Ideal Observer solution for an individual with the values given in \eqref{mles_lim_person70}. We see that the IO would do the exact same thing as individual number 70 has done, that is, choose when we have two boxes of the same colour, and then choose that colour as the dominant colour. In Trial 5 that is after two boxes are opened as the first two boxes are blue. This is visualised in Figure \ref{fig:IO_sol_perosn_70_trial5}. In Trial 6 both the IO and participant number 70 chooses after three boxes are opened as seen in Figure \ref{fig:IO_sol_person70_trial6}.
\begin{figure}
    \centering
    \scalebox{0.7}{\input{tikz-trees/lim_a0.0015_b0.7929_g1_k1}}
    \caption{IO solution individual number 70}
    \label{fig:IO_sol_person_70}
\end{figure}

\begin{figure}
    \centering
    \begin{minipage}{0.48\textwidth}
        \centering
        \scalebox{0.7}{\input{tikz-trees/IO sol person 70, trial 5}}
        \caption{IO sol person 70, trial 5}
        \label{fig:IO_sol_perosn_70_trial5}
    \end{minipage}
    \hfill
    \begin{minipage}{0.48\textwidth}
        \centering
        \scalebox{0.7}{\input{tikz-trees/IO_sol_perosn70_trial6}}
        \caption{IO sol person 70, trial 6}
        \label{fig:IO_sol_person70_trial6}
    \end{minipage}
\end{figure}

We have two individuals with high values of $\ha$. They both have negative $\he$ and $\hb=0$. These can be interpreted the same way, and we therefore present only the participant with the highest $\ha$ here. This is individual number 11. Her parameter estimates are
\begin{equation}
\label{mles_lim_person11}
    \begin{aligned}
        \ha &= 1.1798,\\
        \hb &= 0.0,\\
        \he &= -1.9538.
    \end{aligned}
\end{equation}
She chooses after two or three boxes are opened, and she tends to choose the colour that is in minority, not majority, out of the opened boxes. This is the reason for $\he$ being negative. $\hb$ is a measure of the loss one gets when the test terminates. If the test terminates, this counts as a failed trial. It also counts as a failed trial if the participant chooses the wrong colour as the majority colour. This individual does not seem to care if she chooses the wrong colour as the majority colour, and we might believe that, in the same way, she does not care whether the test terminates or not. This might be the reason that $\hb$ is zero. However, as she chooses after two and three boxes are opened, this indicates some kind of loss of opening boxes, thus we get the high value of $\ha$. 
Earlier, we discussed that $\alpha$ might be unnecessary in the limited trials as so many participants have $\ha=0$. However, for individual number 11 and the other participant with the high value of $\ha$, this parameter might be needed to express some kind of penalty of opening boxes as $\hb=0$.
In Figure \ref{fig:IO_sol_person11_limited_gk1} we see that an Ideal Observer with the same estimates as individual number 11 would choose majority colour before any boxes are opened. The expected loss of choosing majority colour then is 0.5 as it is the probability that the opposite colour is in majority. The expected loss of opening the first box is much higher due to the high value of $\ha$. 
\begin{figure}
    \centering
    \scalebox{0.7}{\input{tikz-trees/lim_a1.1798_b0_g1_k1}}
    \caption{IO sol perosn 11, limited, gk1}
    \label{fig:IO_sol_person11_limited_gk1}
\end{figure}


In Figures \ref{fig:mles_limited_alpha_beta} and \ref{fig:mles_limited_beta_eta} we see participant number 75 that has a high value of $\hb$. Her parameter estimates are
\begin{equation}
\label{mles_lim_person75}
    \begin{aligned}
        \ha &= 0.0517,\\
        \hb &= 2.219,\\
        \he &= 70.87.
    \end{aligned}
\end{equation}
This participant chooses after one box is opened in all of the six limited trials, hence, the high value of $\hb$. At the same time, individual 75 always chooses the colour of that first box as the majority colour, which is the colour with the least expected loss. The expected loss of opening the next box might be lower than the expected loss of choosing that as the majority colour. However, these expected losses are often close to each other, whereas the expected loss of choosing the other colour as the majority is often further away. Thus, she tends to choose decisions with low expected losses, but they might not be the decisions with the lowest expected loss. $\he$ is therefore quite high.
%, but not so high that it reaches the threshold value for $\eta$. However, that threshold value is based on expected losses that differ in value with $0.01$. Here, the expected losses differ more as the parameter estimates are quite high. Thus, the threshold value of $\eta$ might be a lot smaller in this situation. 

If we look at a more typical person, we find, for example, individual number 40. She has parameter estimates
\begin{equation}
\label{mles_lim_person40}
    \begin{aligned}
        \ha &= 0.0,\\
        \hb &= 0.4414,\\
        \he &= 38.00.
    \end{aligned}
\end{equation}
She opens between 2 and 5 boxes in all the trials except Trial 8. In all of these trials she chooses the most probable colour as the colour that she believes is the majority colour. Thus, $\he$ is reasonably high. In Trial 8 she opens nine boxes and tries to open the tenth when the test terminates. In that trial there are never two boxes of the same colour that is opened after each other, the probability that one of the colours is the majority colour is quite low. 









\subsection{Confidence Intervals}
We have presented an Ideal Observer solution of the box task and the maximum likelihood estimates for different participants. Now, we will discuss some of the confidence intervals we have found. Recall that these are found by finding the MLEs of 1000 bootstrap samples for each participant and the finding the 5-th and 95-th percentiles, as discussed in Chapter \ref{chapter:CIs_chap3}. 

\subsubsection{Unlimited}
We start with the confidence intervals in the unlimited case. In Figure \ref{fig:all_cis_alpha_unlim_v2} we see the confidence intervals for $\alpha$. The whole interval for individual number 13 is not included as it is very long. Recall that the MLE of $\alpha$ for person 13 is very large, and we also have a very large value of the upper limit of the CI for $\alpha$, $\ha_{1000}^{(95)}$. We see that many of the CIs include zero, meaning that many participants might not have that small loss of opening the next box. 
\begin{figure}
    \centering
    \includegraphics[scale=0.37]{pictures/all_cis_unlim_alpha.png}
    \caption[CIs for $\alpha$, unlimited. $\gamma=\kappa=1$]{Here are the confidence intervals for all the participants for $\alpha$ in the unlimited version of the box task. We see that individual number 13 has an interval outside the range of this plot. $\gamma=\kappa=1$.}
    \label{fig:all_cis_alpha_unlim_v2}
\end{figure}



In Figure \ref{fig:all_cis_eta_unlim_v2} we see all the CIs in the unlimited case for $\eta$. We see that some of the participants have the whole CI above 1000, the threshold value we defined for $\he$. We can for these participants conclude that they always make decisions with small expected losses. We also see that many of the CIs include the threshold value. In Figure \ref{fig:all_cis_eta_unlim_zoomed} we have zoomed in on the CIs, and added a line at zero. Only one CI include zero, the CI for individual number 13. Recall that she has a negative value of $\he$ and a very high $\ha$.
\begin{figure}
    \centering
    \includegraphics[scale=0.38]{pictures/test_cis_eta_unlim.png}
    \caption[CIs for $\eta$, unlimited. $\gamma=\kappa=1$]{Confidence intervals for each participant for $\eta$ in the unlimited version of the box task. $\gamma=\kappa=1$.}
    \label{fig:all_cis_eta_unlim_v2}
\end{figure}

\begin{figure}
    \centering
    \includegraphics[scale=0.38]{pictures/all_cis_unlim_eta_zoomed.png}
    \caption[CIs for $\eta$ zoomed, unlimited. $\gamma=\kappa=1$]{Confidence intervals of $\eta$ for each participant in the unlimited trials of the box task with $\gamma=\kappa=1$, zoomed.}
    \label{fig:all_cis_eta_unlim_zoomed}
\end{figure}


In Chapter \ref{chapter:mles} we discussed individual 61 that has MLEs in the middle of the range of the MLEs. The MLEs are as given in \eqref{mles_unilim_person61}.
We have 1000 bootstrap samples and thus 1000 values of both $\hat{\alpha}$ and $\he$ for this participant. These are plotted in Figure \ref{fig:ci_unlim_person_61}. There, we have also plotted the confidence interval as black lines. We see that most of the bootstrap samples are accumulated in the bottom left corner. Thus, we zoom in there in Figure \ref{fig:ci_unlim_person_61_zoomed}, where we also have plotted the CI. We have that
\begin{equation*}
    [\hat{\alpha}^{*(5)}_{1000},\hat{\alpha}^{*(95)}_{1000}] = [0,0.0362]
\end{equation*}
and
\begin{equation*}
    [\hat{\eta}^{*(5)}_{1000},\hat{\eta}^{*(95)}_{1000}] = [10.0449,110.3661].
\end{equation*}
We see that the confidence interval for $\alpha$ includes zero. Recall that having $\ha=0$ means that one does not have any cost of opening boxes. Additionally, we see that the whole interval for $\eta$ is above zero, which means that individual number 61 makes decisions with low expected losses, although they might not always be the decisions with the lowest expected loss. 


\begin{figure}
    \centering
    \begin{minipage}{0.48\textwidth}
        \centering
        \includegraphics[scale=0.37]{pictures/ci_unlim_person61.png}
        \caption[MLEs of bootstrap samples individual number 61, unlimited]{All of the MLEs of the 1000 bootstrap samples plotted for individual number 61 in the unlimited case with $\gamma=\kappa=1$. The confidence intervals for the two parameters are also included.}
        \label{fig:ci_unlim_person_61}
    \end{minipage}\hfill
    \begin{minipage}{0.48\textwidth}
        \centering
        \includegraphics[scale=0.37]{pictures/ci_unlim_person61_zoomed.png}
        \caption[MLEs of bootstrap samples individual number 61, unlimited, zoomed]{Here we have zoomed in on the bootstrap samples and confidence intervals that are plotted in Figure \ref{fig:ci_unlim_person_61}. This is for individual number 61 in the unlimited case with $\gamma=\kappa=1$.}
        \label{fig:ci_unlim_person_61_zoomed}
    \end{minipage}
\end{figure}

In Chapter \ref{chapter:mles} we also discussed individual number 13 that has a high $\ha$, as seen in \eqref{mles_unlim_person13}, compared to the other participants. The 1000 bootstrap samples for participant number 13 are plotted in Figure \ref{fig:ci_unlim_person_13}, and zoomed on the $\he$ axis in Figure \ref{fig:ci_unlim_person_13_zoomed}. The CIs are
\begin{equation*}
    [\hat{\alpha}^{*(5)}_{1000},\hat{\alpha}^{*(95)}_{1000}] = [0,1246.3510]
\end{equation*}
and
\begin{equation*}
    [\hat{\eta}^{*(5)}_{1000},\hat{\eta}^{*(95)}_{1000}] = [-9.9272,18.3986].
\end{equation*}
We see that many of the values of $\ha$ are very high, much higher than the MLE, thus $\hat{\alpha}^{*(95)}_{1000}$ is very high. That means that the estimates for this individual are uncertain. Thus, the model might not be a good fit for this participant and the choices she makes. 
\begin{figure}
    \centering
    \begin{minipage}{0.48\textwidth}
        \centering
        \includegraphics[scale=0.37]{pictures/ci_unlim_person13.png}
        \caption[MLEs of bootstrap samples individual number 13, unlimited]{All of the MLEs of the 1000 bootstrap samples plotted for individual number 13 in the unlimited case with $\gamma=\kappa=1$. The confidence intervals for the two parameters are also included.}
        \label{fig:ci_unlim_person_13}
    \end{minipage}\hfill
    \begin{minipage}{0.48\textwidth}
        \centering
        \includegraphics[scale=0.37]{pictures/ci_unlim_person13_zoomed.png}
        \caption[MLEs of bootstrap samples individual number 13, unlimited, zoomed]{Here we have zoomed in on the bootstrap samples and confidence intervals that are plotted in Figure \ref{fig:ci_unlim_person_61}. This is for individual number 13 in the unlimited case with $\gamma=\kappa=1$.}
        \label{fig:ci_unlim_person_13_zoomed}
    \end{minipage}
\end{figure}
%commenting out figure where zooming even more for person 13. 
\begin{comment}
\begin{figure}
    \centering
    \includegraphics[scale=0.7]{pictures/ci_unlim_person13_zoomed2.png}
    \caption{ci unlim person 13 zoomed even more. Kanskje ikke zoome såå mye siden mle er på4.2???}
    \label{fig:ci_unlim_person_13_zoomed2}
\end{figure}
\end{comment}

Another participants with extreme values we looked at in Chapter \ref{chapter:mles} is individual number 58. The MLEs are 
\begin{equation*}
    \begin{aligned}
        \ha &= 0.0016\\
        \he &= 443422.7.
    \end{aligned}
\end{equation*}
This value of $\he$ is above the threshold value, which makes the probabilities in \eqref{probabilities_bootstrap} be approximate either zero or one. Thus, when we draw decisions based on those probabilities, we will always end up with the same decisions, and those are the decisions that the participant have made. All the simulated decisions are therefore identical to the decisions the participant has made, and the MLEs will be identical. Thus, the length of the two CIs will be zero, and the values will be equal to the MLEs. Hence, the CIs are
\begin{equation*}
    [\hat{\alpha}^{*(5)}_{1000},\hat{\alpha}^{*(95)}_{1000}] = [0.0016,0.0016]
\end{equation*}
and
\begin{equation*}
    [\hat{\eta}^{*(5)}_{1000},\hat{\eta}^{*(95)}_{1000}] = [443422.7,443422.7].
\end{equation*}

\begin{comment}
We also see in Figure \ref{fig:ci_unlim_person_58} that all the data points are collected at one spot. 
\begin{figure}
    \centering
    \includegraphics[scale=0.7]{pictures/ci_unlim_person58.png}
    \caption[MLEs of bootstrap samples individual number 58, unlimited]{All MLEs of the 1000 bootstrap samples plotted in the unlimited case for individual number 58. We have a uniform prior here, meaning that $\gamma=\kappa=1$. We see that all the MLEs are in one spot, and thus the CI has length zero, with both ends for each parameter being the values of the MLEs.}
    \label{fig:ci_unlim_person_58}
\end{figure}
The situation described here where the probabilities are either zero or one and we therefore get identical bootstrap samples is also the case for the other participants that have CIs of length zero. 
\end{comment}



Having shown some of the confidence intervals for the unlimited trials we continue with the limited trials.












\subsubsection{Limited}
We will now have a look at the confidence intervals in the limited case. In Figure \ref{fig:all_cis_alpha_lim} we see the CIs for $\alpha$ for all of the participants. Individual number 11 has a much larger upper limit of the CI that the range of the axis here, thus, the CI continues outside of the plot. We also see that participant 13 has a higher interval than the other participants. These to are also the individuals with the high values of $\ha$ in Figure \ref{fig:mles_limited_alpha_eta}. We also see that all participants except these two have upper limits smaller than 0.2, meaning that most participants has none or a small loss of opening the next box. 
\begin{figure}
    \centering
    \includegraphics[scale=0.37]{pictures/all_cis_lim_alpha.png} %wrong name, right plot
    \caption{All cis of $\alpha$. Individual 11 has a much higher value of the upper limit than the range of the axis here.  unif prior, limited}
    \label{fig:all_cis_alpha_lim}
\end{figure}

In Figure \ref{fig:all_cis_beta}, we have plotted all the confidence intervals for $\beta$ in the limited case. Again, we see that individual 11 has  large interval that spans beyond the axis here. Many of the intervals include zero, which means that one does not feel any loss if the test terminates, although this is defined as a failed trial. We also see that most of the participants have upper limits below one, meaning that failed trials are not disastrous for most participants. 
\begin{figure}
    \centering
    \includegraphics[scale=0.38]{pictures/all_cis_lim_beta.png}
    \caption{Al cis beta. Individual 11 has a much higher value of the upper limit than the range of the axis here. Unif prior, limited.}
    \label{fig:all_cis_beta}
\end{figure}

We have also plotted the confidence interval for $\eta$ for each participant. This is shown in Figure \ref{fig:all_cis_eta_lim}. The CI for participant 70 is not included here as it is much higher than the range of the axis. There are only two CIs that include zero, the ones for participants 11 and 13. The rest of the intervals are above zero. That indicates that most participants make  choices with little expected loss, whereas individuals 11 and 13 might tend to make decisions with higher expected losses. Many participants have long intervals which might mean that there is uncertainty tied to their estimates. 
\begin{figure}
    \centering
    \includegraphics[scale=0.37]{pictures/all_cis_lim_eta.png}
    \caption{All cis eta, uniform prior, limited. person 70 not included as ci too high.}
    \label{fig:all_cis_eta_lim}
\end{figure}


We have three participants where all of the confidence intervals have length zero. These are individuals 21, 70 and 75. As for individual 75 in the unlimited case, they have very high values of $\he$, which makes the probabilities of each of the decisions as seen in \eqref{probabilities_bootstrap} be approximately zero or approximately one. Thus, all the simulated decisions are the same as the decisions they have done. All of the 1000 MLEs are therefore the same, and finding the percentiles therefore give the same value as the MLEs. It should be noted that individual 75 has $\he=70.87$ as seen in \ref{mles_lim_person75}, which is far below the threshold value of 1000 that we defined for $\eta$. She has a quite high estimate of $\beta$, which makes the expected loss of opening the next box relatively high. Therefore, the expected losses differ considerably, and it takes a much lower value of $\he$ for the probabilities in \eqref{probabilities_bootstrap} to be approximately zero or one. 





Then, indiv 11 with high values of alpha and beta and negative value of eta. (similar with 13, she can be interpreted in the same way, but 11 is more extreme)

In Figures \ref{fig:ci_lim_a_b_person_11} and \ref{fig:ci_lim_a_e_person_11} we see $\ha$ and $\hb$ in addition to $\ha$ and $\he$ plotted for the 1000 bootstrap samples. These plots are zoomed in Figures \ref{fig:ci_lim_a_b_person_11_zoomed} and \ref{fig:ci_lim_a_e_person_11_zoomed}, respectively. We see also here that there are many high values of $\ha$, which again give long intervals that indicates an uncertain estimate of $\alpha$.
\begin{figure}
    \centering
    \begin{minipage}{0.48\textwidth}
        \centering
        \includegraphics[scale=0.37]{pictures/ci_lim_a_e_person11.png}
        \caption{ci lim person 11}
        \label{fig:ci_lim_a_e_person_11}
    \end{minipage}\hfill
    \begin{minipage}{0.48\textwidth}
        \centering
        \includegraphics[scale=0.37]{pictures/ci_lim_a_e_person11_zoomed.png}
        \caption{ci lim person 11 zoomed}
        \label{fig:ci_lim_a_e_person_11_zoomed}
    \end{minipage}
\end{figure}


\begin{figure}
    \centering
    \begin{minipage}{0.48\textwidth}
        \centering
        \includegraphics[scale=0.37]{pictures/ci_lim_a_b_person11.png}
        \caption{ci lim person 11}
        \label{fig:ci_lim_a_b_person_11}
    \end{minipage}\hfill
    \begin{minipage}{0.48\textwidth}
        \centering
        \includegraphics[scale=0.37]{pictures/ci_lim_a_b_person11_zoomed.png}
        \caption{ci lim person 11 zoomed}
        \label{fig:ci_lim_a_b_person_11_zoomed}
    \end{minipage}
\end{figure}

In Figure \ref{fig:ci_lim_b_e_person_11} we see $\hb$ and $\he$ for the 1000 bootstrap samples plotted, and zoomed in Figure \ref{fig:ci_lim_b_e_person_11_zoomed}.
\begin{figure}
    \centering
    \begin{minipage}{0.48\textwidth}
        \centering
        \includegraphics[scale=0.37]{pictures/ci_lim_b_e_person11.png}
        \caption{ci lim person 11}
        \label{fig:ci_lim_b_e_person_11}
    \end{minipage}\hfill
    \begin{minipage}{0.48\textwidth}
        \centering
        \includegraphics[scale=0.37]{pictures/ci_lim_b_e_person11_zoomed.png}
        \caption{ci lim person 11 zoomed}
        \label{fig:ci_lim_b_e_person_11_zoomed}
    \end{minipage}
\end{figure}




Then about a more regualr person, person 40. 










Old:
except participant 13. In \eqref{mles_lim_person11} we see that she has a very high $\ha$, and thus the values of the CI are high, and the values are outside the range of the plot here. We also see that individual number 11 has a high value of the upper limit of the CI, and that participant number 75 has a CI that is zero in both the lower and upper limit. All of the CIs include zero except for individual number 13. 



In Figure \ref{fig:all_cis_beta} we see all the CIs for $\beta$ plotted. This time it is participant number 75 that is not included because of too high values of the CI.  Participant number 11 has a high upper limit of the CI, just like in the CI for $\alpha$.



In Figure \ref{fig:all_cis_eta_lim} we see all the CIs of $\eta$. We see here that participant number 75 has a CI of length zero, just as the CI for $\alpha$. In Figure \ref{fig:all_cis_eta_lim_zoomed} we have zoomed in , and see that only two participants have CIs that include zero. This means that most of the participants make reasonable choices, except for these two. 



%\begin{figure}
%    \centering
%    \includegraphics[scale=0.37]{pictures/all_cis_lim_eta_zoomed.png}
%    \caption{All cis eta, uniform prior, limited, zoomed.}
%    \label{fig:all_cis_eta_lim_zoomed}
%\end{figure}

If we again have a look at person 32, we find that the CIs are
\begin{equation*}
    [\hat{\alpha}^{*(5)}_{1000},\hat{\alpha}^{*(95)}_{1000}] = [0,0.0818],
\end{equation*}
\begin{equation*}
    [\hb^{*(5)}_{1000},\hb^{*(95)}_{1000}] = [0,0.8690]
\end{equation*}
and
\begin{equation*}
    [\hat{\eta}^{*(5)}_{1000},\hat{\eta}^{*(95)}_{1000}] = [4.4340,60.631].
\end{equation*}
We see the $\ha$ and $\hb$ of the 1000 bootstrap samples and the CIs plotted in Figure \ref{fig:ci_lim_a_b_person_32}. Here we see two outliers in the top right corner, and we therefore zoom in more as in Figure \ref{fig:ci_lim_a_b_person_32_zoomed}. Here we see that many of the bootstrap samples gives $\ha$ and $\hb$ equal to zero. Thus, both of these intervals include zero. 
\begin{figure}
    \centering
    \begin{minipage}{0.48\textwidth}
        \centering
        \includegraphics[scale=0.37]{pictures/ci_lim_a_b_person32.png}
        \caption{ci lim person 32}
        \label{fig:ci_lim_a_b_person_32}
    \end{minipage}\hfill
    \begin{minipage}{0.48\textwidth}
        \centering
        \includegraphics[scale=0.37]{pictures/ci_lim_a_b_person32_zoomed.png}
        \caption{ci lim person 32 zoomed}
        \label{fig:ci_lim_a_b_person_32_zoomed}
    \end{minipage}
\end{figure}
In Figure \ref{fig:ci_lim_a_e_person_32} we see the $\ha$ and $\he$ values plotted and again zoomed in Figure \ref{fig:ci_lim_a_b_person_32_zoomed}. There are some outliers of $\he$ with very high values, but the CI still has a quite small upper limit. 
\begin{figure}
    \centering
    \begin{minipage}{0.48\textwidth}
        \centering
        \includegraphics[scale=0.37]{pictures/ci_lim_a_e_person32.png}
        \caption{ci lim person 32}
        \label{fig:ci_lim_a_e_person_32}
    \end{minipage}\hfill
    \begin{minipage}{0.48\textwidth}
        \centering
        \includegraphics[scale=0.37]{pictures/ci_lim_a_e_person32_zoomed.png}
        \caption{ci lim person 32 zoomed}
        \label{fig:ci_lim_a_e_person_32_zoomed}
    \end{minipage}
\end{figure}


\begin{figure}
    \centering
    \begin{minipage}{0.48\textwidth}
        \centering
        \includegraphics[scale=0.37]{pictures/ci_lim_b_e_person32.png}
        \caption{ci lim person 32}
        \label{fig:ci_lim_b_e_person_32}
    \end{minipage}\hfill
    \begin{minipage}{0.48\textwidth}
        \centering
        \includegraphics[scale=0.37]{pictures/ci_lim_b_e_person32_zoomed.png}
        \caption{ci lim person 32 zoomed}
        \label{fig:ci_lim_b_e_person_32_zoomed}
    \end{minipage}
\end{figure}

Individual number 11 has very high upper limits of both the CI for $\alpha$ and for $\beta$, and she is one of the two that has a CI for $\eta$ that includes zero. The CIs are
\begin{equation*}
    [\hat{\alpha}^{*(5)}_{1000},\hat{\alpha}^{*(95)}_{1000}] = [0,1092.9440],
\end{equation*}
\begin{equation*}
    [\hb^{*(5)}_{1000},\hb^{*(95)}_{1000}] = [0,1023.9252]
\end{equation*}
and
\begin{equation*}
    [\hat{\eta}^{*(5)}_{1000},\hat{\eta}^{*(95)}_{1000}] = [-5.6640,3.2192].
\end{equation*}

In Figures \ref{fig:ci_lim_a_b_person_11} and \ref{fig:ci_lim_a_e_person_11} we see $\ha$ and $\hb$ in addition to $\ha$ and $\he$ plotted for the 1000 bootstrap samples. These plots are zoomed in Figures \ref{fig:ci_lim_a_b_person_11_zoomed} and \ref{fig:ci_lim_a_e_person_11_zoomed}, respectively. We see also here that there are many high values of $\ha$, which again could be local maximum points. We also see quite high values of $\hb$, which might also be because of local maximum points. 


Individual 75 has CIs with length zero. These CIs are
\begin{equation*}
    [\hat{\alpha}^{*(5)}_{1000},\hat{\alpha}^{*(95)}_{1000}] = [0,0],
\end{equation*}
\begin{equation*}
    [\hb^{*(5)}_{1000},\hb^{*(95)}_{1000}] = [79.5448,79.5448]
\end{equation*}
and
\begin{equation*}
    [\hat{\eta}^{*(5)}_{1000},\hat{\eta}^{*(95)}_{1000}] = [45.69408,45.69408].
\end{equation*}
In \eqref{mles_lim_person75} we see that the MLEs for $\beta$ and $\eta$ are smaller than the values for the CIs (jeg aner faktisk ikke hvorfor det er sånn?? man får samme sekvens med valg, men forskjellige mleer, og jeg aner ikke hvorfor. såå hva skal jeg si om dette?)

We have now looked at the results when we have a uniform prior, thus that $\gamma=\kappa =1$. The next we will do is looking at how the results are influenced by a different prior. Thus, we look at the sensitivity of the hyperparameters $\gamma$ and $\kappa$.




\section{Non-uniform Prior?}
note to self: gamma and kappa smaller give more 'weight' to the colour of the boxes that are oepned. hence, we choose earlier because the prob that blue is majority is bigger here than for unif if one blue box is opened. 

Sentence about having seen results for uniform prior. We choose $\gamma=\kappa=0.5$, but there are many different priors one could try. but we believe that gamma and kappa are equal. 

\subsection{Maximum Likelihood Estimators}
sentece about starting with mles, and staritng with unlimted
\subsubsection{Unlimited}
sjekk om det er de samme outliersene som for uniform prior. ja, person 58 og 13. 
\begin{figure}
    \centering
    \begin{minipage}{0.48\textwidth}
        \centering
        \includegraphics[scale=0.37]{pictures/Gamma=kappa=0.5/plotted_mles_unlim_gk0.5.png}
        \caption{Mles unlimited, alpha and eta for all participants. $\gamma=\kappa=0.5$.    Not zoomed}
        \label{fig:gk0.5_mles_unlimited}
    \end{minipage}\hfill%\hspace{0.2cm}%\hfill
    \begin{minipage}{0.48\textwidth}
        \centering
        \includegraphics[scale=0.37]{pictures/Gamma=kappa=0.5/plotted_mles_unlim_gk0.5_zoomed.png}
        \caption{Mles unlimited, alpha and eta for all participants. $\gamma=\kappa=0.5$. Zoomed}
        \label{fig:gk0.5_mles_unlimited_zoomed}
    \end{minipage}
    \vfill
    \begin{minipage}{0.48\textwidth}
        \centering
        \includegraphics[scale=0.37]{pictures/Gamma=kappa=0.5/plotted_mles_unlim_gk0.5_zoomed2.png}
        \caption{Mles unlimited, alpha and eta for all participants. $\gamma=\kappa=0.5$. Zoomed even more.}
        \label{fig:gk0.5_mles_unlimited_zoomed2}
    \end{minipage}
\end{figure}




\subsection{Confidence Intervals}


\subsubsection{Unlimited}
plotting al cis except for perosn 13 with very high value of alpha
\begin{figure}
    \centering
    \includegraphics[scale=0.37]{pictures/Gamma=kappa=0.5/all_cis_alpha_unlim.png}
    \caption{All cis alpha except person 13, $\gamma=\kappa=0.5$.}
    \label{fig:gk0.5_all_cis_alpha_unlim}
\end{figure}

\begin{figure}
    \centering
    \includegraphics[scale=0.38]{pictures/Gamma=kappa=0.5/all_cis_eta_unlim.png}
    \caption{All cis eta except person 58, $\gamma=\kappa=0.5$.}
    \label{fig:gk0.5_all_cis_eta_unlim}
\end{figure}




\begin{figure}
    \centering
    \begin{minipage}{0.48\textwidth}
        \centering
        \includegraphics[scale=0.37]{pictures/Gamma=kappa=0.5/ci_unlim_person61_gk0.5.png}
        \caption{ci unlim person 61, gk0.5}
        \label{fig:ci_unlim_person_61_gk0.5}
    \end{minipage}\hfill
    \begin{minipage}{0.48\textwidth}
        \centering
        \includegraphics[scale=0.37]{pictures/Gamma=kappa=0.5/ci_unlim_person61_gk0.5_zoomed.png}
        \caption{ci unlim person 61 zoomed, gk0.5}
        \label{fig:ci_unlim_person_61_zoomed_gk0.5}
    \end{minipage}
\end{figure}


\subsubsection{Limited}

\begin{figure}
    \centering
    \includegraphics[scale=0.48]{pictures/Gamma=kappa=0.5/all_cis_alpha_lim.png}
    \caption{All cis $\alpha$, limited, $\gamma=\kappa=0.5$.}
    \label{fig:all_cis_alpha_lim_gk0.5}
\end{figure}

\begin{figure}
    \centering
    \includegraphics[scale=0.48]{pictures/Gamma=kappa=0.5/all_cis_beta_lim.png}
    \caption{All cis $\beta$, limited, $\gamma=\kappa=0.5$.}
    \label{fig:all_cis_beta_lim_gk0.5}
\end{figure}

\begin{figure}
    \centering
    \includegraphics[scale=0.48]{pictures/Gamma=kappa=0.5/all_cis_eta_lim.png}
    \caption{All cis $\eta$, limited, $\gamma=\kappa=0.5$.}
    \label{fig:all_cis_eta_lim_gk0.5}
\end{figure}


